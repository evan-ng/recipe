{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TasteBud: GAN Based Recipe Generation with Graph\n",
    "\n",
    "Introductory words about this project..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Data Processing\n",
    "\n",
    "Data processing here has two main goals each with smaller milestones: tokenizing recipe data and creating the ingredients graph.\n",
    "Tokenizing data requires parsing the RecipeNGL dataset, which will be subsetted due to its large size.\n",
    "Creating the ingredients graph first requires a list of ingredients. A raw list will be obtained from the What's Cooking and RecipeNGL datasets. Then, the list will be filtered into a smaller list. The filtered list will be used for indexing ingredients, finding related/close ingredients, and creating the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import json\n",
    "import ast\n",
    "import glob\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing = True\n",
    "glove = torchtext.vocab.GloVe(name='6B', dim=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading What's Cooking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "# loading the What's Cooking dataset from the .json file\n",
    "wc_train_path = './data/whats_cooking/train.json'\n",
    "wc_train_data = json.load(open(wc_train_path, 'r'))\n",
    "print(wc_train_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading RecipeNGL Data and Subsetting\n",
    "Since RecipeNGL contains 2.23 million recipes, select a subset to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/recipe_ngl\\dataset_0_100.csv\n",
      "./data/recipe_ngl\\dataset_0_5000.csv\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    full_ngl_path = './data/recipe_ngl/full_dataset.csv'\n",
    "    # if the full recipeNGL dataset csv file exists, read a subset of it\n",
    "    if os.path.exists(full_ngl_path):\n",
    "        ngl_subset = [0, 5000] # change ngl_subset for different ranges of the dataset\n",
    "        ngl_df = pd.read_csv(full_ngl_path, skiprows=ngl_subset[0], nrows=ngl_subset[1], index_col=0)\n",
    "        ngl_df.to_csv(f'./data/recipe_ngl/dataset_{ngl_subset[0]}_{ngl_subset[1]}.csv')\n",
    "\n",
    "# load the dataset from the saved subset csv file\n",
    "for file in glob.glob('./data/recipe_ngl/dataset*.csv'):\n",
    "    print(file)\n",
    "    # use pd.eval to convert strings of lists into lists\n",
    "    ngl_df = pd.read_csv(file, index_col=0, \n",
    "                         converters={'ingredients':pd.eval, 'directions':pd.eval, 'NER':pd.eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[1 c. firmly packed brown sugar, 1/2 c. evapor...</td>\n",
       "      <td>[In a heavy 2-quart saucepan, mix brown sugar,...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[brown sugar, milk, vanilla, nuts, butter, bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[1 small jar chipped beef, cut up, 4 boned chi...</td>\n",
       "      <td>[Place chipped beef on bottom of baking dish.,...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...</td>\n",
       "      <td>[In a slow cooker, combine all ingredients. Co...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[frozen corn, cream cheese, butter, garlic pow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  [1 c. firmly packed brown sugar, 1/2 c. evapor...   \n",
       "1  Jewell Ball'S Chicken  [1 small jar chipped beef, cut up, 4 boned chi...   \n",
       "2            Creamy Corn  [2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [In a heavy 2-quart saucepan, mix brown sugar,...   \n",
       "1  [Place chipped beef on bottom of baking dish.,...   \n",
       "2  [In a slow cooker, combine all ingredients. Co...   \n",
       "\n",
       "                                              link    source  \\\n",
       "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
       "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
       "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
       "\n",
       "                                                 NER  \n",
       "0  [brown sugar, milk, vanilla, nuts, butter, bit...  \n",
       "1  [beef, chicken breasts, cream of mushroom soup...  \n",
       "2  [frozen corn, cream cheese, butter, garlic pow...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngl_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mustard sauce', 'back bacon rashers', 'gluten-free flour', 'whole wheat rotini pasta', 'red raspberry jello', 'hazelnut flour', 'celery', 'anchovy fillets', 'San Marzano tomatoes', 'wish bone guacamol ranch dress', 'low-fat balsamic vinaigrette', \"Quorn Chik''n Tenders\", 'sloe gin', 'saffron powder', 'passata', 'red curry paste', 'low sodium store bought chicken stock', 'fresno pepper', 'leaf parsley', \"Campbell's cream\", 'brown basmati rice', 'gumbo file powder', 'amaretti', 'reduced fat coconut milk', 'condensed reduced fat reduced sodium cream of chicken soup', 'frozen mustard greens', 'pineapple pie filling', 'king oyster mushroom', 'linguine pasta', 'Tabasco sauce', 'flour tortillas (not low fat)', 'asian noodles', 'low-fat parmesan cheese', 'sausage casings', 'new york strip steaks', 'beef rib roast', 'apple juice', 'cherry jello', 'White Pepper', 'caramel icing', 'Tia Maria', 'meat sauce', 'baby okra', 'green garlic', 'onion buns', 'white tuna', 'dry vermouth', 'small potatoes', 'cream cheese', 'frozen lemonade concentrate, thawed and undiluted']\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    # creating a list of unique ingredients from the datasets\n",
    "    ingredients_set = set()\n",
    "\n",
    "    # loop through What's cooking data to get ingredients\n",
    "    for i in range(len(wc_train_data)):\n",
    "        ingredients_set = ingredients_set | set(wc_train_data[i]['ingredients'])\n",
    "    \n",
    "    # loop through RecipeNGL data to get ingredients\n",
    "    for i in range(len(ngl_df[\"NER\"])):\n",
    "        ingredients_set = ingredients_set | set(ngl_df[\"NER\"][i])\n",
    "        \n",
    "    print(list(ingredients_set)[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # export the list of unique ingredients for manual filtering (use transpose for easier filtering)\n",
    "    cw = csv.writer(open(\"data/raw_ingredients_list.csv\",'w'))\n",
    "    cw.writerow(list(ingredients_set))\n",
    "    pd.read_csv('data/intermediary/raw_ingredients_list.csv', \n",
    "                header=None).T.to_csv('data/intermediary/raw_ingredients_list_transpose.csv', \n",
    "                                      header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a list of 8500 ingredients, we manually removed duplicated items that had spelling errors, semantic similarities, and extra numeric or qualitative descriptors (e.g. chopped, 2% fat, shredded, unsweetened), giving 955 ingredients. Then, each is paired its gloVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param: token_list - a list of tokens, no spaces or symbols\n",
    "# return: a tensor of the averaged GloVe embeddings of each token\n",
    "def glove_average(token_list):\n",
    "    embeds_list = []\n",
    "    for token in token_list:\n",
    "        embeds_list.append(glove[token])\n",
    "    embeds_average = torch.mean(torch.stack(embeds_list), dim=0)\n",
    "    return embeds_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # read the manually filtered ingredient list\n",
    "    filtered_ingredients_df = pd.read_csv('data/intermediary/filtered_ingredients_list_transpose.csv', header=None, names=[\"ingredient\"])\n",
    "    ingredient_embeddings = []\n",
    "\n",
    "    # find GloVe embeddings for each ingredient and save it\n",
    "    for i, row in filtered_ingredients_df.iterrows():\n",
    "        token_list = re.sub(r\"[^a-zA-Z ]+\", '', filtered_ingredients_df['ingredient'][i].lower()).split(' ')\n",
    "        embed_list = []\n",
    "        ingredient_embeddings.append(glove_average(token_list).tolist())\n",
    "        \n",
    "    filtered_ingredients_df['embedding'] = ingredient_embeddings\n",
    "    filtered_ingredients_df['ingredient'] = filtered_ingredients_df['ingredient'].apply(lambda x: x.rstrip())\n",
    "    filtered_ingredients_df.to_csv('data/glove_ingredients_list.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ingredient                                          embedding\n",
      "0      aioli  [0.053968001157045364, 0.027247000485658646, -...\n",
      "1        ale  [-0.4636099934577942, 0.6578099727630615, -1.3...\n",
      "2     almond  [-0.023429999127984047, 0.47051000595092773, -...\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    ingredients_df = pd.read_csv('data/glove_ingredients_list.csv', header=None, names=[\"ingredient\", \"embedding\"],\n",
    "                            converters={'embedding':pd.eval})\n",
    "    \n",
    "    print(ingredients_df[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since GloVe give embeddings for out-of-vocabulary words, the words with null tensors `[0,0,0,...,0]` were removed from the ingredients list, giving a total of 840 ingredients. Using these embeddings will allow for ingredients not in the list to be mapped to the closest ingredient, then put in the ingredient graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aioli': 0, 'ale': 1, 'almond': 2, 'anise': 3, 'apple': 4, 'applesauce': 5, 'apricot': 6, 'artichoke': 7, 'arugula': 8, 'asafoetida': 9, 'asparagus': 10, 'avocado': 11, 'bacon': 12, 'baguette': 13, 'baking mix': 14, 'baking soda': 15, 'banana': 16, 'banana blossom': 17, 'banana leaf': 18, 'basil': 19, 'bay leaf': 20, 'bean': 21, 'bean curd': 22, 'bean sprout': 23, 'beef': 24, 'beer': 25, 'beet': 26, 'berry': 27, 'biscuit': 28, 'bitter melon': 29, 'black pepper': 30, 'blackberries': 31, 'blueberries': 32, 'bok choy': 33, 'bologna': 34, 'bone': 35, 'bouillon': 36, 'brandy': 37, 'bread': 38, 'breast': 39, 'broccoli': 40, 'broth': 41, 'brown sugar': 42, 'brownie': 43, 'burger': 44, 'butter': 45, 'buttermilk': 46, 'butterscotch': 47, 'cabbage': 48, 'cake': 49, 'calabash': 50, 'candy': 51, 'cane sugar': 52, 'canola': 53, 'cantaloupe': 54, 'capsicum': 55, 'caramel': 56, 'carbonated water': 57, 'cardamom': 58, 'cardoon': 59, 'carrot': 60, 'caster sugar': 61, 'cauliflower': 62, 'cayenne': 63, 'celery': 64, 'cereal': 65, 'champagne': 66, 'chayote': 67, 'cheddar': 68, 'cheese': 69, 'cherries': 70, 'chicken': 71, 'chili': 72, 'chocolate': 73, 'chorizo': 74, 'choy sum': 75, 'chutney': 76, 'cider': 77, 'cilantro': 78, 'cinnamon': 79, 'clam': 80, 'clove': 81, 'cocoa': 82, 'coconut': 83, 'coffee': 84, 'cognac': 85, 'coleslaw': 86, 'coloring': 87, 'concentrate': 88, 'cookie': 89, 'coriander': 90, 'corn': 91, 'cornflour': 92, 'cornmeal': 93, 'cornstarch': 94, 'couscous': 95, 'crab': 96, 'cracker': 97, 'cranberries': 98, 'cream': 99, 'crescent roll': 100, 'crust': 101, 'cucumber': 102, 'cumin': 103, 'currant': 104, 'curry': 105, 'custard': 106, 'daikon': 107, 'dashi': 108, 'date': 109, 'dhal': 110, 'dill': 111, 'do chua': 112, 'dough': 113, 'dressing': 114, 'duck': 115, 'egg': 116, 'eggnog': 117, 'eggplant': 118, 'escarole': 119, 'essence': 120, 'extract': 121, 'farro': 122, 'fat': 123, 'fennel': 124, 'fenugreek': 125, 'fillet': 126, 'filling': 127, 'fish': 128, 'fish sauce': 129, 'flavoring': 130, 'flour': 131, 'focaccia': 132, 'frankfurters': 133, 'fruit': 134, 'fusilli': 135, 'galangal': 136, 'garlic': 137, 'gelatin': 138, 'ghee': 139, 'ginger': 140, 'glaze': 141, 'gnocchi': 142, 'goat': 143, 'gobo root': 144, 'goji berries': 145, 'gold leaf': 146, 'gorgonzola': 147, 'graham cracker': 148, 'grape': 149, 'grapefruit': 150, 'greek yogurt': 151, 'guacamole': 152, 'halibut': 153, 'ham': 154, 'hamburger': 155, 'harissa': 156, 'hash brown': 157, 'hominy': 158, 'honey': 159, 'horseradish': 160, 'hot dog': 161, 'hot sauce': 162, 'ice': 163, 'ice cream': 164, 'icing': 165, 'jaggery': 166, 'jalapeno': 167, 'jam': 168, 'jello': 169, 'jicama': 170, 'juice': 171, 'kahlua': 172, 'kalamata': 173, 'kale': 174, 'ketchup': 175, 'kielbasa': 176, 'kimchi': 177, 'kiwi': 178, 'kumquats': 179, 'ladyfingers': 180, 'laksa paste': 181, 'lamb': 182, 'lard': 183, 'lasagna': 184, 'lavender': 185, 'lemon': 186, 'lemongrass': 187, 'lentils': 188, 'lettuce': 189, 'licorice root': 190, 'lima bean': 191, 'lime': 192, 'limoncello': 193, 'linguine': 194, 'liqueur': 195, 'loaf': 196, 'lobster': 197, 'luncheon meat': 198, 'maca powder': 199, 'macaroni': 200, 'mace': 201, 'mandarin': 202, 'mango': 203, 'maple syrup': 204, 'margarine': 205, 'marinade': 206, 'marjoram': 207, 'marmite': 208, 'marshmallow': 209, 'marzipan': 210, 'masala': 211, 'mascarpone': 212, 'mayonnaise': 213, 'milk': 214, 'mint': 215, 'mirin': 216, 'miso': 217, 'molasses': 218, 'mozzarella': 219, 'mushroom': 220, 'mustard': 221, 'naan': 222, 'nectar': 223, 'nori': 224, 'nutmeg': 225, 'oat': 226, 'oatmeal': 227, 'oil': 228, 'okra': 229, 'oleo': 230, 'olive': 231, 'onion': 232, 'orange': 233, 'orecchiette': 234, 'oregano': 235, 'oyster': 236, 'oyster sauce': 237, 'pancetta': 238, 'paneer': 239, 'panko': 240, 'papaya': 241, 'paprika': 242, 'paraffin': 243, 'parmesan': 244, 'parsley': 245, 'passion fruit': 246, 'pasta': 247, 'pastry': 248, 'peach': 249, 'peanut': 250, 'peanut butter': 251, 'pear': 252, 'pecan': 253, 'pepper': 254, 'pepperoni': 255, 'pesto': 256, 'phyllo': 257, 'pickle': 258, 'pie crust': 259, 'piloncillo': 260, 'pimiento': 261, 'pineapple': 262, 'polenta': 263, 'popcorn': 264, 'poppy seed': 265, 'pork': 266, 'porridge': 267, 'potato': 268, 'prosciutto': 269, 'pudding': 270, 'pumpkin': 271, 'pumpkin seed': 272, 'quinoa': 273, 'racks': 274, 'radicchio': 275, 'raspberry': 276, 'relish': 277, 'remoulade': 278, 'rhubarb': 279, 'rib': 280, 'rice': 281, 'rice noodle': 282, 'rice paper': 283, 'ricotta': 284, 'rind': 285, 'rock sugar': 286, 'rosemary': 287, 'round': 288, 'roux': 289, 'rum': 290, 'rutabaga': 291, 'rye': 292, 'saffron': 293, 'sage': 294, 'sake': 295, 'salad': 296, 'salami': 297, 'salmon': 298, 'salsa': 299, 'salt': 300, 'sauce': 301, 'sauerkraut': 302, 'sausage': 303, 'scallion': 304, 'seasoning': 305, 'seaweed': 306, 'seltzer': 307, 'serrano': 308, 'sesame': 309, 'shallot': 310, 'shell': 311, 'shellfish': 312, 'sherbet': 313, 'sherry': 314, 'shiitake': 315, 'shortbread': 316, 'shortening': 317, 'shoyu': 318, 'shrimp': 319, 'shrimp paste': 320, 'sichuan pepper': 321, 'sirloin': 322, 'slaw': 323, 'smoke': 324, 'soda': 325, 'soup': 326, 'sour cream': 327, 'soy flour': 328, 'soy milk': 329, 'soy nut': 330, 'soy sauce': 331, 'spaghetti': 332, 'sparkling water': 333, 'spice': 334, 'spinach': 335, 'sprinkles': 336, 'squash': 337, 'squid': 338, 'star anise': 339, 'steak': 340, 'stew': 341, 'stock': 342, 'strawberry': 343, 'stuffing': 344, 'sugar': 345, 'sunflower seed': 346, 'sweetbread': 347, 'sweetener': 348, 'syrup': 349, 'tahini': 350, 'tallow': 351, 'tangerine': 352, 'tapioca': 353, 'tea': 354, 'tequila': 355, 'thyme': 356, 'toast': 357, 'tofu': 358, 'tomato': 359, 'tortilla': 360, 'tuna': 361, 'turbinado': 362, 'turkey': 363, 'turmeric': 364, 'udon': 365, 'vanilla': 366, 'veal': 367, 'vegetables': 368, 'verjuice': 369, 'vermicelli': 370, 'vinegar': 371, 'vodka': 372, 'water': 373, 'watercress': 374, 'white pepper': 375, 'wine': 376, 'worcestershire': 377, 'yeast': 378, 'yogurt': 379, 'zucchini': 380}\n"
     ]
    }
   ],
   "source": [
    "# dictionary pairing ingredient with index value\n",
    "ingredient_vocab = list(ingredients_df['ingredient'])\n",
    "ingredient_vocab_stoi = {s: i for i, s in enumerate(ingredient_vocab)}\n",
    "ingredient_vocab_itos = {i: s for i, s in enumerate(ingredient_vocab)}\n",
    "ingredient_vocab_size = len(ingredient_vocab)\n",
    "\n",
    "print(ingredient_vocab_stoi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for only \"Gathered\" sources, since those have more consistent format\n",
    "gathered_ngl_df = ngl_df[ngl_df.source == 'Gathered']\n",
    "# remove unnecessary columns\n",
    "filtered_ngl_df = gathered_ngl_df[['title', 'ingredients', 'directions', 'NER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[1 c. firmly packed brown sugar, 1/2 c. evapor...</td>\n",
       "      <td>[In a heavy 2-quart saucepan, mix brown sugar,...</td>\n",
       "      <td>[brown sugar, milk, vanilla, nuts, butter, bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[1 small jar chipped beef, cut up, 4 boned chi...</td>\n",
       "      <td>[Place chipped beef on bottom of baking dish.,...</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...</td>\n",
       "      <td>[In a slow cooker, combine all ingredients. Co...</td>\n",
       "      <td>[frozen corn, cream cheese, butter, garlic pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[1 large whole chicken, 2 (10 1/2 oz.) cans ch...</td>\n",
       "      <td>[Boil and debone chicken., Put bite size piece...</td>\n",
       "      <td>[chicken, chicken gravy, cream of mushroom sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  [1 c. firmly packed brown sugar, 1/2 c. evapor...   \n",
       "1  Jewell Ball'S Chicken  [1 small jar chipped beef, cut up, 4 boned chi...   \n",
       "2            Creamy Corn  [2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...   \n",
       "3          Chicken Funny  [1 large whole chicken, 2 (10 1/2 oz.) cans ch...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [In a heavy 2-quart saucepan, mix brown sugar,...   \n",
       "1  [Place chipped beef on bottom of baking dish.,...   \n",
       "2  [In a slow cooker, combine all ingredients. Co...   \n",
       "3  [Boil and debone chicken., Put bite size piece...   \n",
       "\n",
       "                                                 NER  \n",
       "0  [brown sugar, milk, vanilla, nuts, butter, bit...  \n",
       "1  [beef, chicken breasts, cream of mushroom soup...  \n",
       "2  [frozen corn, cream cheese, butter, garlic pow...  \n",
       "3  [chicken, chicken gravy, cream of mushroom sou...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ngl_df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing uppercase and symbols from directions and fuse using '\\n'\n",
    "for i, row in filtered_ngl_df.iterrows():\n",
    "    cleaned_directions = []\n",
    "    for step in row.directions:\n",
    "        step = re.sub(r\"[^a-zA-Z0-9]+\", ' ', step.lower()) # remove uppercase and symbols\n",
    "        cleaned_directions.append(step)\n",
    "    row.directions = cleaned_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[1 c. firmly packed brown sugar, 1/2 c. evapor...</td>\n",
       "      <td>[in a heavy 2 quart saucepan mix brown sugar n...</td>\n",
       "      <td>[brown sugar, milk, vanilla, nuts, butter, bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[1 small jar chipped beef, cut up, 4 boned chi...</td>\n",
       "      <td>[place chipped beef on bottom of baking dish ,...</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...</td>\n",
       "      <td>[in a slow cooker combine all ingredients cove...</td>\n",
       "      <td>[frozen corn, cream cheese, butter, garlic pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[1 large whole chicken, 2 (10 1/2 oz.) cans ch...</td>\n",
       "      <td>[boil and debone chicken , put bite size piece...</td>\n",
       "      <td>[chicken, chicken gravy, cream of mushroom sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  [1 c. firmly packed brown sugar, 1/2 c. evapor...   \n",
       "1  Jewell Ball'S Chicken  [1 small jar chipped beef, cut up, 4 boned chi...   \n",
       "2            Creamy Corn  [2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...   \n",
       "3          Chicken Funny  [1 large whole chicken, 2 (10 1/2 oz.) cans ch...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [in a heavy 2 quart saucepan mix brown sugar n...   \n",
       "1  [place chipped beef on bottom of baking dish ,...   \n",
       "2  [in a slow cooker combine all ingredients cove...   \n",
       "3  [boil and debone chicken , put bite size piece...   \n",
       "\n",
       "                                                 NER  \n",
       "0  [brown sugar, milk, vanilla, nuts, butter, bit...  \n",
       "1  [beef, chicken breasts, cream of mushroom soup...  \n",
       "2  [frozen corn, cream cheese, butter, garlic pow...  \n",
       "3  [chicken, chicken gravy, cream of mushroom sou...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ngl_df[:4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe Data Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No-Bake', 'Nut', 'Cookies']\n",
      "[['1', 'c.', 'firmly', 'packed', 'brown', 'sugar'], ['1/2', 'c.', 'evaporated', 'milk'], ['1/2', 'tsp.', 'vanilla'], ['1/2', 'c.', 'broken', 'nuts', '(pecans)'], ['2', 'Tbsp.', 'butter', 'or', 'margarine'], ['3', '1/2', 'c.', 'bite', 'size', 'shredded', 'rice', 'biscuits']]\n",
      "[['in', 'a', 'heavy', '2', 'quart', 'saucepan', 'mix', 'brown', 'sugar', 'nuts', 'evaporated', 'milk', 'and', 'butter', 'or', 'margarine', ''], ['stir', 'over', 'medium', 'heat', 'until', 'mixture', 'bubbles', 'all', 'over', 'top', ''], ['boil', 'and', 'stir', '5', 'minutes', 'more', 'take', 'off', 'heat', ''], ['stir', 'in', 'vanilla', 'and', 'cereal', 'mix', 'well', ''], ['using', '2', 'teaspoons', 'drop', 'and', 'shape', 'into', '30', 'clusters', 'on', 'wax', 'paper', ''], ['let', 'stand', 'until', 'firm', 'about', '30', 'minutes', '']]\n",
      "[['brown', 'sugar'], ['milk'], ['vanilla'], ['nuts'], ['butter'], ['bite', 'size', 'shredded', 'rice', 'biscuits']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_titles = []\n",
    "tokenized_ingredients = []\n",
    "tokenized_directions = []\n",
    "tokenized_NER = []\n",
    "\n",
    "for i, row in filtered_ngl_df.iterrows():\n",
    "    # tokenize titles\n",
    "    tokens_list = filtered_ngl_df.title.values[i].split(' ')\n",
    "    tokenized_titles.append(tokens_list)\n",
    "    \n",
    "    # tokenize ingredients\n",
    "    tokens_list = []\n",
    "    for ingredient_item in row.ingredients:\n",
    "        tokens_list.append(ingredient_item.split(' '))\n",
    "    tokenized_ingredients.append(tokens_list)\n",
    "    \n",
    "    # tokenize directions\n",
    "    tokens_list = []\n",
    "    for direction_item in row.directions:\n",
    "        tokens_list.append(direction_item.split(' '))\n",
    "    tokenized_directions.append(tokens_list)\n",
    "    \n",
    "    # tokenize ingredients\n",
    "    tokens_list = []\n",
    "    for NER_item in row.NER:\n",
    "        tokens_list.append( re.sub(r\"[^a-zA-Z ]+\", '', NER_item.lower()).split(' ') )\n",
    "    tokenized_NER.append(tokens_list)\n",
    "\n",
    "print(tokenized_titles[0])\n",
    "print(tokenized_ingredients[0])\n",
    "print(tokenized_directions[0])\n",
    "print(tokenized_NER[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ngl_df = filtered_ngl_df.copy()\n",
    "tokenized_ngl_df['token_title'] = tokenized_titles\n",
    "tokenized_ngl_df['token_ingredients'] = tokenized_ingredients\n",
    "tokenized_ngl_df['token_directions'] = tokenized_directions\n",
    "tokenized_ngl_df['token_NER'] = tokenized_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>NER</th>\n",
       "      <th>token_title</th>\n",
       "      <th>token_ingredients</th>\n",
       "      <th>token_directions</th>\n",
       "      <th>token_NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[1 c. firmly packed brown sugar, 1/2 c. evapor...</td>\n",
       "      <td>[in a heavy 2 quart saucepan mix brown sugar n...</td>\n",
       "      <td>[brown sugar, milk, vanilla, nuts, butter, bit...</td>\n",
       "      <td>[No-Bake, Nut, Cookies]</td>\n",
       "      <td>[[1, c., firmly, packed, brown, sugar], [1/2, ...</td>\n",
       "      <td>[[in, a, heavy, 2, quart, saucepan, mix, brown...</td>\n",
       "      <td>[[brown, sugar], [milk], [vanilla], [nuts], [b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[1 small jar chipped beef, cut up, 4 boned chi...</td>\n",
       "      <td>[place chipped beef on bottom of baking dish ,...</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "      <td>[Jewell, Ball'S, Chicken]</td>\n",
       "      <td>[[1, small, jar, chipped, beef,, cut, up], [4,...</td>\n",
       "      <td>[[place, chipped, beef, on, bottom, of, baking...</td>\n",
       "      <td>[[beef], [chicken, breasts], [cream, of, mushr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...</td>\n",
       "      <td>[in a slow cooker combine all ingredients cove...</td>\n",
       "      <td>[frozen corn, cream cheese, butter, garlic pow...</td>\n",
       "      <td>[Creamy, Corn]</td>\n",
       "      <td>[[2, (16, oz.), pkg., frozen, corn], [1, (8, o...</td>\n",
       "      <td>[[in, a, slow, cooker, combine, all, ingredien...</td>\n",
       "      <td>[[frozen, corn], [cream, cheese], [butter], [g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  [1 c. firmly packed brown sugar, 1/2 c. evapor...   \n",
       "1  Jewell Ball'S Chicken  [1 small jar chipped beef, cut up, 4 boned chi...   \n",
       "2            Creamy Corn  [2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [in a heavy 2 quart saucepan mix brown sugar n...   \n",
       "1  [place chipped beef on bottom of baking dish ,...   \n",
       "2  [in a slow cooker combine all ingredients cove...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  [brown sugar, milk, vanilla, nuts, butter, bit...   \n",
       "1  [beef, chicken breasts, cream of mushroom soup...   \n",
       "2  [frozen corn, cream cheese, butter, garlic pow...   \n",
       "\n",
       "                 token_title  \\\n",
       "0    [No-Bake, Nut, Cookies]   \n",
       "1  [Jewell, Ball'S, Chicken]   \n",
       "2             [Creamy, Corn]   \n",
       "\n",
       "                                   token_ingredients  \\\n",
       "0  [[1, c., firmly, packed, brown, sugar], [1/2, ...   \n",
       "1  [[1, small, jar, chipped, beef,, cut, up], [4,...   \n",
       "2  [[2, (16, oz.), pkg., frozen, corn], [1, (8, o...   \n",
       "\n",
       "                                    token_directions  \\\n",
       "0  [[in, a, heavy, 2, quart, saucepan, mix, brown...   \n",
       "1  [[place, chipped, beef, on, bottom, of, baking...   \n",
       "2  [[in, a, slow, cooker, combine, all, ingredien...   \n",
       "\n",
       "                                           token_NER  \n",
       "0  [[brown, sugar], [milk], [vanilla], [nuts], [b...  \n",
       "1  [[beef], [chicken, breasts], [cream, of, mushr...  \n",
       "2  [[frozen, corn], [cream, cheese], [butter], [g...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ngl_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction Step Combining\n",
    "To ease the complexity of the GAN and RNN, the list of directions for each recipe will be fused into a single list of words, with each step separated by `'\\n'` (note all prior symbols were removed). The end of the directions will be marked by `'<EOS>'` for \"End of String.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roll', 'steak', 'strips', 'in', 'flour', '\\n', 'brown', 'in', 'skillet', '\\n', 'salt', 'and', 'pepper', '\\n', 'combine', 'tomato', 'liquid', 'water', 'onions', 'and', 'browned', 'steak', 'cover', 'and', 'simmer', 'for', 'one', 'and', 'a', 'quarter', 'hours', '\\n', 'uncover', 'and', 'stir', 'in', 'worcestershire', 'sauce', '\\n', 'add', 'tomatoes', 'green', 'peppers', 'and', 'simmer', 'for', '5', 'minutes', '\\n', 'serve', 'over', 'hot', 'cooked', 'rice', '\\n', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "combined_directions = []\n",
    "for i, row in tokenized_ngl_df.iterrows():\n",
    "    direction = []\n",
    "    for step in row.token_directions:\n",
    "        for word in step:\n",
    "            if word == '': # skip empty words\n",
    "                continue\n",
    "            direction.append(word)\n",
    "        direction.append('\\n')\n",
    "    direction.append('<EOS>')\n",
    "    combined_directions.append(direction)\n",
    "     \n",
    "tokenized_ngl_df['combined_directions'] = combined_directions\n",
    "print(combined_directions[8])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction Word Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words before ignoring: 3499\n",
      "Unique words after ignoring: 2393\n",
      "['raisin', 'fitted', 'yams', 'snack', 'wish', 'chutney', 'service', 'hunger', 'pizzelle', 'celery', 'prayer', 'dot', 'headspace', 'chill', 'sprayed', 'faith', 'uv', 'stockpot', 'puddings', '16', 'overnight', 'rim', 'vegies', 'coals', 'atop', 'pepperidge', 'sifting', 'prawns', 'results', 'rind', 'teflon', 'nicely', 'nice', 'caramel', 'sear', 'gets', 'bake', 'water', 'hours', 'knead', 'sprouts', 'dip', 'pumpernickel', 'salads', 'bits', 'reynolds', 'soups', 'tart', 'slaw', 'rolled', 'filled', 'splenda', 'putting', 'cilantro', 'free', 'showers', 'treat', 'veggies', 'cokes', 'clear', 'rosemary', 'halibut', 'chafing', 'sterile', 'directions', 'sealed', 'saving', 'minutes', 'wilted', 'consistency', 'speed', 'coarse', 'combined', '0', 'liquids', 'fill', 'slice', 'flute', 'tin', 'sure', 'tartar', 'seconds', 'crackers', 'burritos', 'spreading', 'vermouth', 'fist', 'starter', 'half', 'pull', 'sticks', 'pitcher', 'kiwi', 'couple', 'sugars', 'tel', 'life', 'confectioner', 'orange', 'hard', 'evaporated', 'stock', 'chilling', 'rinse', 'cleaned', 'butter', 'ro', 'jicama', 'fire', 'crimp', 'adding', 'raise', 'mushy', 'platter', 'powdered', 'oats', 'reserve', 'linguini', 'cocoa', 'tester', 'container', 'bark', 'insides', 'cumin', 'love', 'beat', 'big', 'won', 'seal', 'then', 'crushed', 'addition', 'sheets', 'method', '\\n', 'to', 'cinnamon', 'dish', 'starch', 'grated', 'place', 'cob', 'fall', 'mine', 'original', 'spoon', 'constantly', 'papers', 'rims', 'made', 'sweeter', 'smooth', 'fillets', 'omit', 'fresh', 'teriyaki', 'dirt', 'kindly', 'ale', 'sausage', 'roux', 'takes', 'sauteed', 'hominy', 'enough', 'dash', 'option', 'inserted', 'pick', 'eggs', 'cool', 'end', 'pile', 'rinsed', 'gallons', 'yolk', 'depending', 'hors', 'fits', 'dice', 'spice', 'sugared', 'marinate', 'remove', 'oiled', 'chestnut', 'sized', 'in', 'actually', 'lawry', 'microwave', 'shoyu', 'ketchup', 'work', 'cheeses', 'dark', 'minute', 'crystals', 'corned', 'serves', 'frequently', 'raisins', 'serving', 'preferably', 'cook', 'ovenproof', 'fine', 'works', 'long', 'shallow', 'set', 'zucchini', 'thickest', 'control', 'wax', 'pink', 'metal', 'night', 'what', 'some', 'kraft', 'ricotta', 'rubber', 'dill', 'fairly', 'dogs', 'apple', 'here', 'sprinkles', 'eggbeater', 'instant', 'seed', 'form', 'rise', 'tines', 'fashion', 'tip', 'sprite', 'thoroughly', 'd', 'tots', 'runs', 'beans', 'choice', 'for', '36', 'creamy', 'liking', 'emulsify', 'times', 'dust', 'leftover', 'debone', 'replace', 'delightful', 'rotary', '86', 'beef', 'great', 'low', 'cutter', 'cloth', 'applesauce', 'cooled', 'continue', 'drop', 'sodium', 'loses', 'two', 'been', 'o', 'overbeat', 'whiskey', 'sympathy', 'slab', 'doing', 'scald', 'longer', '55', 'requires', 'up', 'covers', 'thinner', 'rotini', 'tsp', 'browns', 'distribute', 'partly', '120', 'turmeric', 'min', 'thinly', 'yellow', 'blended', 'strainer', 'kindness', 'bundt', 'occasionally', 'mound', 'chocolate', 'light', 'funnel', 'flour', 'extra', 'dried', 'meringue', 'mashed', 'sorrow', 'glaze', 'stars', 'shaking', 'roll', 'normally', 'forming', 'microcook', 'overcook', 'canned', 'tapped', 'lentils', 'loaves', 'buttered', 'leftovers', 'halfway', 'using', 'rabbit', 'feta', 'saran', 'leave', 'oatmeal', '9x9', 'parchment', 'cheez', 'calories', 'ginger', 'section', 'chewy', 'colors', 'points', 'salsa', 'jell', 'enclose', 'step', 'weed', 'runny', 'lid', 'feed', 'dome', 'saved', 'perhaps', '70', 'from', 'purple', 'chili', 'little', 'shell', 'bed', 'core', 'morsels', 'pith', 'secure', 'taste', 'prevent', 'inverted', 'drying', 'squeeze', 'boil', 'frosted', 'slightly', 'melting', 'stew', 'slit', 'shortening', 'souffle', 'pickle', 'molds', 'spoonful', 'among', 'sweeten', 'position', 'variety', 'haddock', 'unpeeled', 'tint', 'pocket', 'machine', 'nonstick', 'chunks', 'preheated', 'hearts', 'shredded', 'catalina', 'legs', 'steadily', 'pulling', 'strawberries', 'according', 'pastry', 'provolone', 'patties', 'saltwater', 'scalded', 'mash', 'lima', 'crumbles', 'steam', 'except', 'save', 'vanilla', 'different', 'pet', 'last', 'seeds', '8ths', 'procedure', 'damp', 'formed', 'noodle', 'bottles', 'dough', 'buy', 'pouring', 'egg', 'lumps', 'stop', 'rounded', 'peaked', 'shaker', 'pattern', 'help', 'spoonfuls', 'tamales', 'plus', 'unsweetened', 'ice', 'servings', 'available', 'gel', 'oven', 'oleo', 'stretch', 'take', 'pepper', 'circular', 'franks', 'pat', '100', 'having', 'complete', 'dampen', 'continuing', 'going', 'changes', 'trays', 'trim', 'about', 'whipping', 'cast', 'quite', 'campbell', '1', 'between', 'first', 'sauces', 'overbake', 'ending', 'tough', 'follows', 'smaller', 'salty', 'golf', 'rows', 'toothpick', 'pecan', 'bag', 'unbeaten', 'moisture', 'touched', 'coat', 'simply', 'tablespoonful', 'sort', 'french', 'pressed', 'american', 'heatproof', 'tightly', 'level', 'cold', 'refrigerate', 'juice', 'tvp', '200', 'good', 'crispy', 'cooking', 'split', 'pointed', 'average', 'flat', 'possible', 'dinner', 'small', 'spices', 'feeds', 'but', 'dissolves', 'centers', 'next', 'ones', 'gives', '13', 'chow', 'spaghetti', 'children', 'lime', 'texture', 'done', 'fried', 'three', 'tops', 'well', 'blot', 'rounds', 'knife', 'bamboo', 'broth', 'touch', 'leaf', 'candied', 'them', 'bags', 'chiles', 'crust', 'vinegar', 'wafers', 'penne', 'approx', 'bottoms', 'six', 'crusts', 'tan', 'lite', 'handling', 'against', '75', 'heated', 'boils', 'separates', 'largest', 'russian', 'apricots', 'string', 'round', 'grind', 'criss', 'okra', 'leak', 'weather', 'standing', 'tossing', 'recipe', 'eating', 'ring', 'age', 'beet', 'with', 'cutters', 'breast', 'semi', 'skim', 'directs', 'cherries', 'removed', 'crescents', 'satisfy', 'chip', 'shape', 'glasses', 'couscous', 'used', 'prefer', 'yummy', 'please', 'season', 'size', 'pressure', 'my', 'begin', '46', 'peppers', 'parties', 'prepared', 'kitchen', 'batch', 'dilute', 'stuffing', 'skillets', 'above', 'separately', 'wheat', 'underside', 'decoration', 'mixer', 'toast', 'lowest', 'peaches', 'pretzel', 'melted', 'radishes', '25', 'slash', 'pretty', 'rotel', 'disappear', 'beets', 'cabbage', 'herb', 'doesn', 'muffin', '500', 'slicing', 'stops', 'tube', 'out', 'teaspoonful', 'quiche', 'twinkies', 'separated', 'stiff', 'creamed', 'qt', 'grinder', 'meats', 'rack', 'leaves', 'c', 'plain', 'same', 'grate', 'coca', 'peeling', 'delicately', 'beer', 'dab', 'return', 'twice', 'thickened', 'almond', 'moderately', 'other', 'toward', 'cores', 'plump', 'divide', 'peaks', 'uncovered', 'garlic', 'sections', 'appetizer', 'flaked', 'floating', 'evaporate', 'envelope', 'becomes', 'pyrex', 'begins', 'yeast', 'firms', 'skin', 'milligrams', '11', 'scrape', 'along', 'mixture', 'moist', 'fluted', 'farm', 'roast', 'jackets', 'poke', 'snow', 'beaters', 'jalapeno', 'only', 'stays', 'package', 'devein', 'close', 'cutlets', 'gather', 'coarsely', 'arugula', 'bath', 'soup', 'grapes', 'usual', 'burner', 'left', 'insert', 'turning', 'extracts', 'star', 'flatter', 'adjust', 'thighs', 'creme', 'protein', 'basil', 'pounds', 'real', 'wrappers', 'whisk', 'heath', 'measured', 'baked', 'stream', 'peak', 'moisten', 'overlapping', 'throughout', 'squeezing', 'this', 'undercooked', 'carton', 'glass', 'jello', 'artichokes', 'depression', 'cheese', 'limburger', 'amber', 'meat', 'sweetened', 'several', 'berries', 'chex', 'casserole', 'pop', 'your', 'salt', '17', 'daily', 'retain', 'refrigerator', 'venison', 'cheddar', 'wine', '275', 'cranberries', 'cookies', 'coloring', 'circles', 'karo', 'gone', 'bringing', 'important', 'settling', 'soaked', 'roses', 'ends', 'pineapple', 'crepes', '64', 'horseradish', 'tomato', 'enchilada', 'towel', 'crockpot', 'advance', 'marshmallow', 'english', 'pudding', 'mg', 'seasonings', 'wire', 'pineapples', 'roasted', 'added', '85', 'main', 'substituted', 'finally', 'rectangular', 'shred', 'allspice', 'grains', 'coke', 'top', 'salmon', 'crumbled', 'pulp', 'cranberry', 'mix', 'pressing', 'raspberry', 'amount', 'follow', 'finely', 'marjoram', 'jelled', 'raspberries', 'salted', 'its', 'again', 'partially', 'right', 'any', 'meanwhile', 'gas', 'cereals', 'blintzes', 'old', 'ball', 'lightly', 'stand', 'kielbasa', 'exchange', 'letting', 'gr', 'even', 'diced', 'dipped', 'really', 'stiffen', 'club', 'rectangles', 'guests', 'pears', 'use', 'ribs', 'whirl', 'stuck', 'tasty', 'another', 'chilled', 'spring', 'disappears', 'we', 'covering', 'portion', 'sprinkled', 'process', 'dew', 'supper', 'v', 'baking', 'steamed', 'pin', 'velveeta', 'navy', '65', 'shaped', 'spray', 'non', 'spread', 'warmer', 'scissors', 'halve', 'pot', 'needed', 'soupy', 'covered', 'savory', 'blade', 'picante', '48', 'desired', 'espresso', 'coating', 'batches', 'stands', 'birthday', 'instructions', 'into', 'glossy', 'angle', 'italian', 'dipping', 'bakon', 'warmed', 'fat', 'coconut', 'braise', 'fingers', 'shells', 'marmalade', 'splashing', 'skillet', 'granulated', 'mini', 'bottom', 'miracle', 'shelf', 'toasted', 'crowd', 'teaspoons', 'grams', '2', 'flame', 'whites', 'saucepot', 'soaking', 'number', '9', 'kraut', 'green', 'deboned', 'side', 'transparent', 'mush', 'poppy', 'popcorn', 'lids', 'i', 'bouillon', 'remains', '13x9', 'home', 'wash', 'palms', 'nutmeg', 'various', 'of', 'ground', 'balls', 'safe', 'completely', 'dots', 'foam', 'bit', 'genesis', 'swiss', 'tail', 'paraffin', 'thawed', '8', 'chips', 'stove', 'oreo', 'store', 'serve', 'punch', 'wrap', 'drops', 'brandy', 'bisquick', 'finish', 'champagne', 'every', 'scrub', 'pints', 'on', 'scraping', 'that', 'hands', 'leaving', 'slices', 'beaten', 'flatten', 'rinsing', 'rises', 'vegetables', 'grease', 'firm', 'blanch', 'bell', 'cakes', 'during', 'knives', 'brussels', 'aside', 'very', 'poultry', 'watch', 'combination', 'after', 'scoops', 'cluster', 'beverages', 'chopper', 'near', 'self', 'oyster', 'flavoring', 'steak', 'moistened', 'crush', 'indirect', 'chopped', 'fitting', 'select', 'cauliflower', 'supreme', 'layers', 'diagonal', 'chocolates', 'crisco', 'go', 'griddle', 'colored', 'fasten', 'almonds', 'table', 'raw', 'chitterlings', 'alternating', 'drained', 'spreadable', 'saut', 'people', 'ungreased', 'allow', 'boiled', 'sweetener', 'degrees', 'oleomargarine', 'grapefruit', 'dropping', 'special', 'cholesterol', 'remaining', 'hot', 'future', 'packaged', 'wedge', 'piping', 'enjoy', 'soda', 'sandwich', 'chicken', 'oblong', 'thirds', 'tuck', 'edges', 'tiny', 'vermicelli', 'bun', 'patty', 'around', 'brine', 'game', 'cross', 'plate', 'curry', 'beginning', 'n', 'individually', 'orzo', 'boneless', 'are', 'alone', 'bread', 'you', 'tabasco', 'mints', '10x', 'crusty', 'meatballs', 'cornmeal', 'working', 'taking', 'watercress', 'way', 'pimentos', 'within', 'strip', 'easy', 'freezes', 'discarding', 'dates', 'indefinitely', 'mold', 'alcohol', 'crawfish', 'flours', 'unwrap', 'spins', 'dropped', 'deep', 'escape', 'medium', 'third', 'smearing', 'flake', 'mint', 'duty', 'temperature', 'ranch', 'cantaloupe', 'glazed', '300', 'parmesan', 'exchanges', 'oregano', 'absorb', 'phyllo', 'crepe', 'pasta', 'part', 'soft', 'sausages', 'being', 'cools', 'strain', 'own', 'realemon', 'gently', 'packages', 'saltine', 'pint', 'lower', 'contents', 'test', 'juices', 'herbs', 'pepperoni', 'flower', 'cup', 'roaster', 'amounts', 'graham', 'flavors', 'seasoned', 'homemade', 'log', 'reduce', 'across', 'slits', 'eight', 'stage', 'draw', 'pour', 'soon', 'juicy', 'full', 'strips', 'equally', 'lay', 'pig', 'generous', 'slush', 'granules', 'hand', 'finger', 'brush', 'proceed', 'suit', 'cutting', 'floured', 'twist', 'now', 'crumbling', 'fish', 'button', 'as', 'tastes', 'wrapper', 'filling', 'heavy', 'gravy', 'bombs', 'check', 'perk', 'foamy', 'bars', 'try', 'should', 'cover', 'smoothness', 'toppings', 'salad', 'scorching', 'marinade', 'mace', 'tray', 'bacon', 'much', 'onions', 'fork', 'pimiento', 'still', 'hardened', 'ladle', 'rolling', 'mixtures', 'continually', 'stuff', 'avocado', 'substitute', 'kettle', 'truss', 'pies', 'rolls', 'wedges', 'blueberry', 'warm', 'spanish', 'whipped', 'fruit', 'tight', 'coated', 'puree', 'roasting', 'under', 'smile', 'both', 'fingertips', 'butterfingers', 'sliced', 'cube', 'lastly', 'cupcake', 'blend', 'shallots', 'toy', 'knox', 'reserved', 'maraschino', 'mounds', 'stem', 'sets', 'brownies', 'tips', 'hamburgers', 'bowls', 'peanut', 'avoid', 'thyme', 'put', 'muffins', 'cherry', 'deviled', 'fruits', 'dog', 'foil', 'fry', 'richer', 'better', 'fully', 'best', 'congealed', 'early', 'kahlua', 'looks', 'dividing', 'smoke', 'liqueur', 'croutons', 'grits', 'inch', 'onion', 'months', 'noodles', 'horizontally', 'want', 'pkg', 'sauce', 'molasses', 'sifted', 'opaque', 'll', 'zest', 'quick', 'hershey', 'flavored', 'reduced', 'thick', 'baby', 'sealing', 'line', 'skewer', 'tater', 'filo', 'mustard', 'was', 'cake', 'till', 'ziploc', 'rock', 'loosely', 'hollow', 'caraway', 'cider', 'condensed', 'inside', 'sweat', 'anise', 'browned', 'stay', 'chowder', 'doubled', '80', 'all', 'freeze', 'steep', 'more', 'would', 'plates', 'airtight', 'lamb', 'lumpy', 'it', 'collards', 'cocktail', 'breading', 'most', 'strings', 'tie', 'elastic', 'freezing', 'slide', '240', 'precooked', 'less', 'omitted', 'ladyfingers', 'halves', 'prepare', 'bird', 'strawberry', 'absorbed', 'dump', 'sterilize', '90', 'so', 'sour', 'handle', 'awhile', 'quarter', 'banana', 'mince', 'wafer', 'bubble', 'liver', 'carefully', 'diagonally', 'style', 's', '3', 'keeping', 'hang', 'family', 'solids', 'quickly', 'butterfly', 'maximum', 'needs', 'or', 'giblets', '6', 'per', 'sugar', 'balance', 'melts', 'directed', 'day', 'kettles', 'liquid', 'circle', 'choose', 'opening', 'evenly', 'hens', 'pack', 'sunflower', 'sesame', 'quarts', 'candies', 'wait', 'carrot', 'reaches', 'open', 'p', 'buttermilk', 'tall', 'holes', 'decorating', 'removing', 'garnish', 'crank', 'cucumbers', 'cola', 'yum', 'not', 'peas', 'figs', 'racks', 'closely', 'one', 'undrained', 'powder', 'loaf', 'dente', 'macaroni', 'crumb', 'motion', 'pimento', 'deer', 'cracked', 'tails', 'eagle', 'pickles', 'wanted', 'combine', 'their', 'mouth', 'onto', 'trifle', 'rest', 'decorative', 'extremely', 'once', 'sift', 'simmer', '10', 'easier', 'larger', 'mug', 'outer', 'soak', 'melba', 'seasoning', 'relish', 'cornflakes', 'bubbles', 'sides', 'jar', 'waxed', 'hold', 'dissolved', 'always', 'pats', 'maybe', 'parts', 'run', 'flank', 'sticking', 'seams', 'fries', 'group', 'sprinkle', 'chop', 'upon', 'corns', 'tortilla', 'heat', 'lot', 'lots', 'fettuccine', 'winter', 'puff', 'reheated', 'either', 'ripe', 'corn', 'mixed', 'the', 'cracker', 'tuna', 'stems', 'purchased', 'chunk', 'rich', 'additional', 'firmly', 'tins', 'crock', 'clams', 'almost', 'continuously', 'mayonnaise', 'ahead', 'pureed', 'breakfast', '1st', 'drink', 'human', 'served', 'making', 'preference', 'canning', 'slowly', 'many', 'lined', '24', 'peanuts', 'lasts', 'never', 'basting', 'hamburg', 'kool', 'oeuvre', 'careful', 'tarragon', 'they', 'room', 'undiluted', 'bubbling', 'cole', 'necessary', 'pans', 'volume', 'anchor', 'miniature', 'sherry', 'membranes', 'thousand', 'rye', 'boned', 'mugs', 'transfer', 'caramels', 'parsley', '4', 'frankfurters', 'scrambled', 'chunked', 'dozen', 'squares', 'forms', 'tapioca', 'dollop', 'evaporates', 'caps', 'checking', 'lean', 'tears', 'repeat', 'lasagna', 'a', 'persimmon', 'cashews', 'square', 'seems', 'throw', '35', 'crumbly', 'gloss', 'allowed', 'dry', 'release', 'back', 'ramen', 'seam', 'florets', 'whatever', 'upside', 'hash', 'mixes', 'unmold', 'sterilized', 'halved', 'rectangle', 'food', 'spoke', 'spoons', 'paint', 'worcestershire', 'tea', 'drain', 'luke', 'tap', 'tomatoes', 'batter', 'measure', 'poured', 'packet', 'bay', 'mocha', 'total', '20', 'sun', 'smoked', 'need', 'pickling', 'cheesecloth', 'usually', 'thermometer', 'ham', 'shows', 'pea', 'edge', 'spiral', 'soy', 'thickening', 'springs', 'pheasant', 'beater', 'few', 'comes', 'slow', 'oreos', 'discard', 'sink', 'waffles', 'marshmallows', '375', 'skins', 'clam', 'remainder', 'resistant', 'equal', 'flavorings', 'optional', 'ounce', 'barbecue', 'thumb', 'like', 'beating', 'jars', '14', 'toothpicks', 'church', 'building', 'outside', 'pliable', 'custard', 'chestnuts', 'pork', 'blender', 'lengthwise', 'had', 'overmix', 'bean', 'breadcrumbs', 'running', 'lift', 'tossed', 'blossoms', 'saute', 'single', 'blackberries', 'red', 'creaming', 'drizzle', 'coats', 'cupcakes', 'jelly', 'nutmeats', 'holds', 'scallions', 'bring', '60', 'dutch', 'empty', 'seafood', 'cottage', 'turns', 'manufacturer', 'gentle', 'crunch', 'capers', 'increase', 'accent', 'oval', 'aluminum', 'garnishes', 'joy', 'upright', '50', 'has', '350', 'kneading', 'setting', 'before', 'pan', 'flavor', 'rotating', 'drippings', 'block', 'corners', 'followed', 'desire', 'carrots', 'air', 'extract', 'piece', '130', 'mountain', 'fluffy', 'field', '30', 'portions', '234', 'preheating', 'yogurt', 'eat', 'refrigerated', 'make', 'ready', 'score', 'pale', 'blending', 'child', 'dumplings', 'yields', 'peeled', 'stuffed', 'jellyroll', 'holding', 'meal', 'washed', 'gelatine', 'candy', 'mozzarella', 'could', 'taffy', 'an', 'alum', 'dressing', 'basket', 'change', 'including', 'chinese', 'point', '250', 'alternate', 'fryer', 'brown', 'frothy', 'get', 'listed', 'eggplant', 'and', 'wide', 'baker', 'row', 'buns', 'tofu', 'm', '2nd', 'shellfish', 'sherbet', 'starting', 'sharp', 'curdle', 'pectin', 'containers', 'bubbly', 'marble', 'note', 'krispies', 'cream', 'heating', 'frying', 'burn', 'bakes', 'those', 'margarine', 'wieners', 'popped', 'let', 'together', 'folding', 'consomme', 'bigger', 'narrow', 'milk', 'alternately', 'biscuit', 'worms', 'apart', 'breasts', 'breads', 'pare', 'lengths', 'teaspoonfuls', 'at', 'thin', 'refried', 'prick', 'oysters', 'kidney', 'wild', 'blueberries', 'entire', 'preheat', 'nacho', 'shoulder', 'separate', 'honey', 'spooned', 'is', 'cans', 'apples', 'also', 'saucepan', 'mushroom', 'lemon', 'instead', 'tablespoon', 'yolks', 'turned', 'tests', 'kids', 'do', 'wrapped', 'double', 'sizzling', 'peek', 'move', 'pops', 'days', 'party', 'makes', 'sweet', 'chuck', 'person', 'coffee', 'crack', 'stalks', '450', 'roni', 'solution', 'liberally', 'remember', 'equals', 'proof', 'flowers', 'eaten', 'remain', 'electric', 'ounces', 'bar', 'logs', 'correct', 'tortellini', 'without', 'placed', 'regularly', 'greased', 'fix', 'shut', 'vessel', 'dashes', 'hotter', 'trimmings', 'there', 'peel', 'minced', 'hole', 'pumpkin', 'push', 'give', 'purpose', 'rotate', 'syrup', 'invert', 'regular', 'milnot', 'de', 'be', 'shears', 'cloves', 'cayenne', 'diluted', 'gruyere', 'ragu', 'hr', 'shiny', 'golden', 'everything', 'wok', 'bran', 'kiss', 'directly', 'brand', 'indention', 'drinks', 'cooks', 'angel', 'loosen', 'moderate', 'kept', 'brushing', 'containing', 'dishes', 'how', 'storage', 'unroll', 'center', 'assorted', 'steady', 'rather', 'peppercorns', '425', 'ingredient', 'flakes', 'rotelle', 'samuel', '18', 'monterey', 'base', 'cubed', 'particles', 'white', 'bananas', 'draft', 'resembles', 'float', 'clumping', 'fun', 'burgers', 'bourbon', 'lunch', '22', 'rings', 'x', 'breaking', 'nuts', 'jack', 'crumble', 'absorbent', 'walnut', 'browning', 'chives', '7', 'keep', 'guacamole', 'apply', 'tbsp', 'spots', 'parboil', 'label', 'fats', 'maple', 'smash', 'black', 'have', 'just', 'head', 'broiler', 'sit', 'turn', 'pieces', 'sage', 'allowing', 'pronged', 'bite', 'yield', 'soften', 'harden', 'wipe', 'slotted', 'freshly', 'nonfat', 'cubes', 'immediately', 'asparagus', '33', 'scatter', 'lettuce', 'clusters', 'stick', 'biscuits', 'cornbread', 'see', 'stir', 'elephant', 'taco', 'tablespoonfuls', 'leeks', 'often', 'gummy', 'vigorously', 'swirl', 'pizza', 'broil', 'dissolve', 'pinto', 'such', 'prior', 'tear', 'cornflake', 'securely', 'etc', 'anything', 'topped', 'microwavable', 'pretzels', 'candle', 'bagels', 'rivels', '365', 'delicious', 'mill', 'sheet', 'colander', 'frosting', 'f', 'crescent', 'greens', 'spiced', 'pizzas', 'blue', 'topping', 'fast', '40', 'concentrate', 'crunchy', 'grain', 'grocery', 'heaping', 'tupperware', 'lighten', 'mallet', 'generously', 'processor', 'cooked', 'olives', 'marsala', 'time', 'bone', 'bundles', 'surround', 'become', 'everyone', 'preserves', 'pound', 'reused', 'type', 'cuts', 'look', 'resemble', 'xxxx', 'probably', 'confectioners', 'pit', 'broken', 'whole', 'tablespoons', 'shrimp', 'perforations', 'hour', 'veal', 'newspaper', 'skewers', 'gallon', 'potatoes', 'too', 'excess', 'does', 'brisket', 'dredge', 'personal', 'kisses', 'below', 'mushrooms', 'altogether', 'mango', 'enchiladas', 'cracks', 'surface', '45', 'limp', 'find', 'favorite', 'than', 'grill', 'rhubarb', '9x13', 'if', 'layer', '32', 'similar', 'softened', 'individual', 'new', 'island', 'thickens', 'preparing', 'mexican', 'when', 'rapidly', 'sieve', '112', 're', 'uncooked', 'pancake', 'puffs', 'linguine', 'shake', 'lasagne', 'luncheon', 'gelatin', 'aid', 'tostitos', 'steaks', 'garnished', 'lemons', 'fritos', 'closed', 'skinless', 'exactly', 'arrange', 'fold', 'crosswise', 'until', 'crumbs', 'wet', 'oil', 'measuring', 'cereal', 'break', 'something', 'sooner', 'crisp', 'stewed', 'steel', 'goes', '5', 'incorporate', 'handful', 'order', 'second', 'paprika', 'mayo', 'walnuts', 'clean', 'through', 'solid', 'chops', 'uncover', 'bulk', 'called', 'least', 'sauerkraut', 'helps', 'must', 'towels', 'tied', 'germ', 'mostaccioli', 'pistachio', '150', 'dunk', 'will', 'given', 'sticky', 'wings', 'dessert', 'create', 'thicken', 'briefly', 'spatula', 't', 'apricot', 'cucumber', '325', 'al', 'themselves', 'come', 'diet', 'large', 'pimientos', '23', 'taken', 'down', 'appear', 'artificial', 'puffy', 'bones', 'wesson', 'g', 'saucer', 'groundhog', 'week', 'teaspoon', 'don', 'five', 'seasons', 'placing', 'iron', 'rice', 'nearly', 'starts', 'cracklins', 'touching', 'ziti', 'stirred', 'fashioned', 'triangle', 'vent', 'avocados', 'freezer', 'counter', 'oz', 'romaine', 'chipped', 'frost', 'stiffly', 'clove', 'door', 'scallops', 'flowerets', 'country', 'frypan', 'reserving', 'spears', 'icebox', 'cooling', 'degree', 'middle', 'gradually', 'lard', 'burning', 'broccoli', 'reheat', 'pear', 'baste', 'off', 'liners', 'mixing', 'scramble', 'syrupy', 'whip', 'pie', 'dippers', 'fridge', 'simmering', 'icing', 'bowl', 'diameter', 'sprinkling', 'slight', 'ensure', 'decorate', 'pam', 'able', 'fondant', 'wooden', '370', 'while', 'itself', 'can', 'countertop', 'morning', 'excellent', 'layering', 'amaretto', 'high', 'these', 'whiz', 'flaky', 'paste', 'quart', 'nectar', 'away', 'thread', 'oat', 'prebaked', 'stack', 'over', 'peach', 'puffed', 'liquor', 'seem', 'finished', 'doneness', 'plastic', 'squirrel', 'artichoke', 'squash', 'garbanzo', '475', 'appearance', 'potato', 'weeks', 'prep', 'blanched', 'masher', 'toss', 'paper', 'cooker', 'add', 'thaw', 'tinfoil', 'flattened', 'following', 'thickness', 'doritos', 'cookie', 'cut', 'congeal', 'dream', 'intact', 'press', 'start', 'rub', 'nine', 'crabmeat', 'because', 'color', 'butterscotch', 'thicker', 'stirring', 'quarters', 'power', 'may', 'grape', 'scoop', 'cornstarch', 'shapes', 'catsup', 'barely', 'hollowed', 'brownie', 'cups', 'palm', 'strokes', 'frozen', 'jam', 'pecans', 'mein', 'four', 'preparation', 'christmas', 'neck', 'sandwiches', 'cajun', 'contains', 'no', 'loose', 'translucent', 'nut', 'mandarin', 'stone', 'triangles', 'rum', 'hamburger', 'fit', 'later', 'scant', 'lemonade', 'boiling', '15', 'melt', 'boiler', '12', 'quantity', 'inches', 'ritz', 'awful', 'grilled', '<EOS>', 'tortillas', 'sprigs', 'depth', 'chilies', 'helpings', 'items', 'hi', 'by', 'lukewarm', 'width', 'birds', 'pancakes', 'preferred', 'tender', 'butterflied', 'vegetable', 'unbaked', 'envelopes', 'pinch', 'ingredients', 'prunes', 'board', 'tongs', 'spinach', 'kind', 'fudge', 'already', 'which', 'olive', 'box', 'basic', 'each', 'says', 'month', 'bottle', 'pulled', 'oranges', 'approximately', 'holidays', 'turkey', 'pulls', 'stored', 'clings', 'keeps', 'easily', '400', 'crab', 'elbow']\n"
     ]
    }
   ],
   "source": [
    "# calculate word frequency from directions and ingredients list (NER)\n",
    "if pre_processing == True:\n",
    "    directions_word_freq = {}\n",
    "    for i, row in tokenized_ngl_df.iterrows():\n",
    "        for word in row.combined_directions:\n",
    "            directions_word_freq[word] = directions_word_freq.get(word, 0) + 1\n",
    "\n",
    "        for ingredient_list in row.token_NER:\n",
    "            for ingredient in ingredient_list:\n",
    "                directions_word_freq[word] = directions_word_freq.get(word, 0) + 1\n",
    "            \n",
    "    minimum_word_freq = 2\n",
    "    vocab = set()\n",
    "    for word, freq in directions_word_freq.items():\n",
    "        if directions_word_freq[word] >= minimum_word_freq:\n",
    "            vocab.add(word)\n",
    "\n",
    "    print('Unique words before ignoring:', len(directions_word_freq))\n",
    "    print('Unique words after ignoring:', len(vocab))\n",
    "\n",
    "    vocab = list(vocab)\n",
    "    json.dump(vocab, open('./data/vocab.json', 'w'))\n",
    "\n",
    "    print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raisin': 0, 'fitted': 1, 'yams': 2, 'snack': 3, 'wish': 4, 'chutney': 5, 'service': 6, 'hunger': 7, 'pizzelle': 8, 'celery': 9, 'prayer': 10, 'dot': 11, 'headspace': 12, 'chill': 13, 'sprayed': 14, 'faith': 15, 'uv': 16, 'stockpot': 17, 'puddings': 18, '16': 19, 'overnight': 20, 'rim': 21, 'vegies': 22, 'coals': 23, 'atop': 24, 'pepperidge': 25, 'sifting': 26, 'prawns': 27, 'results': 28, 'rind': 29, 'teflon': 30, 'nicely': 31, 'nice': 32, 'caramel': 33, 'sear': 34, 'gets': 35, 'bake': 36, 'water': 37, 'hours': 38, 'knead': 39, 'sprouts': 40, 'dip': 41, 'pumpernickel': 42, 'salads': 43, 'bits': 44, 'reynolds': 45, 'soups': 46, 'tart': 47, 'slaw': 48, 'rolled': 49, 'filled': 50, 'splenda': 51, 'putting': 52, 'cilantro': 53, 'free': 54, 'showers': 55, 'treat': 56, 'veggies': 57, 'cokes': 58, 'clear': 59, 'rosemary': 60, 'halibut': 61, 'chafing': 62, 'sterile': 63, 'directions': 64, 'sealed': 65, 'saving': 66, 'minutes': 67, 'wilted': 68, 'consistency': 69, 'speed': 70, 'coarse': 71, 'combined': 72, '0': 73, 'liquids': 74, 'fill': 75, 'slice': 76, 'flute': 77, 'tin': 78, 'sure': 79, 'tartar': 80, 'seconds': 81, 'crackers': 82, 'burritos': 83, 'spreading': 84, 'vermouth': 85, 'fist': 86, 'starter': 87, 'half': 88, 'pull': 89, 'sticks': 90, 'pitcher': 91, 'kiwi': 92, 'couple': 93, 'sugars': 94, 'tel': 95, 'life': 96, 'confectioner': 97, 'orange': 98, 'hard': 99, 'evaporated': 100, 'stock': 101, 'chilling': 102, 'rinse': 103, 'cleaned': 104, 'butter': 105, 'ro': 106, 'jicama': 107, 'fire': 108, 'crimp': 109, 'adding': 110, 'raise': 111, 'mushy': 112, 'platter': 113, 'powdered': 114, 'oats': 115, 'reserve': 116, 'linguini': 117, 'cocoa': 118, 'tester': 119, 'container': 120, 'bark': 121, 'insides': 122, 'cumin': 123, 'love': 124, 'beat': 125, 'big': 126, 'won': 127, 'seal': 128, 'then': 129, 'crushed': 130, 'addition': 131, 'sheets': 132, 'method': 133, '\\n': 134, 'to': 135, 'cinnamon': 136, 'dish': 137, 'starch': 138, 'grated': 139, 'place': 140, 'cob': 141, 'fall': 142, 'mine': 143, 'original': 144, 'spoon': 145, 'constantly': 146, 'papers': 147, 'rims': 148, 'made': 149, 'sweeter': 150, 'smooth': 151, 'fillets': 152, 'omit': 153, 'fresh': 154, 'teriyaki': 155, 'dirt': 156, 'kindly': 157, 'ale': 158, 'sausage': 159, 'roux': 160, 'takes': 161, 'sauteed': 162, 'hominy': 163, 'enough': 164, 'dash': 165, 'option': 166, 'inserted': 167, 'pick': 168, 'eggs': 169, 'cool': 170, 'end': 171, 'pile': 172, 'rinsed': 173, 'gallons': 174, 'yolk': 175, 'depending': 176, 'hors': 177, 'fits': 178, 'dice': 179, 'spice': 180, 'sugared': 181, 'marinate': 182, 'remove': 183, 'oiled': 184, 'chestnut': 185, 'sized': 186, 'in': 187, 'actually': 188, 'lawry': 189, 'microwave': 190, 'shoyu': 191, 'ketchup': 192, 'work': 193, 'cheeses': 194, 'dark': 195, 'minute': 196, 'crystals': 197, 'corned': 198, 'serves': 199, 'frequently': 200, 'raisins': 201, 'serving': 202, 'preferably': 203, 'cook': 204, 'ovenproof': 205, 'fine': 206, 'works': 207, 'long': 208, 'shallow': 209, 'set': 210, 'zucchini': 211, 'thickest': 212, 'control': 213, 'wax': 214, 'pink': 215, 'metal': 216, 'night': 217, 'what': 218, 'some': 219, 'kraft': 220, 'ricotta': 221, 'rubber': 222, 'dill': 223, 'fairly': 224, 'dogs': 225, 'apple': 226, 'here': 227, 'sprinkles': 228, 'eggbeater': 229, 'instant': 230, 'seed': 231, 'form': 232, 'rise': 233, 'tines': 234, 'fashion': 235, 'tip': 236, 'sprite': 237, 'thoroughly': 238, 'd': 239, 'tots': 240, 'runs': 241, 'beans': 242, 'choice': 243, 'for': 244, '36': 245, 'creamy': 246, 'liking': 247, 'emulsify': 248, 'times': 249, 'dust': 250, 'leftover': 251, 'debone': 252, 'replace': 253, 'delightful': 254, 'rotary': 255, '86': 256, 'beef': 257, 'great': 258, 'low': 259, 'cutter': 260, 'cloth': 261, 'applesauce': 262, 'cooled': 263, 'continue': 264, 'drop': 265, 'sodium': 266, 'loses': 267, 'two': 268, 'been': 269, 'o': 270, 'overbeat': 271, 'whiskey': 272, 'sympathy': 273, 'slab': 274, 'doing': 275, 'scald': 276, 'longer': 277, '55': 278, 'requires': 279, 'up': 280, 'covers': 281, 'thinner': 282, 'rotini': 283, 'tsp': 284, 'browns': 285, 'distribute': 286, 'partly': 287, '120': 288, 'turmeric': 289, 'min': 290, 'thinly': 291, 'yellow': 292, 'blended': 293, 'strainer': 294, 'kindness': 295, 'bundt': 296, 'occasionally': 297, 'mound': 298, 'chocolate': 299, 'light': 300, 'funnel': 301, 'flour': 302, 'extra': 303, 'dried': 304, 'meringue': 305, 'mashed': 306, 'sorrow': 307, 'glaze': 308, 'stars': 309, 'shaking': 310, 'roll': 311, 'normally': 312, 'forming': 313, 'microcook': 314, 'overcook': 315, 'canned': 316, 'tapped': 317, 'lentils': 318, 'loaves': 319, 'buttered': 320, 'leftovers': 321, 'halfway': 322, 'using': 323, 'rabbit': 324, 'feta': 325, 'saran': 326, 'leave': 327, 'oatmeal': 328, '9x9': 329, 'parchment': 330, 'cheez': 331, 'calories': 332, 'ginger': 333, 'section': 334, 'chewy': 335, 'colors': 336, 'points': 337, 'salsa': 338, 'jell': 339, 'enclose': 340, 'step': 341, 'weed': 342, 'runny': 343, 'lid': 344, 'feed': 345, 'dome': 346, 'saved': 347, 'perhaps': 348, '70': 349, 'from': 350, 'purple': 351, 'chili': 352, 'little': 353, 'shell': 354, 'bed': 355, 'core': 356, 'morsels': 357, 'pith': 358, 'secure': 359, 'taste': 360, 'prevent': 361, 'inverted': 362, 'drying': 363, 'squeeze': 364, 'boil': 365, 'frosted': 366, 'slightly': 367, 'melting': 368, 'stew': 369, 'slit': 370, 'shortening': 371, 'souffle': 372, 'pickle': 373, 'molds': 374, 'spoonful': 375, 'among': 376, 'sweeten': 377, 'position': 378, 'variety': 379, 'haddock': 380, 'unpeeled': 381, 'tint': 382, 'pocket': 383, 'machine': 384, 'nonstick': 385, 'chunks': 386, 'preheated': 387, 'hearts': 388, 'shredded': 389, 'catalina': 390, 'legs': 391, 'steadily': 392, 'pulling': 393, 'strawberries': 394, 'according': 395, 'pastry': 396, 'provolone': 397, 'patties': 398, 'saltwater': 399, 'scalded': 400, 'mash': 401, 'lima': 402, 'crumbles': 403, 'steam': 404, 'except': 405, 'save': 406, 'vanilla': 407, 'different': 408, 'pet': 409, 'last': 410, 'seeds': 411, '8ths': 412, 'procedure': 413, 'damp': 414, 'formed': 415, 'noodle': 416, 'bottles': 417, 'dough': 418, 'buy': 419, 'pouring': 420, 'egg': 421, 'lumps': 422, 'stop': 423, 'rounded': 424, 'peaked': 425, 'shaker': 426, 'pattern': 427, 'help': 428, 'spoonfuls': 429, 'tamales': 430, 'plus': 431, 'unsweetened': 432, 'ice': 433, 'servings': 434, 'available': 435, 'gel': 436, 'oven': 437, 'oleo': 438, 'stretch': 439, 'take': 440, 'pepper': 441, 'circular': 442, 'franks': 443, 'pat': 444, '100': 445, 'having': 446, 'complete': 447, 'dampen': 448, 'continuing': 449, 'going': 450, 'changes': 451, 'trays': 452, 'trim': 453, 'about': 454, 'whipping': 455, 'cast': 456, 'quite': 457, 'campbell': 458, '1': 459, 'between': 460, 'first': 461, 'sauces': 462, 'overbake': 463, 'ending': 464, 'tough': 465, 'follows': 466, 'smaller': 467, 'salty': 468, 'golf': 469, 'rows': 470, 'toothpick': 471, 'pecan': 472, 'bag': 473, 'unbeaten': 474, 'moisture': 475, 'touched': 476, 'coat': 477, 'simply': 478, 'tablespoonful': 479, 'sort': 480, 'french': 481, 'pressed': 482, 'american': 483, 'heatproof': 484, 'tightly': 485, 'level': 486, 'cold': 487, 'refrigerate': 488, 'juice': 489, 'tvp': 490, '200': 491, 'good': 492, 'crispy': 493, 'cooking': 494, 'split': 495, 'pointed': 496, 'average': 497, 'flat': 498, 'possible': 499, 'dinner': 500, 'small': 501, 'spices': 502, 'feeds': 503, 'but': 504, 'dissolves': 505, 'centers': 506, 'next': 507, 'ones': 508, 'gives': 509, '13': 510, 'chow': 511, 'spaghetti': 512, 'children': 513, 'lime': 514, 'texture': 515, 'done': 516, 'fried': 517, 'three': 518, 'tops': 519, 'well': 520, 'blot': 521, 'rounds': 522, 'knife': 523, 'bamboo': 524, 'broth': 525, 'touch': 526, 'leaf': 527, 'candied': 528, 'them': 529, 'bags': 530, 'chiles': 531, 'crust': 532, 'vinegar': 533, 'wafers': 534, 'penne': 535, 'approx': 536, 'bottoms': 537, 'six': 538, 'crusts': 539, 'tan': 540, 'lite': 541, 'handling': 542, 'against': 543, '75': 544, 'heated': 545, 'boils': 546, 'separates': 547, 'largest': 548, 'russian': 549, 'apricots': 550, 'string': 551, 'round': 552, 'grind': 553, 'criss': 554, 'okra': 555, 'leak': 556, 'weather': 557, 'standing': 558, 'tossing': 559, 'recipe': 560, 'eating': 561, 'ring': 562, 'age': 563, 'beet': 564, 'with': 565, 'cutters': 566, 'breast': 567, 'semi': 568, 'skim': 569, 'directs': 570, 'cherries': 571, 'removed': 572, 'crescents': 573, 'satisfy': 574, 'chip': 575, 'shape': 576, 'glasses': 577, 'couscous': 578, 'used': 579, 'prefer': 580, 'yummy': 581, 'please': 582, 'season': 583, 'size': 584, 'pressure': 585, 'my': 586, 'begin': 587, '46': 588, 'peppers': 589, 'parties': 590, 'prepared': 591, 'kitchen': 592, 'batch': 593, 'dilute': 594, 'stuffing': 595, 'skillets': 596, 'above': 597, 'separately': 598, 'wheat': 599, 'underside': 600, 'decoration': 601, 'mixer': 602, 'toast': 603, 'lowest': 604, 'peaches': 605, 'pretzel': 606, 'melted': 607, 'radishes': 608, '25': 609, 'slash': 610, 'pretty': 611, 'rotel': 612, 'disappear': 613, 'beets': 614, 'cabbage': 615, 'herb': 616, 'doesn': 617, 'muffin': 618, '500': 619, 'slicing': 620, 'stops': 621, 'tube': 622, 'out': 623, 'teaspoonful': 624, 'quiche': 625, 'twinkies': 626, 'separated': 627, 'stiff': 628, 'creamed': 629, 'qt': 630, 'grinder': 631, 'meats': 632, 'rack': 633, 'leaves': 634, 'c': 635, 'plain': 636, 'same': 637, 'grate': 638, 'coca': 639, 'peeling': 640, 'delicately': 641, 'beer': 642, 'dab': 643, 'return': 644, 'twice': 645, 'thickened': 646, 'almond': 647, 'moderately': 648, 'other': 649, 'toward': 650, 'cores': 651, 'plump': 652, 'divide': 653, 'peaks': 654, 'uncovered': 655, 'garlic': 656, 'sections': 657, 'appetizer': 658, 'flaked': 659, 'floating': 660, 'evaporate': 661, 'envelope': 662, 'becomes': 663, 'pyrex': 664, 'begins': 665, 'yeast': 666, 'firms': 667, 'skin': 668, 'milligrams': 669, '11': 670, 'scrape': 671, 'along': 672, 'mixture': 673, 'moist': 674, 'fluted': 675, 'farm': 676, 'roast': 677, 'jackets': 678, 'poke': 679, 'snow': 680, 'beaters': 681, 'jalapeno': 682, 'only': 683, 'stays': 684, 'package': 685, 'devein': 686, 'close': 687, 'cutlets': 688, 'gather': 689, 'coarsely': 690, 'arugula': 691, 'bath': 692, 'soup': 693, 'grapes': 694, 'usual': 695, 'burner': 696, 'left': 697, 'insert': 698, 'turning': 699, 'extracts': 700, 'star': 701, 'flatter': 702, 'adjust': 703, 'thighs': 704, 'creme': 705, 'protein': 706, 'basil': 707, 'pounds': 708, 'real': 709, 'wrappers': 710, 'whisk': 711, 'heath': 712, 'measured': 713, 'baked': 714, 'stream': 715, 'peak': 716, 'moisten': 717, 'overlapping': 718, 'throughout': 719, 'squeezing': 720, 'this': 721, 'undercooked': 722, 'carton': 723, 'glass': 724, 'jello': 725, 'artichokes': 726, 'depression': 727, 'cheese': 728, 'limburger': 729, 'amber': 730, 'meat': 731, 'sweetened': 732, 'several': 733, 'berries': 734, 'chex': 735, 'casserole': 736, 'pop': 737, 'your': 738, 'salt': 739, '17': 740, 'daily': 741, 'retain': 742, 'refrigerator': 743, 'venison': 744, 'cheddar': 745, 'wine': 746, '275': 747, 'cranberries': 748, 'cookies': 749, 'coloring': 750, 'circles': 751, 'karo': 752, 'gone': 753, 'bringing': 754, 'important': 755, 'settling': 756, 'soaked': 757, 'roses': 758, 'ends': 759, 'pineapple': 760, 'crepes': 761, '64': 762, 'horseradish': 763, 'tomato': 764, 'enchilada': 765, 'towel': 766, 'crockpot': 767, 'advance': 768, 'marshmallow': 769, 'english': 770, 'pudding': 771, 'mg': 772, 'seasonings': 773, 'wire': 774, 'pineapples': 775, 'roasted': 776, 'added': 777, '85': 778, 'main': 779, 'substituted': 780, 'finally': 781, 'rectangular': 782, 'shred': 783, 'allspice': 784, 'grains': 785, 'coke': 786, 'top': 787, 'salmon': 788, 'crumbled': 789, 'pulp': 790, 'cranberry': 791, 'mix': 792, 'pressing': 793, 'raspberry': 794, 'amount': 795, 'follow': 796, 'finely': 797, 'marjoram': 798, 'jelled': 799, 'raspberries': 800, 'salted': 801, 'its': 802, 'again': 803, 'partially': 804, 'right': 805, 'any': 806, 'meanwhile': 807, 'gas': 808, 'cereals': 809, 'blintzes': 810, 'old': 811, 'ball': 812, 'lightly': 813, 'stand': 814, 'kielbasa': 815, 'exchange': 816, 'letting': 817, 'gr': 818, 'even': 819, 'diced': 820, 'dipped': 821, 'really': 822, 'stiffen': 823, 'club': 824, 'rectangles': 825, 'guests': 826, 'pears': 827, 'use': 828, 'ribs': 829, 'whirl': 830, 'stuck': 831, 'tasty': 832, 'another': 833, 'chilled': 834, 'spring': 835, 'disappears': 836, 'we': 837, 'covering': 838, 'portion': 839, 'sprinkled': 840, 'process': 841, 'dew': 842, 'supper': 843, 'v': 844, 'baking': 845, 'steamed': 846, 'pin': 847, 'velveeta': 848, 'navy': 849, '65': 850, 'shaped': 851, 'spray': 852, 'non': 853, 'spread': 854, 'warmer': 855, 'scissors': 856, 'halve': 857, 'pot': 858, 'needed': 859, 'soupy': 860, 'covered': 861, 'savory': 862, 'blade': 863, 'picante': 864, '48': 865, 'desired': 866, 'espresso': 867, 'coating': 868, 'batches': 869, 'stands': 870, 'birthday': 871, 'instructions': 872, 'into': 873, 'glossy': 874, 'angle': 875, 'italian': 876, 'dipping': 877, 'bakon': 878, 'warmed': 879, 'fat': 880, 'coconut': 881, 'braise': 882, 'fingers': 883, 'shells': 884, 'marmalade': 885, 'splashing': 886, 'skillet': 887, 'granulated': 888, 'mini': 889, 'bottom': 890, 'miracle': 891, 'shelf': 892, 'toasted': 893, 'crowd': 894, 'teaspoons': 895, 'grams': 896, '2': 897, 'flame': 898, 'whites': 899, 'saucepot': 900, 'soaking': 901, 'number': 902, '9': 903, 'kraut': 904, 'green': 905, 'deboned': 906, 'side': 907, 'transparent': 908, 'mush': 909, 'poppy': 910, 'popcorn': 911, 'lids': 912, 'i': 913, 'bouillon': 914, 'remains': 915, '13x9': 916, 'home': 917, 'wash': 918, 'palms': 919, 'nutmeg': 920, 'various': 921, 'of': 922, 'ground': 923, 'balls': 924, 'safe': 925, 'completely': 926, 'dots': 927, 'foam': 928, 'bit': 929, 'genesis': 930, 'swiss': 931, 'tail': 932, 'paraffin': 933, 'thawed': 934, '8': 935, 'chips': 936, 'stove': 937, 'oreo': 938, 'store': 939, 'serve': 940, 'punch': 941, 'wrap': 942, 'drops': 943, 'brandy': 944, 'bisquick': 945, 'finish': 946, 'champagne': 947, 'every': 948, 'scrub': 949, 'pints': 950, 'on': 951, 'scraping': 952, 'that': 953, 'hands': 954, 'leaving': 955, 'slices': 956, 'beaten': 957, 'flatten': 958, 'rinsing': 959, 'rises': 960, 'vegetables': 961, 'grease': 962, 'firm': 963, 'blanch': 964, 'bell': 965, 'cakes': 966, 'during': 967, 'knives': 968, 'brussels': 969, 'aside': 970, 'very': 971, 'poultry': 972, 'watch': 973, 'combination': 974, 'after': 975, 'scoops': 976, 'cluster': 977, 'beverages': 978, 'chopper': 979, 'near': 980, 'self': 981, 'oyster': 982, 'flavoring': 983, 'steak': 984, 'moistened': 985, 'crush': 986, 'indirect': 987, 'chopped': 988, 'fitting': 989, 'select': 990, 'cauliflower': 991, 'supreme': 992, 'layers': 993, 'diagonal': 994, 'chocolates': 995, 'crisco': 996, 'go': 997, 'griddle': 998, 'colored': 999, 'fasten': 1000, 'almonds': 1001, 'table': 1002, 'raw': 1003, 'chitterlings': 1004, 'alternating': 1005, 'drained': 1006, 'spreadable': 1007, 'saut': 1008, 'people': 1009, 'ungreased': 1010, 'allow': 1011, 'boiled': 1012, 'sweetener': 1013, 'degrees': 1014, 'oleomargarine': 1015, 'grapefruit': 1016, 'dropping': 1017, 'special': 1018, 'cholesterol': 1019, 'remaining': 1020, 'hot': 1021, 'future': 1022, 'packaged': 1023, 'wedge': 1024, 'piping': 1025, 'enjoy': 1026, 'soda': 1027, 'sandwich': 1028, 'chicken': 1029, 'oblong': 1030, 'thirds': 1031, 'tuck': 1032, 'edges': 1033, 'tiny': 1034, 'vermicelli': 1035, 'bun': 1036, 'patty': 1037, 'around': 1038, 'brine': 1039, 'game': 1040, 'cross': 1041, 'plate': 1042, 'curry': 1043, 'beginning': 1044, 'n': 1045, 'individually': 1046, 'orzo': 1047, 'boneless': 1048, 'are': 1049, 'alone': 1050, 'bread': 1051, 'you': 1052, 'tabasco': 1053, 'mints': 1054, '10x': 1055, 'crusty': 1056, 'meatballs': 1057, 'cornmeal': 1058, 'working': 1059, 'taking': 1060, 'watercress': 1061, 'way': 1062, 'pimentos': 1063, 'within': 1064, 'strip': 1065, 'easy': 1066, 'freezes': 1067, 'discarding': 1068, 'dates': 1069, 'indefinitely': 1070, 'mold': 1071, 'alcohol': 1072, 'crawfish': 1073, 'flours': 1074, 'unwrap': 1075, 'spins': 1076, 'dropped': 1077, 'deep': 1078, 'escape': 1079, 'medium': 1080, 'third': 1081, 'smearing': 1082, 'flake': 1083, 'mint': 1084, 'duty': 1085, 'temperature': 1086, 'ranch': 1087, 'cantaloupe': 1088, 'glazed': 1089, '300': 1090, 'parmesan': 1091, 'exchanges': 1092, 'oregano': 1093, 'absorb': 1094, 'phyllo': 1095, 'crepe': 1096, 'pasta': 1097, 'part': 1098, 'soft': 1099, 'sausages': 1100, 'being': 1101, 'cools': 1102, 'strain': 1103, 'own': 1104, 'realemon': 1105, 'gently': 1106, 'packages': 1107, 'saltine': 1108, 'pint': 1109, 'lower': 1110, 'contents': 1111, 'test': 1112, 'juices': 1113, 'herbs': 1114, 'pepperoni': 1115, 'flower': 1116, 'cup': 1117, 'roaster': 1118, 'amounts': 1119, 'graham': 1120, 'flavors': 1121, 'seasoned': 1122, 'homemade': 1123, 'log': 1124, 'reduce': 1125, 'across': 1126, 'slits': 1127, 'eight': 1128, 'stage': 1129, 'draw': 1130, 'pour': 1131, 'soon': 1132, 'juicy': 1133, 'full': 1134, 'strips': 1135, 'equally': 1136, 'lay': 1137, 'pig': 1138, 'generous': 1139, 'slush': 1140, 'granules': 1141, 'hand': 1142, 'finger': 1143, 'brush': 1144, 'proceed': 1145, 'suit': 1146, 'cutting': 1147, 'floured': 1148, 'twist': 1149, 'now': 1150, 'crumbling': 1151, 'fish': 1152, 'button': 1153, 'as': 1154, 'tastes': 1155, 'wrapper': 1156, 'filling': 1157, 'heavy': 1158, 'gravy': 1159, 'bombs': 1160, 'check': 1161, 'perk': 1162, 'foamy': 1163, 'bars': 1164, 'try': 1165, 'should': 1166, 'cover': 1167, 'smoothness': 1168, 'toppings': 1169, 'salad': 1170, 'scorching': 1171, 'marinade': 1172, 'mace': 1173, 'tray': 1174, 'bacon': 1175, 'much': 1176, 'onions': 1177, 'fork': 1178, 'pimiento': 1179, 'still': 1180, 'hardened': 1181, 'ladle': 1182, 'rolling': 1183, 'mixtures': 1184, 'continually': 1185, 'stuff': 1186, 'avocado': 1187, 'substitute': 1188, 'kettle': 1189, 'truss': 1190, 'pies': 1191, 'rolls': 1192, 'wedges': 1193, 'blueberry': 1194, 'warm': 1195, 'spanish': 1196, 'whipped': 1197, 'fruit': 1198, 'tight': 1199, 'coated': 1200, 'puree': 1201, 'roasting': 1202, 'under': 1203, 'smile': 1204, 'both': 1205, 'fingertips': 1206, 'butterfingers': 1207, 'sliced': 1208, 'cube': 1209, 'lastly': 1210, 'cupcake': 1211, 'blend': 1212, 'shallots': 1213, 'toy': 1214, 'knox': 1215, 'reserved': 1216, 'maraschino': 1217, 'mounds': 1218, 'stem': 1219, 'sets': 1220, 'brownies': 1221, 'tips': 1222, 'hamburgers': 1223, 'bowls': 1224, 'peanut': 1225, 'avoid': 1226, 'thyme': 1227, 'put': 1228, 'muffins': 1229, 'cherry': 1230, 'deviled': 1231, 'fruits': 1232, 'dog': 1233, 'foil': 1234, 'fry': 1235, 'richer': 1236, 'better': 1237, 'fully': 1238, 'best': 1239, 'congealed': 1240, 'early': 1241, 'kahlua': 1242, 'looks': 1243, 'dividing': 1244, 'smoke': 1245, 'liqueur': 1246, 'croutons': 1247, 'grits': 1248, 'inch': 1249, 'onion': 1250, 'months': 1251, 'noodles': 1252, 'horizontally': 1253, 'want': 1254, 'pkg': 1255, 'sauce': 1256, 'molasses': 1257, 'sifted': 1258, 'opaque': 1259, 'll': 1260, 'zest': 1261, 'quick': 1262, 'hershey': 1263, 'flavored': 1264, 'reduced': 1265, 'thick': 1266, 'baby': 1267, 'sealing': 1268, 'line': 1269, 'skewer': 1270, 'tater': 1271, 'filo': 1272, 'mustard': 1273, 'was': 1274, 'cake': 1275, 'till': 1276, 'ziploc': 1277, 'rock': 1278, 'loosely': 1279, 'hollow': 1280, 'caraway': 1281, 'cider': 1282, 'condensed': 1283, 'inside': 1284, 'sweat': 1285, 'anise': 1286, 'browned': 1287, 'stay': 1288, 'chowder': 1289, 'doubled': 1290, '80': 1291, 'all': 1292, 'freeze': 1293, 'steep': 1294, 'more': 1295, 'would': 1296, 'plates': 1297, 'airtight': 1298, 'lamb': 1299, 'lumpy': 1300, 'it': 1301, 'collards': 1302, 'cocktail': 1303, 'breading': 1304, 'most': 1305, 'strings': 1306, 'tie': 1307, 'elastic': 1308, 'freezing': 1309, 'slide': 1310, '240': 1311, 'precooked': 1312, 'less': 1313, 'omitted': 1314, 'ladyfingers': 1315, 'halves': 1316, 'prepare': 1317, 'bird': 1318, 'strawberry': 1319, 'absorbed': 1320, 'dump': 1321, 'sterilize': 1322, '90': 1323, 'so': 1324, 'sour': 1325, 'handle': 1326, 'awhile': 1327, 'quarter': 1328, 'banana': 1329, 'mince': 1330, 'wafer': 1331, 'bubble': 1332, 'liver': 1333, 'carefully': 1334, 'diagonally': 1335, 'style': 1336, 's': 1337, '3': 1338, 'keeping': 1339, 'hang': 1340, 'family': 1341, 'solids': 1342, 'quickly': 1343, 'butterfly': 1344, 'maximum': 1345, 'needs': 1346, 'or': 1347, 'giblets': 1348, '6': 1349, 'per': 1350, 'sugar': 1351, 'balance': 1352, 'melts': 1353, 'directed': 1354, 'day': 1355, 'kettles': 1356, 'liquid': 1357, 'circle': 1358, 'choose': 1359, 'opening': 1360, 'evenly': 1361, 'hens': 1362, 'pack': 1363, 'sunflower': 1364, 'sesame': 1365, 'quarts': 1366, 'candies': 1367, 'wait': 1368, 'carrot': 1369, 'reaches': 1370, 'open': 1371, 'p': 1372, 'buttermilk': 1373, 'tall': 1374, 'holes': 1375, 'decorating': 1376, 'removing': 1377, 'garnish': 1378, 'crank': 1379, 'cucumbers': 1380, 'cola': 1381, 'yum': 1382, 'not': 1383, 'peas': 1384, 'figs': 1385, 'racks': 1386, 'closely': 1387, 'one': 1388, 'undrained': 1389, 'powder': 1390, 'loaf': 1391, 'dente': 1392, 'macaroni': 1393, 'crumb': 1394, 'motion': 1395, 'pimento': 1396, 'deer': 1397, 'cracked': 1398, 'tails': 1399, 'eagle': 1400, 'pickles': 1401, 'wanted': 1402, 'combine': 1403, 'their': 1404, 'mouth': 1405, 'onto': 1406, 'trifle': 1407, 'rest': 1408, 'decorative': 1409, 'extremely': 1410, 'once': 1411, 'sift': 1412, 'simmer': 1413, '10': 1414, 'easier': 1415, 'larger': 1416, 'mug': 1417, 'outer': 1418, 'soak': 1419, 'melba': 1420, 'seasoning': 1421, 'relish': 1422, 'cornflakes': 1423, 'bubbles': 1424, 'sides': 1425, 'jar': 1426, 'waxed': 1427, 'hold': 1428, 'dissolved': 1429, 'always': 1430, 'pats': 1431, 'maybe': 1432, 'parts': 1433, 'run': 1434, 'flank': 1435, 'sticking': 1436, 'seams': 1437, 'fries': 1438, 'group': 1439, 'sprinkle': 1440, 'chop': 1441, 'upon': 1442, 'corns': 1443, 'tortilla': 1444, 'heat': 1445, 'lot': 1446, 'lots': 1447, 'fettuccine': 1448, 'winter': 1449, 'puff': 1450, 'reheated': 1451, 'either': 1452, 'ripe': 1453, 'corn': 1454, 'mixed': 1455, 'the': 1456, 'cracker': 1457, 'tuna': 1458, 'stems': 1459, 'purchased': 1460, 'chunk': 1461, 'rich': 1462, 'additional': 1463, 'firmly': 1464, 'tins': 1465, 'crock': 1466, 'clams': 1467, 'almost': 1468, 'continuously': 1469, 'mayonnaise': 1470, 'ahead': 1471, 'pureed': 1472, 'breakfast': 1473, '1st': 1474, 'drink': 1475, 'human': 1476, 'served': 1477, 'making': 1478, 'preference': 1479, 'canning': 1480, 'slowly': 1481, 'many': 1482, 'lined': 1483, '24': 1484, 'peanuts': 1485, 'lasts': 1486, 'never': 1487, 'basting': 1488, 'hamburg': 1489, 'kool': 1490, 'oeuvre': 1491, 'careful': 1492, 'tarragon': 1493, 'they': 1494, 'room': 1495, 'undiluted': 1496, 'bubbling': 1497, 'cole': 1498, 'necessary': 1499, 'pans': 1500, 'volume': 1501, 'anchor': 1502, 'miniature': 1503, 'sherry': 1504, 'membranes': 1505, 'thousand': 1506, 'rye': 1507, 'boned': 1508, 'mugs': 1509, 'transfer': 1510, 'caramels': 1511, 'parsley': 1512, '4': 1513, 'frankfurters': 1514, 'scrambled': 1515, 'chunked': 1516, 'dozen': 1517, 'squares': 1518, 'forms': 1519, 'tapioca': 1520, 'dollop': 1521, 'evaporates': 1522, 'caps': 1523, 'checking': 1524, 'lean': 1525, 'tears': 1526, 'repeat': 1527, 'lasagna': 1528, 'a': 1529, 'persimmon': 1530, 'cashews': 1531, 'square': 1532, 'seems': 1533, 'throw': 1534, '35': 1535, 'crumbly': 1536, 'gloss': 1537, 'allowed': 1538, 'dry': 1539, 'release': 1540, 'back': 1541, 'ramen': 1542, 'seam': 1543, 'florets': 1544, 'whatever': 1545, 'upside': 1546, 'hash': 1547, 'mixes': 1548, 'unmold': 1549, 'sterilized': 1550, 'halved': 1551, 'rectangle': 1552, 'food': 1553, 'spoke': 1554, 'spoons': 1555, 'paint': 1556, 'worcestershire': 1557, 'tea': 1558, 'drain': 1559, 'luke': 1560, 'tap': 1561, 'tomatoes': 1562, 'batter': 1563, 'measure': 1564, 'poured': 1565, 'packet': 1566, 'bay': 1567, 'mocha': 1568, 'total': 1569, '20': 1570, 'sun': 1571, 'smoked': 1572, 'need': 1573, 'pickling': 1574, 'cheesecloth': 1575, 'usually': 1576, 'thermometer': 1577, 'ham': 1578, 'shows': 1579, 'pea': 1580, 'edge': 1581, 'spiral': 1582, 'soy': 1583, 'thickening': 1584, 'springs': 1585, 'pheasant': 1586, 'beater': 1587, 'few': 1588, 'comes': 1589, 'slow': 1590, 'oreos': 1591, 'discard': 1592, 'sink': 1593, 'waffles': 1594, 'marshmallows': 1595, '375': 1596, 'skins': 1597, 'clam': 1598, 'remainder': 1599, 'resistant': 1600, 'equal': 1601, 'flavorings': 1602, 'optional': 1603, 'ounce': 1604, 'barbecue': 1605, 'thumb': 1606, 'like': 1607, 'beating': 1608, 'jars': 1609, '14': 1610, 'toothpicks': 1611, 'church': 1612, 'building': 1613, 'outside': 1614, 'pliable': 1615, 'custard': 1616, 'chestnuts': 1617, 'pork': 1618, 'blender': 1619, 'lengthwise': 1620, 'had': 1621, 'overmix': 1622, 'bean': 1623, 'breadcrumbs': 1624, 'running': 1625, 'lift': 1626, 'tossed': 1627, 'blossoms': 1628, 'saute': 1629, 'single': 1630, 'blackberries': 1631, 'red': 1632, 'creaming': 1633, 'drizzle': 1634, 'coats': 1635, 'cupcakes': 1636, 'jelly': 1637, 'nutmeats': 1638, 'holds': 1639, 'scallions': 1640, 'bring': 1641, '60': 1642, 'dutch': 1643, 'empty': 1644, 'seafood': 1645, 'cottage': 1646, 'turns': 1647, 'manufacturer': 1648, 'gentle': 1649, 'crunch': 1650, 'capers': 1651, 'increase': 1652, 'accent': 1653, 'oval': 1654, 'aluminum': 1655, 'garnishes': 1656, 'joy': 1657, 'upright': 1658, '50': 1659, 'has': 1660, '350': 1661, 'kneading': 1662, 'setting': 1663, 'before': 1664, 'pan': 1665, 'flavor': 1666, 'rotating': 1667, 'drippings': 1668, 'block': 1669, 'corners': 1670, 'followed': 1671, 'desire': 1672, 'carrots': 1673, 'air': 1674, 'extract': 1675, 'piece': 1676, '130': 1677, 'mountain': 1678, 'fluffy': 1679, 'field': 1680, '30': 1681, 'portions': 1682, '234': 1683, 'preheating': 1684, 'yogurt': 1685, 'eat': 1686, 'refrigerated': 1687, 'make': 1688, 'ready': 1689, 'score': 1690, 'pale': 1691, 'blending': 1692, 'child': 1693, 'dumplings': 1694, 'yields': 1695, 'peeled': 1696, 'stuffed': 1697, 'jellyroll': 1698, 'holding': 1699, 'meal': 1700, 'washed': 1701, 'gelatine': 1702, 'candy': 1703, 'mozzarella': 1704, 'could': 1705, 'taffy': 1706, 'an': 1707, 'alum': 1708, 'dressing': 1709, 'basket': 1710, 'change': 1711, 'including': 1712, 'chinese': 1713, 'point': 1714, '250': 1715, 'alternate': 1716, 'fryer': 1717, 'brown': 1718, 'frothy': 1719, 'get': 1720, 'listed': 1721, 'eggplant': 1722, 'and': 1723, 'wide': 1724, 'baker': 1725, 'row': 1726, 'buns': 1727, 'tofu': 1728, 'm': 1729, '2nd': 1730, 'shellfish': 1731, 'sherbet': 1732, 'starting': 1733, 'sharp': 1734, 'curdle': 1735, 'pectin': 1736, 'containers': 1737, 'bubbly': 1738, 'marble': 1739, 'note': 1740, 'krispies': 1741, 'cream': 1742, 'heating': 1743, 'frying': 1744, 'burn': 1745, 'bakes': 1746, 'those': 1747, 'margarine': 1748, 'wieners': 1749, 'popped': 1750, 'let': 1751, 'together': 1752, 'folding': 1753, 'consomme': 1754, 'bigger': 1755, 'narrow': 1756, 'milk': 1757, 'alternately': 1758, 'biscuit': 1759, 'worms': 1760, 'apart': 1761, 'breasts': 1762, 'breads': 1763, 'pare': 1764, 'lengths': 1765, 'teaspoonfuls': 1766, 'at': 1767, 'thin': 1768, 'refried': 1769, 'prick': 1770, 'oysters': 1771, 'kidney': 1772, 'wild': 1773, 'blueberries': 1774, 'entire': 1775, 'preheat': 1776, 'nacho': 1777, 'shoulder': 1778, 'separate': 1779, 'honey': 1780, 'spooned': 1781, 'is': 1782, 'cans': 1783, 'apples': 1784, 'also': 1785, 'saucepan': 1786, 'mushroom': 1787, 'lemon': 1788, 'instead': 1789, 'tablespoon': 1790, 'yolks': 1791, 'turned': 1792, 'tests': 1793, 'kids': 1794, 'do': 1795, 'wrapped': 1796, 'double': 1797, 'sizzling': 1798, 'peek': 1799, 'move': 1800, 'pops': 1801, 'days': 1802, 'party': 1803, 'makes': 1804, 'sweet': 1805, 'chuck': 1806, 'person': 1807, 'coffee': 1808, 'crack': 1809, 'stalks': 1810, '450': 1811, 'roni': 1812, 'solution': 1813, 'liberally': 1814, 'remember': 1815, 'equals': 1816, 'proof': 1817, 'flowers': 1818, 'eaten': 1819, 'remain': 1820, 'electric': 1821, 'ounces': 1822, 'bar': 1823, 'logs': 1824, 'correct': 1825, 'tortellini': 1826, 'without': 1827, 'placed': 1828, 'regularly': 1829, 'greased': 1830, 'fix': 1831, 'shut': 1832, 'vessel': 1833, 'dashes': 1834, 'hotter': 1835, 'trimmings': 1836, 'there': 1837, 'peel': 1838, 'minced': 1839, 'hole': 1840, 'pumpkin': 1841, 'push': 1842, 'give': 1843, 'purpose': 1844, 'rotate': 1845, 'syrup': 1846, 'invert': 1847, 'regular': 1848, 'milnot': 1849, 'de': 1850, 'be': 1851, 'shears': 1852, 'cloves': 1853, 'cayenne': 1854, 'diluted': 1855, 'gruyere': 1856, 'ragu': 1857, 'hr': 1858, 'shiny': 1859, 'golden': 1860, 'everything': 1861, 'wok': 1862, 'bran': 1863, 'kiss': 1864, 'directly': 1865, 'brand': 1866, 'indention': 1867, 'drinks': 1868, 'cooks': 1869, 'angel': 1870, 'loosen': 1871, 'moderate': 1872, 'kept': 1873, 'brushing': 1874, 'containing': 1875, 'dishes': 1876, 'how': 1877, 'storage': 1878, 'unroll': 1879, 'center': 1880, 'assorted': 1881, 'steady': 1882, 'rather': 1883, 'peppercorns': 1884, '425': 1885, 'ingredient': 1886, 'flakes': 1887, 'rotelle': 1888, 'samuel': 1889, '18': 1890, 'monterey': 1891, 'base': 1892, 'cubed': 1893, 'particles': 1894, 'white': 1895, 'bananas': 1896, 'draft': 1897, 'resembles': 1898, 'float': 1899, 'clumping': 1900, 'fun': 1901, 'burgers': 1902, 'bourbon': 1903, 'lunch': 1904, '22': 1905, 'rings': 1906, 'x': 1907, 'breaking': 1908, 'nuts': 1909, 'jack': 1910, 'crumble': 1911, 'absorbent': 1912, 'walnut': 1913, 'browning': 1914, 'chives': 1915, '7': 1916, 'keep': 1917, 'guacamole': 1918, 'apply': 1919, 'tbsp': 1920, 'spots': 1921, 'parboil': 1922, 'label': 1923, 'fats': 1924, 'maple': 1925, 'smash': 1926, 'black': 1927, 'have': 1928, 'just': 1929, 'head': 1930, 'broiler': 1931, 'sit': 1932, 'turn': 1933, 'pieces': 1934, 'sage': 1935, 'allowing': 1936, 'pronged': 1937, 'bite': 1938, 'yield': 1939, 'soften': 1940, 'harden': 1941, 'wipe': 1942, 'slotted': 1943, 'freshly': 1944, 'nonfat': 1945, 'cubes': 1946, 'immediately': 1947, 'asparagus': 1948, '33': 1949, 'scatter': 1950, 'lettuce': 1951, 'clusters': 1952, 'stick': 1953, 'biscuits': 1954, 'cornbread': 1955, 'see': 1956, 'stir': 1957, 'elephant': 1958, 'taco': 1959, 'tablespoonfuls': 1960, 'leeks': 1961, 'often': 1962, 'gummy': 1963, 'vigorously': 1964, 'swirl': 1965, 'pizza': 1966, 'broil': 1967, 'dissolve': 1968, 'pinto': 1969, 'such': 1970, 'prior': 1971, 'tear': 1972, 'cornflake': 1973, 'securely': 1974, 'etc': 1975, 'anything': 1976, 'topped': 1977, 'microwavable': 1978, 'pretzels': 1979, 'candle': 1980, 'bagels': 1981, 'rivels': 1982, '365': 1983, 'delicious': 1984, 'mill': 1985, 'sheet': 1986, 'colander': 1987, 'frosting': 1988, 'f': 1989, 'crescent': 1990, 'greens': 1991, 'spiced': 1992, 'pizzas': 1993, 'blue': 1994, 'topping': 1995, 'fast': 1996, '40': 1997, 'concentrate': 1998, 'crunchy': 1999, 'grain': 2000, 'grocery': 2001, 'heaping': 2002, 'tupperware': 2003, 'lighten': 2004, 'mallet': 2005, 'generously': 2006, 'processor': 2007, 'cooked': 2008, 'olives': 2009, 'marsala': 2010, 'time': 2011, 'bone': 2012, 'bundles': 2013, 'surround': 2014, 'become': 2015, 'everyone': 2016, 'preserves': 2017, 'pound': 2018, 'reused': 2019, 'type': 2020, 'cuts': 2021, 'look': 2022, 'resemble': 2023, 'xxxx': 2024, 'probably': 2025, 'confectioners': 2026, 'pit': 2027, 'broken': 2028, 'whole': 2029, 'tablespoons': 2030, 'shrimp': 2031, 'perforations': 2032, 'hour': 2033, 'veal': 2034, 'newspaper': 2035, 'skewers': 2036, 'gallon': 2037, 'potatoes': 2038, 'too': 2039, 'excess': 2040, 'does': 2041, 'brisket': 2042, 'dredge': 2043, 'personal': 2044, 'kisses': 2045, 'below': 2046, 'mushrooms': 2047, 'altogether': 2048, 'mango': 2049, 'enchiladas': 2050, 'cracks': 2051, 'surface': 2052, '45': 2053, 'limp': 2054, 'find': 2055, 'favorite': 2056, 'than': 2057, 'grill': 2058, 'rhubarb': 2059, '9x13': 2060, 'if': 2061, 'layer': 2062, '32': 2063, 'similar': 2064, 'softened': 2065, 'individual': 2066, 'new': 2067, 'island': 2068, 'thickens': 2069, 'preparing': 2070, 'mexican': 2071, 'when': 2072, 'rapidly': 2073, 'sieve': 2074, '112': 2075, 're': 2076, 'uncooked': 2077, 'pancake': 2078, 'puffs': 2079, 'linguine': 2080, 'shake': 2081, 'lasagne': 2082, 'luncheon': 2083, 'gelatin': 2084, 'aid': 2085, 'tostitos': 2086, 'steaks': 2087, 'garnished': 2088, 'lemons': 2089, 'fritos': 2090, 'closed': 2091, 'skinless': 2092, 'exactly': 2093, 'arrange': 2094, 'fold': 2095, 'crosswise': 2096, 'until': 2097, 'crumbs': 2098, 'wet': 2099, 'oil': 2100, 'measuring': 2101, 'cereal': 2102, 'break': 2103, 'something': 2104, 'sooner': 2105, 'crisp': 2106, 'stewed': 2107, 'steel': 2108, 'goes': 2109, '5': 2110, 'incorporate': 2111, 'handful': 2112, 'order': 2113, 'second': 2114, 'paprika': 2115, 'mayo': 2116, 'walnuts': 2117, 'clean': 2118, 'through': 2119, 'solid': 2120, 'chops': 2121, 'uncover': 2122, 'bulk': 2123, 'called': 2124, 'least': 2125, 'sauerkraut': 2126, 'helps': 2127, 'must': 2128, 'towels': 2129, 'tied': 2130, 'germ': 2131, 'mostaccioli': 2132, 'pistachio': 2133, '150': 2134, 'dunk': 2135, 'will': 2136, 'given': 2137, 'sticky': 2138, 'wings': 2139, 'dessert': 2140, 'create': 2141, 'thicken': 2142, 'briefly': 2143, 'spatula': 2144, 't': 2145, 'apricot': 2146, 'cucumber': 2147, '325': 2148, 'al': 2149, 'themselves': 2150, 'come': 2151, 'diet': 2152, 'large': 2153, 'pimientos': 2154, '23': 2155, 'taken': 2156, 'down': 2157, 'appear': 2158, 'artificial': 2159, 'puffy': 2160, 'bones': 2161, 'wesson': 2162, 'g': 2163, 'saucer': 2164, 'groundhog': 2165, 'week': 2166, 'teaspoon': 2167, 'don': 2168, 'five': 2169, 'seasons': 2170, 'placing': 2171, 'iron': 2172, 'rice': 2173, 'nearly': 2174, 'starts': 2175, 'cracklins': 2176, 'touching': 2177, 'ziti': 2178, 'stirred': 2179, 'fashioned': 2180, 'triangle': 2181, 'vent': 2182, 'avocados': 2183, 'freezer': 2184, 'counter': 2185, 'oz': 2186, 'romaine': 2187, 'chipped': 2188, 'frost': 2189, 'stiffly': 2190, 'clove': 2191, 'door': 2192, 'scallops': 2193, 'flowerets': 2194, 'country': 2195, 'frypan': 2196, 'reserving': 2197, 'spears': 2198, 'icebox': 2199, 'cooling': 2200, 'degree': 2201, 'middle': 2202, 'gradually': 2203, 'lard': 2204, 'burning': 2205, 'broccoli': 2206, 'reheat': 2207, 'pear': 2208, 'baste': 2209, 'off': 2210, 'liners': 2211, 'mixing': 2212, 'scramble': 2213, 'syrupy': 2214, 'whip': 2215, 'pie': 2216, 'dippers': 2217, 'fridge': 2218, 'simmering': 2219, 'icing': 2220, 'bowl': 2221, 'diameter': 2222, 'sprinkling': 2223, 'slight': 2224, 'ensure': 2225, 'decorate': 2226, 'pam': 2227, 'able': 2228, 'fondant': 2229, 'wooden': 2230, '370': 2231, 'while': 2232, 'itself': 2233, 'can': 2234, 'countertop': 2235, 'morning': 2236, 'excellent': 2237, 'layering': 2238, 'amaretto': 2239, 'high': 2240, 'these': 2241, 'whiz': 2242, 'flaky': 2243, 'paste': 2244, 'quart': 2245, 'nectar': 2246, 'away': 2247, 'thread': 2248, 'oat': 2249, 'prebaked': 2250, 'stack': 2251, 'over': 2252, 'peach': 2253, 'puffed': 2254, 'liquor': 2255, 'seem': 2256, 'finished': 2257, 'doneness': 2258, 'plastic': 2259, 'squirrel': 2260, 'artichoke': 2261, 'squash': 2262, 'garbanzo': 2263, '475': 2264, 'appearance': 2265, 'potato': 2266, 'weeks': 2267, 'prep': 2268, 'blanched': 2269, 'masher': 2270, 'toss': 2271, 'paper': 2272, 'cooker': 2273, 'add': 2274, 'thaw': 2275, 'tinfoil': 2276, 'flattened': 2277, 'following': 2278, 'thickness': 2279, 'doritos': 2280, 'cookie': 2281, 'cut': 2282, 'congeal': 2283, 'dream': 2284, 'intact': 2285, 'press': 2286, 'start': 2287, 'rub': 2288, 'nine': 2289, 'crabmeat': 2290, 'because': 2291, 'color': 2292, 'butterscotch': 2293, 'thicker': 2294, 'stirring': 2295, 'quarters': 2296, 'power': 2297, 'may': 2298, 'grape': 2299, 'scoop': 2300, 'cornstarch': 2301, 'shapes': 2302, 'catsup': 2303, 'barely': 2304, 'hollowed': 2305, 'brownie': 2306, 'cups': 2307, 'palm': 2308, 'strokes': 2309, 'frozen': 2310, 'jam': 2311, 'pecans': 2312, 'mein': 2313, 'four': 2314, 'preparation': 2315, 'christmas': 2316, 'neck': 2317, 'sandwiches': 2318, 'cajun': 2319, 'contains': 2320, 'no': 2321, 'loose': 2322, 'translucent': 2323, 'nut': 2324, 'mandarin': 2325, 'stone': 2326, 'triangles': 2327, 'rum': 2328, 'hamburger': 2329, 'fit': 2330, 'later': 2331, 'scant': 2332, 'lemonade': 2333, 'boiling': 2334, '15': 2335, 'melt': 2336, 'boiler': 2337, '12': 2338, 'quantity': 2339, 'inches': 2340, 'ritz': 2341, 'awful': 2342, 'grilled': 2343, '<EOS>': 2344, 'tortillas': 2345, 'sprigs': 2346, 'depth': 2347, 'chilies': 2348, 'helpings': 2349, 'items': 2350, 'hi': 2351, 'by': 2352, 'lukewarm': 2353, 'width': 2354, 'birds': 2355, 'pancakes': 2356, 'preferred': 2357, 'tender': 2358, 'butterflied': 2359, 'vegetable': 2360, 'unbaked': 2361, 'envelopes': 2362, 'pinch': 2363, 'ingredients': 2364, 'prunes': 2365, 'board': 2366, 'tongs': 2367, 'spinach': 2368, 'kind': 2369, 'fudge': 2370, 'already': 2371, 'which': 2372, 'olive': 2373, 'box': 2374, 'basic': 2375, 'each': 2376, 'says': 2377, 'month': 2378, 'bottle': 2379, 'pulled': 2380, 'oranges': 2381, 'approximately': 2382, 'holidays': 2383, 'turkey': 2384, 'pulls': 2385, 'stored': 2386, 'clings': 2387, 'keeps': 2388, 'easily': 2389, '400': 2390, 'crab': 2391, 'elbow': 2392}\n"
     ]
    }
   ],
   "source": [
    "# store vocab into a .json file\n",
    "vocab = json.load(open('./data/vocab.json', 'r'))\n",
    "vocab_stoi = {s: i for i, s in enumerate(vocab)}\n",
    "vocab_itos = {i: s for i, s in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab_stoi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[311, 984, 1135, 187, 302, 134, 1718, 187, 887, 134, 739, 1723, 441, 134, 1403, 764, 1357, 37, 1177, 1723, 1287, 984, 1167, 1723, 1413, 244, 1388, 1723, 1529, 1328, 38, 134, 2122, 1723, 1957, 187, 1557, 1256, 134, 2274, 1562, 905, 589, 1723, 1413, 244, 2110, 67, 134, 940, 2252, 1021, 2008, 2173, 134, 2344]\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    indexed_directions = []\n",
    "    for i, row in tokenized_ngl_df.iterrows():\n",
    "        direction = []\n",
    "        for word in row.combined_directions:\n",
    "            if word in vocab:\n",
    "                direction.append(vocab_stoi[word])\n",
    "        indexed_directions.append(direction)\n",
    "        \n",
    "    print(indexed_directions[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1562, 37, 1177, 1557, 1256, 905, 589, 2100]\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    indexed_ingredients = []\n",
    "    for i, row in tokenized_ngl_df.iterrows():\n",
    "        ingredients = []\n",
    "        for ingredient_list in row.token_NER:\n",
    "            for word in ingredient_list:\n",
    "                if word in vocab:\n",
    "                    ingredients.append(vocab_stoi[word])\n",
    "        indexed_ingredients.append(ingredients)\n",
    "        \n",
    "    print(indexed_ingredients[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    indexed_ngl_df = pd.DataFrame({'directions': indexed_directions, 'ingredients': indexed_ingredients})\n",
    "    indexed_ngl_df.to_json('./data/indexed_ngl.json')\n",
    "    \n",
    "indexed_ngl_df = pd.read_json('./data/indexed_ngl.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[187, 1529, 1158, 897, 2245, 1786, 792, 1718, ...</td>\n",
       "      <td>[1718, 1351, 1757, 407, 1909, 105, 1938, 584, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[140, 2188, 257, 951, 890, 922, 845, 137, 134,...</td>\n",
       "      <td>[257, 1029, 1762, 1742, 922, 1787, 693, 1325, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[187, 1529, 1590, 2273, 1403, 1292, 2364, 1167...</td>\n",
       "      <td>[2310, 1454, 1742, 728, 105, 656, 1390, 739, 441]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  [187, 1529, 1158, 897, 2245, 1786, 792, 1718, ...   \n",
       "1  [140, 2188, 257, 951, 890, 922, 845, 137, 134,...   \n",
       "2  [187, 1529, 1590, 2273, 1403, 1292, 2364, 1167...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [1718, 1351, 1757, 407, 1909, 105, 1938, 584, ...  \n",
       "1  [257, 1029, 1762, 1742, 922, 1787, 693, 1325, ...  \n",
       "2  [2310, 1454, 1742, 728, 105, 656, 1390, 739, 441]  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_ngl_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction Character Vocabulary\n",
    "For the baseline model, a character based vocabulary will be used instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ', '\\n', '<EOS>']\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '0': 26, '1': 27, '2': 28, '3': 29, '4': 30, '5': 31, '6': 32, '7': 33, '8': 34, '9': 35, ' ': 36, '\\n': 37, '<EOS>': 38}\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    char_vocab = list(string.ascii_lowercase) + list(string.digits) + [' ', '\\n', '<EOS>']\n",
    "    json.dump(char_vocab, open('./data/char_vocab.json', 'w'))\n",
    "char_vocab = json.load(open('./data/char_vocab.json', 'r'))\n",
    "char_vocab_stoi = {s: i for i, s in enumerate(char_vocab)}\n",
    "char_vocab_itos = {i: s for i, s in enumerate(char_vocab)}\n",
    "char_vocab_size = len(vocab)\n",
    "print(char_vocab)\n",
    "print(char_vocab_stoi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token to Character Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 14, 11, 11, 36, 18, 19, 4, 0, 10, 36, 18, 19, 17, 8, 15, 18, 36, 8, 13, 36, 5, 11, 14, 20, 17, 36, 37, 1, 17, 14, 22, 13, 36, 8, 13, 36, 18, 10, 8, 11, 11, 4, 19, 36, 37, 18, 0, 11, 19, 36, 0, 13, 3, 36, 15, 4, 15, 15, 4, 17, 36, 37, 2, 14, 12, 1, 8, 13, 4, 36, 19, 14, 12, 0, 19, 14, 36, 11, 8, 16, 20, 8, 3, 36, 22, 0, 19, 4, 17, 36, 14, 13, 8, 14, 13, 18, 36, 0, 13, 3, 36, 1, 17, 14, 22, 13, 4, 3, 36, 18, 19, 4, 0, 10, 36, 2, 14, 21, 4, 17, 36, 0, 13, 3, 36, 18, 8, 12, 12, 4, 17, 36, 5, 14, 17, 36, 14, 13, 4, 36, 0, 13, 3, 36, 0, 36, 16, 20, 0, 17, 19, 4, 17, 36, 7, 14, 20, 17, 18, 36, 37, 20, 13, 2, 14, 21, 4, 17, 36, 0, 13, 3, 36, 18, 19, 8, 17, 36, 8, 13, 36, 22, 14, 17, 2, 4, 18, 19, 4, 17, 18, 7, 8, 17, 4, 36, 18, 0, 20, 2, 4, 36, 37, 0, 3, 3, 36, 19, 14, 12, 0, 19, 14, 4, 18, 36, 6, 17, 4, 4, 13, 36, 15, 4, 15, 15, 4, 17, 18, 36, 0, 13, 3, 36, 18, 8, 12, 12, 4, 17, 36, 5, 14, 17, 36, 31, 36, 12, 8, 13, 20, 19, 4, 18, 36, 37, 18, 4, 17, 21, 4, 36, 14, 21, 4, 17, 36, 7, 14, 19, 36, 2, 14, 14, 10, 4, 3, 36, 17, 8, 2, 4, 36, 37, 38]\n",
      "'r''o''l''l'' ''s''t''e''a''k'' ''s''t''r''i''p''s'' ''i''n'' ''f''l''o''u''r'' ''\\n''b''r''o''w''n'' ''i''n'' ''s''k''i''l''l''e''t'' ''\\n''s''a''l''t'' ''a''n''d'' ''p''e''p''p''e''r'' ''\\n''c''o''m''b''i''n''e'' ''t''o''m''a''t''o'' ''l''i''q''u''i''d'' ''w''a''t''e''r'' ''o''n''i''o''n''s'' ''a''n''d'' ''b''r''o''w''n''e''d'' ''s''t''e''a''k'' ''c''o''v''e''r'' ''a''n''d'' ''s''i''m''m''e''r'' ''f''o''r'' ''o''n''e'' ''a''n''d'' ''a'' ''q''u''a''r''t''e''r'' ''h''o''u''r''s'' ''\\n''u''n''c''o''v''e''r'' ''a''n''d'' ''s''t''i''r'' ''i''n'' ''w''o''r''c''e''s''t''e''r''s''h''i''r''e'' ''s''a''u''c''e'' ''\\n''a''d''d'' ''t''o''m''a''t''o''e''s'' ''g''r''e''e''n'' ''p''e''p''p''e''r''s'' ''a''n''d'' ''s''i''m''m''e''r'' ''f''o''r'' ''5'' ''m''i''n''u''t''e''s'' ''\\n''s''e''r''v''e'' ''o''v''e''r'' ''h''o''t'' ''c''o''o''k''e''d'' ''r''i''c''e'' ''\\n''<EOS>'"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    char_indexed_directions = []\n",
    "    for i, row in tokenized_ngl_df.iterrows():\n",
    "        direction = []\n",
    "        for word in row.combined_directions:\n",
    "            if word in ['\\n', '<EOS>']:\n",
    "                direction.append(char_vocab_stoi[word])\n",
    "            else:\n",
    "                for char in word:\n",
    "                    if char in char_vocab:\n",
    "                        direction.append(char_vocab_stoi[char])\n",
    "                direction.append(char_vocab_stoi[' '])\n",
    "            \n",
    "        char_indexed_directions.append(direction)\n",
    "        \n",
    "    print(char_indexed_directions[8])\n",
    "    for char in char_indexed_directions[8]:\n",
    "        print(repr(char_vocab_itos[char]), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 14, 12, 0, 19, 14, 4, 18, 37, 22, 0, 19, 4, 17, 37, 14, 13, 8, 14, 13, 18, 37, 22, 14, 17, 2, 4, 18, 19, 4, 17, 18, 7, 8, 17, 4, 37, 18, 0, 20, 2, 4, 37, 6, 17, 4, 4, 13, 37, 15, 4, 15, 15, 4, 17, 18, 37, 14, 8, 11, 37]\n",
      "'t''o''m''a''t''o''e''s''\\n''w''a''t''e''r''\\n''o''n''i''o''n''s''\\n''w''o''r''c''e''s''t''e''r''s''h''i''r''e''\\n''s''a''u''c''e''\\n''g''r''e''e''n''\\n''p''e''p''p''e''r''s''\\n''o''i''l''\\n'"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    char_indexed_ingredients = []\n",
    "    for i, row in tokenized_ngl_df.iterrows():\n",
    "        ingredients = []\n",
    "        for ingredient_list in row.token_NER:\n",
    "            for word in ingredient_list:\n",
    "                if word in ['\\n', '<EOS>']:\n",
    "                    ingredients.append(char_vocab_stoi[word])\n",
    "                else:\n",
    "                    for char in word:\n",
    "                        if char in char_vocab:\n",
    "                            ingredients.append(char_vocab_stoi[char])\n",
    "                    ingredients.append(char_vocab_stoi['\\n'])\n",
    "        char_indexed_ingredients.append(ingredients)\n",
    "        \n",
    "    print(char_indexed_ingredients[8])\n",
    "    for char in char_indexed_ingredients[8]:\n",
    "        print(repr(char_vocab_itos[char]), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    char_indexed_ngl_df = pd.DataFrame({'directions': char_indexed_directions, 'ingredients': char_indexed_ingredients})\n",
    "    char_indexed_ngl_df.to_csv('data/char_indexed_ngl.csv', header=False, index=False)\n",
    "    \n",
    "char_indexed_ngl_df = pd.read_csv('data/char_indexed_ngl.csv', header=None, names=[\"directions\", \"ingredients\"],\n",
    "                            converters={'directions':pd.eval, 'ingredients':pd.eval})\n",
    "    \n",
    "    \n",
    "    #char_indexed_ngl_df.to_json('./data/char_indexed_ngl.json')\n",
    "    \n",
    "#char_indexed_ngl_df = pd.read_json('./data/char_indexed_ngl.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 13, 36, 0, 36, 7, 4, 0, 21, 24, 36, 28, 36...</td>\n",
       "      <td>[1, 17, 14, 22, 13, 37, 18, 20, 6, 0, 17, 37, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[15, 11, 0, 2, 4, 36, 2, 7, 8, 15, 15, 4, 3, 3...</td>\n",
       "      <td>[1, 4, 4, 5, 37, 2, 7, 8, 2, 10, 4, 13, 37, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[8, 13, 36, 0, 36, 18, 11, 14, 22, 36, 2, 14, ...</td>\n",
       "      <td>[5, 17, 14, 25, 4, 13, 37, 2, 14, 17, 13, 37, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  [8, 13, 36, 0, 36, 7, 4, 0, 21, 24, 36, 28, 36...   \n",
       "1  [15, 11, 0, 2, 4, 36, 2, 7, 8, 15, 15, 4, 3, 3...   \n",
       "2  [8, 13, 36, 0, 36, 18, 11, 14, 22, 36, 2, 14, ...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [1, 17, 14, 22, 13, 37, 18, 20, 6, 0, 17, 37, ...  \n",
       "1  [1, 4, 4, 5, 37, 2, 7, 8, 2, 10, 4, 13, 37, 1,...  \n",
       "2  [5, 17, 14, 25, 4, 13, 37, 2, 14, 17, 13, 37, ...  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indexed_ngl_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closest Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param: ingredient - list of strings of an ingredient (tokenized)\n",
    "#        ingredient_df - dataframe containing ingredient vocabulary and\n",
    "#                        their corresponding GloVe embedding\n",
    "# return: string of closest ingredient in vocabulary\n",
    "#         if none (e.g. ingredient has is OOV in GloVe), returns empty string\n",
    "def get_closest_ingredient (ingredient, ingredients_df):\n",
    "    # check if ingredient is in ingredients_df\n",
    "    if len(ingredient) == 1 and ingredient[0] in ingredients_df['ingredient'].values:\n",
    "        return ingredient[0]\n",
    "    \n",
    "    closest_ingredient = ''\n",
    "    smallest_distance = float('inf')\n",
    "    \n",
    "    # compute the GloVe embedding of the ingredient\n",
    "    ingredient_embedding = glove_average(ingredient)\n",
    "    \n",
    "    if torch.count_nonzero(ingredient_embedding) == 0:\n",
    "        return ''\n",
    "    \n",
    "    # compute distances between embeddings, choose the smallest distance\n",
    "    for _, row in ingredients_df.iterrows():\n",
    "        difference = ingredient_embedding - torch.FloatTensor(row['embedding'])\n",
    "        distance = torch.sum(torch.square(difference))\n",
    "        if distance < smallest_distance:\n",
    "            smallest_distance = distance\n",
    "            closest_ingredient = row['ingredient']\n",
    "    \n",
    "    return closest_ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown sugar', 'milk', 'vanilla', 'soy nut', 'butter', 'rice paper']\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    # changes the ingredients list into their corresponding closest ingredients\n",
    "    # in the vocabulary using the GloVe embeddings\n",
    "    NER_closest_ingredients = []\n",
    "\n",
    "    for i, row in tokenized_ngl_df.iterrows():\n",
    "        NER_closest_list = []\n",
    "        for ingredient_tokens in row.token_NER:\n",
    "            NER_closest_list.append( get_closest_ingredient(ingredient_tokens, ingredients_df) )\n",
    "        NER_closest_ingredients.append(NER_closest_list)\n",
    "\n",
    "    print(NER_closest_ingredients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    processed_ngl_df = tokenized_ngl_df.copy()\n",
    "    processed_ngl_df['closest_ingredients'] = NER_closest_ingredients\n",
    "    processed_ngl_df.to_csv('data/processed_ngl.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ngl_df = pd.read_csv('data/processed_ngl.csv', index_col=0,\n",
    "                               converters={'ingredients':pd.eval, 'directions':pd.eval, 'NER':pd.eval, \n",
    "                                           'token_title':pd.eval, 'token_ingredients':pd.eval, \n",
    "                                           'token_directions':pd.eval,' token_NER':pd.eval, 'closest_ingredients':pd.eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_NER</th>\n",
       "      <th>closest_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[['brown', 'sugar'], ['milk'], ['vanilla'], ['...</td>\n",
       "      <td>[brown sugar, milk, vanilla, soy nut, butter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[['beef'], ['chicken', 'breasts'], ['cream', '...</td>\n",
       "      <td>[beef, chicken, passion fruit, sour cream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[['frozen', 'corn'], ['cream', 'cheese'], ['bu...</td>\n",
       "      <td>[corn, cheese, butter, garlic, salt, pepper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[['chicken'], ['chicken', 'gravy'], ['cream', ...</td>\n",
       "      <td>[chicken, chicken, passion fruit, cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[['peanut', 'butter'], ['graham', 'cracker', '...</td>\n",
       "      <td>[peanut butter, graham cracker, butter, sugar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[['baking', 'potatoes'], ['extra', 'lean', 'gr...</td>\n",
       "      <td>[baking mix, crescent roll, butter, milk, salt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[['sugar'], ['butter'], ['egg'], ['buttermilk'...</td>\n",
       "      <td>[sugar, butter, egg, buttermilk, flour, salt, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           token_NER  \\\n",
       "0  [['brown', 'sugar'], ['milk'], ['vanilla'], ['...   \n",
       "1  [['beef'], ['chicken', 'breasts'], ['cream', '...   \n",
       "2  [['frozen', 'corn'], ['cream', 'cheese'], ['bu...   \n",
       "3  [['chicken'], ['chicken', 'gravy'], ['cream', ...   \n",
       "4  [['peanut', 'butter'], ['graham', 'cracker', '...   \n",
       "5  [['baking', 'potatoes'], ['extra', 'lean', 'gr...   \n",
       "6  [['sugar'], ['butter'], ['egg'], ['buttermilk'...   \n",
       "\n",
       "                                 closest_ingredients  \n",
       "0  [brown sugar, milk, vanilla, soy nut, butter, ...  \n",
       "1         [beef, chicken, passion fruit, sour cream]  \n",
       "2       [corn, cheese, butter, garlic, salt, pepper]  \n",
       "3          [chicken, chicken, passion fruit, cheese]  \n",
       "4  [peanut butter, graham cracker, butter, sugar,...  \n",
       "5  [baking mix, crescent roll, butter, milk, salt...  \n",
       "6  [sugar, butter, egg, buttermilk, flour, salt, ...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_ngl_df[[\"token_NER\", \"closest_ingredients\"]][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lettuce', 'black pepper', 'grape', 'garlic', 'pepper', 'onion', 'seasoning', 'lentils', 'gorgonzola']\n"
     ]
    }
   ],
   "source": [
    "# outputs the ingredient to closest ingredient pairings for What's Cooking data\n",
    "if pre_processing == True:\n",
    "    wc_ingredients, wc_closest_ingredients = [], []\n",
    "    \n",
    "    limit = 7500\n",
    "    for i in range(len(wc_train_data)):\n",
    "        wc_ingredients.append(wc_train_data[i]['ingredients'])\n",
    "        \n",
    "        item_closest_ingredients = []\n",
    "        for ingredient in wc_train_data[i]['ingredients']:\n",
    "            token_list = re.sub(r\"[^a-zA-Z ]+\", '', ingredient.lower()).split(' ')\n",
    "            closest_ingredient = get_closest_ingredient(token_list, ingredients_df)\n",
    "            item_closest_ingredients.append(closest_ingredient)\n",
    "        wc_closest_ingredients.append(item_closest_ingredients)\n",
    "        \n",
    "        if i >= limit:\n",
    "            break\n",
    "\n",
    "    print(wc_closest_ingredients[0])\n",
    "    \n",
    "    wc_ingredients_df = pd.DataFrame({'ingredients': wc_ingredients, 'closest_ingredients': wc_closest_ingredients})\n",
    "    wc_ingredients_df.to_csv('data/whats_cooking/closest_ingredients.csv', header=True, index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredient Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # get frequency based on appearences in RecipeNGL recipes\n",
    "    ingredient_frequency = torch.zeros(len(ingredients_df)).tolist()\n",
    "    \n",
    "    for i in range(processed_ngl_df.shape[0]):\n",
    "        for closest_ingredient in processed_ngl_df[\"closest_ingredients\"][i]:\n",
    "            index = ingredient_vocab_stoi.get(closest_ingredient)\n",
    "            if (index != None):\n",
    "                ingredient_frequency[index] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # get frequency based on appearences in What's Cooking recipes\n",
    "    wc_ingredients_df = pd.read_csv('data/whats_cooking/closest_ingredients.csv', index_col=0,\n",
    "                                    converters={'ingredients':pd.eval, 'closest_ingredients':pd.eval})\n",
    "    \n",
    "    for i in range(wc_ingredients_df.shape[0]):\n",
    "        for closest_ingredient in wc_ingredients_df[\"closest_ingredients\"][i]:\n",
    "            index = ingredient_vocab_stoi.get(closest_ingredient)\n",
    "            if (index != None):\n",
    "                ingredient_frequency[index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    ingredient_frequency = ( torch.FloatTensor(ingredient_frequency) / max(ingredient_frequency) ).tolist()\n",
    "    ingredients_frequency_df = (ingredients_df.copy()).drop('embedding', axis=1)\n",
    "    ingredients_frequency_df['frequency'] = ingredient_frequency\n",
    "    ingredients_frequency_df.to_csv('data/ingredients_frequency.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_frequency_df = pd.read_csv('data/ingredients_frequency.csv', header=None, names=[\"ingredient\", \"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aioli</td>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ale</td>\n",
       "      <td>0.007678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almond</td>\n",
       "      <td>0.014886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anise</td>\n",
       "      <td>0.002977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.008461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>applesauce</td>\n",
       "      <td>0.013475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apricot</td>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>artichoke</td>\n",
       "      <td>0.009715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arugula</td>\n",
       "      <td>0.007521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asafoetida</td>\n",
       "      <td>0.005171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ingredient  frequency\n",
       "0       aioli   0.004231\n",
       "1         ale   0.007678\n",
       "2      almond   0.014886\n",
       "3       anise   0.002977\n",
       "4       apple   0.008461\n",
       "5  applesauce   0.013475\n",
       "6     apricot   0.005641\n",
       "7   artichoke   0.009715\n",
       "8     arugula   0.007521\n",
       "9  asafoetida   0.005171"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_frequency_df[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first iteration, we further filter the ingredients with less than 0.1% frequency. This yielded 381 ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    filtered_ingredients_frequency_df = ingredients_frequency_df[ingredients_frequency_df['frequency'] > 0.001]\n",
    "    print(filtered_ingredients_frequency_df.shape[0])\n",
    "    filtered_ingredients_frequency_df.drop('frequency', axis=1).to_csv('data/intermediary/frequency_filtered_ingredients.csv', header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredient Graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the graph, each time an ingredient appears in a recipe with another ingredient, their compatibility is increased. This is implemented with an adjacency matrix. The compatibilities will be normalized by each row of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    ingredient_graph = torch.zeros(len(ingredients_df), len(ingredients_df))\n",
    "\n",
    "    for i in range(processed_ngl_df.shape[0]):\n",
    "        for ingredient_1 in processed_ngl_df[\"closest_ingredients\"][i]:\n",
    "            if ingredient_1 != '':\n",
    "                index_1 = ingredient_vocab_stoi[ingredient_1]\n",
    "                for ingredient_2 in processed_ngl_df[\"closest_ingredients\"][i]:\n",
    "                    if ingredient_2 != '' and ingredient_2 != ingredient_1:\n",
    "                        index_2 = ingredient_vocab_stoi[ingredient_2]\n",
    "                        \n",
    "                        ingredient_graph[index_1][index_2] += 1\n",
    "    \n",
    "    for i in range(ingredient_graph.shape[0]):\n",
    "        ingredient_max = torch.max(ingredient_graph[i])\n",
    "        if (ingredient_max > 0):\n",
    "            ingredient_graph[i] = ingredient_graph[i] / ingredient_max\n",
    "        \n",
    "    json.dump(ingredient_graph.tolist(), open('./data/ingredient_graph.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1091, 0.0000, 0.0000, 0.0000, 0.5818, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.0000, 0.1167, 0.0000, 0.0000, 0.4667, 0.0000, 0.0000, 0.0333],\n",
      "        [0.0000, 0.0199, 0.0000, 0.0000, 0.0000, 0.6534, 0.0511, 0.0142, 0.0142],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0527, 0.0461, 0.3789, 0.0016, 0.0000, 0.0000, 0.0675, 0.0099, 0.0148],\n",
      "        [0.0000, 0.0000, 0.1552, 0.0000, 0.0000, 0.3534, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3571, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0476, 0.1190, 0.0000, 0.0000, 0.2143, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "ingredient_graph = json.load(open('./data/ingredient_graph.json', 'r'))\n",
    "ingredient_graph = torch.FloatTensor(ingredient_graph)\n",
    "print(ingredient_graph[40:49,40:49])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Primary Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredient Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Baseline Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: A generative RNN trained using character-tokenized recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRecipeGenerator(nn.Moduel):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers =1 ):\n",
    "          super(RNNRecipeGenerator, self).__init__()\n",
    "          self.ident = torch.eye(vocab_size)\n",
    "          self.rnn = nn.GRU(vocab_size, hidden_size, n_layers, batch_first = True)\n",
    "          self.decoder = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inp, hidden = None):\n",
    "          inp = self.ident[inp]\n",
    "          output, hidden = self.rnn(inp, hidden)\n",
    "          output = self.decoder(output)\n",
    "          return output, hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recipe Generation: Using probability distribution to predict next character. GPU Enabled to speed up generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence_cuda(model, max_len=1000, temperature=0.8):\n",
    "    generated_sequence = \"\n",
    "    \n",
    "    inp = torch.Tensor([vocab_stoi[\"<BOS>\"]]).long().cuda()\n",
    "    hidden = None\n",
    "\n",
    "    for c in range(max_len):\n",
    "          output, hidden = model(inp.unsqueeze(0), hidden)\n",
    "          output_dist = output.data.view(-1).div(temperature).exp().cpu()\n",
    "          top_i = int(torch.multinomial(output_dist, 1)[0])\n",
    "\n",
    "          predicted_char = vocab_itos[top_i]\n",
    "\n",
    "          if predicted_char == \"<EOS>\":\n",
    "              break\n",
    "\n",
    "          generated_sequence += predicted char\n",
    "          inp = torch.Tensor([top_i]).long().cuda()\n",
    "\n",
    "    return generated_sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training: GPU Enabled to speed up training. A sample is printed every print_freq iterations to see the model's progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cuda(model, data, batch_size=1, num_epochs=1, lr=1e-3, print_freq=200):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    iter = 0\n",
    "    data_iter = torchtext.legacy.data.BucketIterator(data, batch_size=batch_size, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "    losses, epochs = []\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        for (recipe, lengths), label in data_iter:\n",
    "            target = recipe[:, 1:].cuda()\n",
    "            inp = recipe[:, :-1].cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output, _ = model(inp)\n",
    "            loss = criterion(output.reshape(-1, vocab_size), target.reshape(-1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss\n",
    "            iter += 1\n",
    "            losses.append(float(loss))\n",
    "            epochs.append(e)\n",
    "\n",
    "            if iter % print_freq == 0:\n",
    "                  print(\"Iteration # %d: Loss %f\" % (it+1, float(avg_loss/print_freq)))\n",
    "                  print(\"Generated Recipe: \" + sample_sequence_cuda(model, 140, 0.8))\n",
    "                  avg_loss = 0\n",
    "\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epochs, losses, label = \"Training\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = RNNRecipeGenerator(vocab_size, 64)\n",
    "baseline_model = baseline_model.cuda()\n",
    "baseline_model.ident = baseline_model.ident.cuda()\n",
    "train_cuda(baseline_model, recipes, batch_size=32, num_epochs=1, lr=1e-3, print_every=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Results and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f6b67828bcf6e6b24b24226b27e29c318445726d2dd849532926bd41a61ff72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
