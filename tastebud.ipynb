{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TasteBud: GAN Based Recipe Generation with Graph\n",
    "\n",
    "Introductory words about this project..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Data Processing\n",
    "\n",
    "Data processing here has two main goals each with smaller milestones: tokenizing recipe data and creating the ingredients graph.\n",
    "Tokenizing data requires parsing the Recipenlg dataset, which will be subsetted due to its large size.\n",
    "Creating the ingredients graph first requires a list of ingredients. A raw list will be obtained from the What's Cooking and RecipeNLG datasets. Then, the list will be filtered into a smaller list. The filtered list will be used for indexing ingredients, finding related/close ingredients, and creating the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import json\n",
    "import ast\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing = True\n",
    "glove = torchtext.vocab.GloVe(name='6B', dim=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading What's Cooking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "# loading the What's Cooking dataset from the .json file\n",
    "wc_train_path = './data/whats_cooking/train.json'\n",
    "wc_train_data = json.load(open(wc_train_path, 'r'))\n",
    "print(wc_train_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Recipenlg Data and Subsetting\n",
    "Since Recipenlg contains 2.23 million recipes, select a subset to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/recipe_nlg\\dataset_0_100.csv\n",
      "./data/recipe_nlg\\dataset_0_5000.csv\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    full_nlg_path = './data/recipe_nlg/full_dataset.csv'\n",
    "    # if the full recipenlg dataset csv file exists, read a subset of it\n",
    "    if os.path.exists(full_nlg_path):\n",
    "        nlg_subset = [0, 5000] # change nlg_subset for different ranges of the dataset\n",
    "        nlg_df = pd.read_csv(full_nlg_path, skiprows=nlg_subset[0], nrows=nlg_subset[1], index_col=0)\n",
    "        nlg_df.to_csv(f'./data/recipe_nlg/dataset_{nlg_subset[0]}_{nlg_subset[1]}.csv')\n",
    "\n",
    "# load the dataset from the saved subset csv file\n",
    "for file in glob.glob('./data/recipe_nlg/dataset*.csv'):\n",
    "    print(file)\n",
    "    # use pd.eval to convert strings of lists into lists\n",
    "    nlg_df = pd.read_csv(file, index_col=0, \n",
    "                         converters={'ingredients':pd.eval, 'directions':pd.eval, 'NER':pd.eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[1 c. firmly packed brown sugar, 1/2 c. evapor...</td>\n",
       "      <td>[In a heavy 2-quart saucepan, mix brown sugar,...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[brown sugar, milk, vanilla, nuts, butter, bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[1 small jar chipped beef, cut up, 4 boned chi...</td>\n",
       "      <td>[Place chipped beef on bottom of baking dish.,...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...</td>\n",
       "      <td>[In a slow cooker, combine all ingredients. Co...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n",
       "      <td>Gathered</td>\n",
       "      <td>[frozen corn, cream cheese, butter, garlic pow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  [1 c. firmly packed brown sugar, 1/2 c. evapor...   \n",
       "1  Jewell Ball'S Chicken  [1 small jar chipped beef, cut up, 4 boned chi...   \n",
       "2            Creamy Corn  [2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [In a heavy 2-quart saucepan, mix brown sugar,...   \n",
       "1  [Place chipped beef on bottom of baking dish.,...   \n",
       "2  [In a slow cooker, combine all ingredients. Co...   \n",
       "\n",
       "                                              link    source  \\\n",
       "0   www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
       "1  www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
       "2   www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
       "\n",
       "                                                 NER  \n",
       "0  [brown sugar, milk, vanilla, nuts, butter, bit...  \n",
       "1  [beef, chicken breasts, cream of mushroom soup...  \n",
       "2  [frozen corn, cream cheese, butter, garlic pow...  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlg_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create List of Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mustard sauce', 'back bacon rashers', 'gluten-free flour', 'whole wheat rotini pasta', 'red raspberry jello', 'hazelnut flour', 'celery', 'anchovy fillets', 'San Marzano tomatoes', 'wish bone guacamol ranch dress', 'low-fat balsamic vinaigrette', \"Quorn Chik''n Tenders\", 'sloe gin', 'saffron powder', 'passata', 'red curry paste', 'low sodium store bought chicken stock', 'fresno pepper', 'leaf parsley', \"Campbell's cream\", 'brown basmati rice', 'gumbo file powder', 'amaretti', 'reduced fat coconut milk', 'condensed reduced fat reduced sodium cream of chicken soup', 'frozen mustard greens', 'pineapple pie filling', 'king oyster mushroom', 'linguine pasta', 'Tabasco sauce', 'flour tortillas (not low fat)', 'asian noodles', 'low-fat parmesan cheese', 'sausage casings', 'new york strip steaks', 'beef rib roast', 'apple juice', 'cherry jello', 'White Pepper', 'caramel icing', 'Tia Maria', 'meat sauce', 'baby okra', 'green garlic', 'onion buns', 'white tuna', 'dry vermouth', 'small potatoes', 'cream cheese', 'frozen lemonade concentrate, thawed and undiluted']\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    # creating a list of unique ingredients from the datasets\n",
    "    ingredients_set = set()\n",
    "\n",
    "    # loop through What's cooking data to get ingredients\n",
    "    for i in range(len(wc_train_data)):\n",
    "        ingredients_set = ingredients_set | set(wc_train_data[i]['ingredients'])\n",
    "    \n",
    "    # loop through Recipenlg data to get ingredients\n",
    "    for i in range(len(nlg_df[\"NER\"])):\n",
    "        ingredients_set = ingredients_set | set(nlg_df[\"NER\"][i])\n",
    "        \n",
    "    print(list(ingredients_set)[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # export the list of unique ingredients for manual filtering (use transpose for easier filtering)\n",
    "    cw = csv.writer(open(\"data/intermediary/raw_ingredients_list.csv\",'w'))\n",
    "    cw.writerow(list(ingredients_set))\n",
    "    pd.read_csv('data/intermediary/raw_ingredients_list.csv', \n",
    "                header=None).T.to_csv('data/intermediary/raw_ingredients_list_transpose.csv', \n",
    "                                      header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a list of 8500 ingredients, we manually removed duplicated items that had spelling errors, semantic similarities, and extra numeric or qualitative descriptors (e.g. chopped, 2% fat, shredded, unsweetened), giving 955 ingredients. Then, each is paired its gloVe embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param: token_list - a list of tokens, no spaces or symbols\n",
    "# return: a tensor of the averaged GloVe embeddings of each token\n",
    "def glove_average(token_list):\n",
    "    embeds_list = []\n",
    "    for token in token_list:\n",
    "        embeds_list.append(glove[token])\n",
    "    embeds_average = torch.mean(torch.stack(embeds_list), dim=0)\n",
    "    return embeds_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # read the manually filtered ingredient list\n",
    "    filtered_ingredients_df = pd.read_csv('data/intermediary/filtered_ingredients_list_transpose.csv', header=None, names=[\"ingredient\"])\n",
    "    ingredient_embeddings = []\n",
    "\n",
    "    # find GloVe embeddings for each ingredient and save it\n",
    "    for i, row in filtered_ingredients_df.iterrows():\n",
    "        token_list = re.sub(r\"[^a-zA-Z ]+\", '', filtered_ingredients_df['ingredient'][i].lower()).split(' ')\n",
    "        embed_list = []\n",
    "        ingredient_embeddings.append(glove_average(token_list).tolist())\n",
    "        \n",
    "    filtered_ingredients_df['embedding'] = ingredient_embeddings\n",
    "    filtered_ingredients_df['ingredient'] = filtered_ingredients_df['ingredient'].apply(lambda x: x.rstrip())\n",
    "    filtered_ingredients_df.to_csv('data/glove_ingredients_list.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ingredient                                          embedding\n",
      "0      aioli  [0.053968001157045364, 0.027247000485658646, -...\n",
      "1        ale  [-0.4636099934577942, 0.6578099727630615, -1.3...\n",
      "2     almond  [-0.023429999127984047, 0.47051000595092773, -...\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    ingredients_df = pd.read_csv('data/glove_ingredients_list.csv', header=None, names=[\"ingredient\", \"embedding\"],\n",
    "                            converters={'embedding':pd.eval})\n",
    "    \n",
    "    print(ingredients_df[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since GloVe give embeddings for out-of-vocabulary words, the words with null tensors `[0,0,0,...,0]` were removed from the ingredients list, giving a total of 840 ingredients. Using these embeddings will allow for ingredients not in the list to be mapped to the closest ingredient, then put in the ingredient graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aioli': 0, 'ale': 1, 'almond': 2, 'anise': 3, 'apple': 4, 'applesauce': 5, 'apricot': 6, 'artichoke': 7, 'arugula': 8, 'asafoetida': 9, 'asparagus': 10, 'avocado': 11, 'bacon': 12, 'baguette': 13, 'baking mix': 14, 'baking soda': 15, 'banana': 16, 'banana blossom': 17, 'banana leaf': 18, 'basil': 19, 'bay leaf': 20, 'bean': 21, 'bean curd': 22, 'bean sprout': 23, 'beef': 24, 'beer': 25, 'beet': 26, 'berry': 27, 'biscuit': 28, 'bitter melon': 29, 'black pepper': 30, 'blackberries': 31, 'blueberries': 32, 'bok choy': 33, 'bologna': 34, 'bone': 35, 'bouillon': 36, 'brandy': 37, 'bread': 38, 'breast': 39, 'broccoli': 40, 'broth': 41, 'brown sugar': 42, 'brownie': 43, 'burger': 44, 'butter': 45, 'buttermilk': 46, 'butterscotch': 47, 'cabbage': 48, 'cake': 49, 'calabash': 50, 'candy': 51, 'cane sugar': 52, 'canola': 53, 'cantaloupe': 54, 'capsicum': 55, 'caramel': 56, 'carbonated water': 57, 'cardamom': 58, 'cardoon': 59, 'carrot': 60, 'caster sugar': 61, 'cauliflower': 62, 'cayenne': 63, 'celery': 64, 'cereal': 65, 'champagne': 66, 'chayote': 67, 'cheddar': 68, 'cheese': 69, 'cherries': 70, 'chicken': 71, 'chili': 72, 'chocolate': 73, 'chorizo': 74, 'choy sum': 75, 'chutney': 76, 'cider': 77, 'cilantro': 78, 'cinnamon': 79, 'clam': 80, 'clove': 81, 'cocoa': 82, 'coconut': 83, 'coffee': 84, 'cognac': 85, 'coleslaw': 86, 'coloring': 87, 'concentrate': 88, 'cookie': 89, 'coriander': 90, 'corn': 91, 'cornflour': 92, 'cornmeal': 93, 'cornstarch': 94, 'couscous': 95, 'crab': 96, 'cracker': 97, 'cranberries': 98, 'cream': 99, 'crescent roll': 100, 'crust': 101, 'cucumber': 102, 'cumin': 103, 'currant': 104, 'curry': 105, 'custard': 106, 'daikon': 107, 'dashi': 108, 'date': 109, 'dhal': 110, 'dill': 111, 'do chua': 112, 'dough': 113, 'dressing': 114, 'duck': 115, 'egg': 116, 'eggnog': 117, 'eggplant': 118, 'escarole': 119, 'essence': 120, 'extract': 121, 'farro': 122, 'fat': 123, 'fennel': 124, 'fenugreek': 125, 'fillet': 126, 'filling': 127, 'fish': 128, 'fish sauce': 129, 'flavoring': 130, 'flour': 131, 'focaccia': 132, 'frankfurters': 133, 'fruit': 134, 'fusilli': 135, 'galangal': 136, 'garlic': 137, 'gelatin': 138, 'ghee': 139, 'ginger': 140, 'glaze': 141, 'gnocchi': 142, 'goat': 143, 'gobo root': 144, 'goji berries': 145, 'gold leaf': 146, 'gorgonzola': 147, 'graham cracker': 148, 'grape': 149, 'grapefruit': 150, 'greek yogurt': 151, 'guacamole': 152, 'halibut': 153, 'ham': 154, 'hamburger': 155, 'harissa': 156, 'hash brown': 157, 'hominy': 158, 'honey': 159, 'horseradish': 160, 'hot dog': 161, 'hot sauce': 162, 'ice': 163, 'ice cream': 164, 'icing': 165, 'jaggery': 166, 'jalapeno': 167, 'jam': 168, 'jello': 169, 'jicama': 170, 'juice': 171, 'kahlua': 172, 'kalamata': 173, 'kale': 174, 'ketchup': 175, 'kielbasa': 176, 'kimchi': 177, 'kiwi': 178, 'kumquats': 179, 'ladyfingers': 180, 'laksa paste': 181, 'lamb': 182, 'lard': 183, 'lasagna': 184, 'lavender': 185, 'lemon': 186, 'lemongrass': 187, 'lentils': 188, 'lettuce': 189, 'licorice root': 190, 'lima bean': 191, 'lime': 192, 'limoncello': 193, 'linguine': 194, 'liqueur': 195, 'loaf': 196, 'lobster': 197, 'luncheon meat': 198, 'maca powder': 199, 'macaroni': 200, 'mace': 201, 'mandarin': 202, 'mango': 203, 'maple syrup': 204, 'margarine': 205, 'marinade': 206, 'marjoram': 207, 'marmite': 208, 'marshmallow': 209, 'marzipan': 210, 'masala': 211, 'mascarpone': 212, 'mayonnaise': 213, 'milk': 214, 'mint': 215, 'mirin': 216, 'miso': 217, 'molasses': 218, 'mozzarella': 219, 'mushroom': 220, 'mustard': 221, 'naan': 222, 'nectar': 223, 'nori': 224, 'nutmeg': 225, 'oat': 226, 'oatmeal': 227, 'oil': 228, 'okra': 229, 'oleo': 230, 'olive': 231, 'onion': 232, 'orange': 233, 'orecchiette': 234, 'oregano': 235, 'oyster': 236, 'oyster sauce': 237, 'pancetta': 238, 'paneer': 239, 'panko': 240, 'papaya': 241, 'paprika': 242, 'paraffin': 243, 'parmesan': 244, 'parsley': 245, 'passion fruit': 246, 'pasta': 247, 'pastry': 248, 'peach': 249, 'peanut': 250, 'peanut butter': 251, 'pear': 252, 'pecan': 253, 'pepper': 254, 'pepperoni': 255, 'pesto': 256, 'phyllo': 257, 'pickle': 258, 'pie crust': 259, 'piloncillo': 260, 'pimiento': 261, 'pineapple': 262, 'polenta': 263, 'popcorn': 264, 'poppy seed': 265, 'pork': 266, 'porridge': 267, 'potato': 268, 'prosciutto': 269, 'pudding': 270, 'pumpkin': 271, 'pumpkin seed': 272, 'quinoa': 273, 'racks': 274, 'radicchio': 275, 'raspberry': 276, 'relish': 277, 'remoulade': 278, 'rhubarb': 279, 'rib': 280, 'rice': 281, 'rice noodle': 282, 'rice paper': 283, 'ricotta': 284, 'rind': 285, 'rock sugar': 286, 'rosemary': 287, 'round': 288, 'roux': 289, 'rum': 290, 'rutabaga': 291, 'rye': 292, 'saffron': 293, 'sage': 294, 'sake': 295, 'salad': 296, 'salami': 297, 'salmon': 298, 'salsa': 299, 'salt': 300, 'sauce': 301, 'sauerkraut': 302, 'sausage': 303, 'scallion': 304, 'seasoning': 305, 'seaweed': 306, 'seltzer': 307, 'serrano': 308, 'sesame': 309, 'shallot': 310, 'shell': 311, 'shellfish': 312, 'sherbet': 313, 'sherry': 314, 'shiitake': 315, 'shortbread': 316, 'shortening': 317, 'shoyu': 318, 'shrimp': 319, 'shrimp paste': 320, 'sichuan pepper': 321, 'sirloin': 322, 'slaw': 323, 'smoke': 324, 'soda': 325, 'soup': 326, 'sour cream': 327, 'soy flour': 328, 'soy milk': 329, 'soy nut': 330, 'soy sauce': 331, 'spaghetti': 332, 'sparkling water': 333, 'spice': 334, 'spinach': 335, 'sprinkles': 336, 'squash': 337, 'squid': 338, 'star anise': 339, 'steak': 340, 'stew': 341, 'stock': 342, 'strawberry': 343, 'stuffing': 344, 'sugar': 345, 'sunflower seed': 346, 'sweetbread': 347, 'sweetener': 348, 'syrup': 349, 'tahini': 350, 'tallow': 351, 'tangerine': 352, 'tapioca': 353, 'tea': 354, 'tequila': 355, 'thyme': 356, 'toast': 357, 'tofu': 358, 'tomato': 359, 'tortilla': 360, 'tuna': 361, 'turbinado': 362, 'turkey': 363, 'turmeric': 364, 'udon': 365, 'vanilla': 366, 'veal': 367, 'vegetables': 368, 'verjuice': 369, 'vermicelli': 370, 'vinegar': 371, 'vodka': 372, 'water': 373, 'watercress': 374, 'white pepper': 375, 'wine': 376, 'worcestershire': 377, 'yeast': 378, 'yogurt': 379, 'zucchini': 380}\n"
     ]
    }
   ],
   "source": [
    "# dictionary pairing ingredient with index value\n",
    "ingredient_vocab = list(ingredients_df['ingredient'])\n",
    "ingredient_vocab_stoi = {s: i for i, s in enumerate(ingredient_vocab)}\n",
    "ingredient_vocab_itos = {i: s for i, s in enumerate(ingredient_vocab)}\n",
    "ingredient_vocab_size = len(ingredient_vocab)\n",
    "\n",
    "print(ingredient_vocab_stoi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for only \"Gathered\" sources, since those have more consistent format\n",
    "gathered_nlg_df = nlg_df[nlg_df.source == 'Gathered']\n",
    "# remove unnecessary columns\n",
    "filtered_nlg_df = gathered_nlg_df[['title', 'ingredients', 'directions', 'NER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in filtered_nlg_df.iterrows():\n",
    "    cleaned_directions = []\n",
    "    for step in row.directions:\n",
    "        step = re.sub(r\"[^a-z0-9]+\", ' ', step.lower()) # remove uppercase and symbols\n",
    "        cleaned_directions.append(step)\n",
    "    row.directions = cleaned_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[1 c. firmly packed brown sugar, 1/2 c. evapor...</td>\n",
       "      <td>[in a heavy 2 quart saucepan mix brown sugar n...</td>\n",
       "      <td>[brown sugar, milk, vanilla, nuts, butter, bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[1 small jar chipped beef, cut up, 4 boned chi...</td>\n",
       "      <td>[place chipped beef on bottom of baking dish ,...</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...</td>\n",
       "      <td>[in a slow cooker combine all ingredients cove...</td>\n",
       "      <td>[frozen corn, cream cheese, butter, garlic pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[1 large whole chicken, 2 (10 1/2 oz.) cans ch...</td>\n",
       "      <td>[boil and debone chicken , put bite size piece...</td>\n",
       "      <td>[chicken, chicken gravy, cream of mushroom sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        ingredients  \\\n",
       "0    No-Bake Nut Cookies  [1 c. firmly packed brown sugar, 1/2 c. evapor...   \n",
       "1  Jewell Ball'S Chicken  [1 small jar chipped beef, cut up, 4 boned chi...   \n",
       "2            Creamy Corn  [2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...   \n",
       "3          Chicken Funny  [1 large whole chicken, 2 (10 1/2 oz.) cans ch...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [in a heavy 2 quart saucepan mix brown sugar n...   \n",
       "1  [place chipped beef on bottom of baking dish ,...   \n",
       "2  [in a slow cooker combine all ingredients cove...   \n",
       "3  [boil and debone chicken , put bite size piece...   \n",
       "\n",
       "                                                 NER  \n",
       "0  [brown sugar, milk, vanilla, nuts, butter, bit...  \n",
       "1  [beef, chicken breasts, cream of mushroom soup...  \n",
       "2  [frozen corn, cream cheese, butter, garlic pow...  \n",
       "3  [chicken, chicken gravy, cream of mushroom sou...  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_nlg_df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing uppercase and symbols from directions and fuse using ':'\n",
    "combined_directions, combined_ingredients = [], []\n",
    "\n",
    "for i, row in filtered_nlg_df.iterrows():\n",
    "    cleaned_directions = ''\n",
    "    for step in row.directions:\n",
    "        step = re.sub(r\"[^a-z0-9]+\", ' ', step.lower()) # remove uppercase and symbols\n",
    "        cleaned_directions += step + ' ; '\n",
    "    combined_directions.append(cleaned_directions)\n",
    "    \n",
    "    cleaned_NER = ''\n",
    "    for ingredient in row.NER:\n",
    "        ingredient = re.sub(r\"[^a-z0-9]+\", ' ', ingredient.lower()) # remove uppercase and symbols\n",
    "        cleaned_NER += ingredient + ' ; '\n",
    "    combined_ingredients.append(cleaned_NER)\n",
    "    \n",
    "combined_nlg_df = pd.DataFrame()\n",
    "combined_nlg_df['directions'] = combined_directions\n",
    "combined_nlg_df['ingredients'] = combined_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in a heavy 2 quart saucepan mix brown sugar nu...</td>\n",
       "      <td>brown sugar ; milk ; vanilla ; nuts ; butter ;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place chipped beef on bottom of baking dish  ;...</td>\n",
       "      <td>beef ; chicken breasts ; cream of mushroom sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in a slow cooker combine all ingredients cover...</td>\n",
       "      <td>frozen corn ; cream cheese ; butter ; garlic p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boil and debone chicken  ; put bite size piece...</td>\n",
       "      <td>chicken ; chicken gravy ; cream of mushroom so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  in a heavy 2 quart saucepan mix brown sugar nu...   \n",
       "1  place chipped beef on bottom of baking dish  ;...   \n",
       "2  in a slow cooker combine all ingredients cover...   \n",
       "3  boil and debone chicken  ; put bite size piece...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  brown sugar ; milk ; vanilla ; nuts ; butter ;...  \n",
       "1  beef ; chicken breasts ; cream of mushroom sou...  \n",
       "2  frozen corn ; cream cheese ; butter ; garlic p...  \n",
       "3  chicken ; chicken gravy ; cream of mushroom so...  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_nlg_df[:4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe Data Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['in', 'a', 'heavy', '2', 'quart', 'saucepan', 'mix', 'brown', 'sugar', 'nuts', 'evaporated', 'milk', 'and', 'butter', 'or', 'margarine'], ['stir', 'over', 'medium', 'heat', 'until', 'mixture', 'bubbles', 'all', 'over', 'top'], ['boil', 'and', 'stir', '5', 'minutes', 'more', 'take', 'off', 'heat'], ['stir', 'in', 'vanilla', 'and', 'cereal', 'mix', 'well'], ['using', '2', 'teaspoons', 'drop', 'and', 'shape', 'into', '30', 'clusters', 'on', 'wax', 'paper'], ['let', 'stand', 'until', 'firm', 'about', '30', 'minutes']]\n",
      "[['brown', 'sugar'], ['milk'], ['vanilla'], ['nuts'], ['butter'], ['bite', 'size', 'shredded', 'rice', 'biscuits']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\n",
    "tokenized_directions = []\n",
    "tokenized_ingredients = []\n",
    "\n",
    "for i, row in filtered_nlg_df.iterrows():\n",
    "    # tokenize directions\n",
    "#    tokenized_directions.append(row.directions.split(' '))\n",
    "    \n",
    "    # tokenize ingredients\n",
    "#    tokens_list = []\n",
    "#    tokenized_ingredients.append(row.ingredients.split(' '))\n",
    "    \n",
    "    # tokenize directions\n",
    "    tokens_list = []\n",
    "    for direction_item in row.directions:\n",
    "        tokens_list.append(direction_item.split(' '))\n",
    "    tokenized_directions.append(tokens_list)\n",
    "    \n",
    "    # tokenize ingredients\n",
    "    tokens_list = []\n",
    "    for ingredient in row.NER:\n",
    "        tokens_list.append( re.sub(r\"[^a-zA-Z ]+\", '', ingredient.lower()).split(' ') )\n",
    "    tokenized_ingredients.append(tokens_list)\n",
    "    \n",
    "# remove empty words\n",
    "for i, direction_list in enumerate(tokenized_directions):\n",
    "    temp = []\n",
    "    for direction in direction_list:\n",
    "        direction = [x for x in direction if x != '']\n",
    "        temp.append(direction)\n",
    "    tokenized_directions[i] = temp\n",
    "\n",
    "for i, ingredient_list in enumerate(tokenized_ingredients):\n",
    "    temp = []\n",
    "    for ingredient in ingredient_list:\n",
    "        ingredient = [x for x in ingredient if x != '']\n",
    "        temp.append(ingredient)\n",
    "    tokenized_ingredients[i] = temp\n",
    "\n",
    "\"\"\"\n",
    "tokenized_titles = []\n",
    "tokenized_ingredients = []\n",
    "tokenized_directions = []\n",
    "tokenized_NER = []\n",
    "\n",
    "for i, row in filtered_nlg_df.iterrows():\n",
    "    # tokenize titles\n",
    "    tokens_list = filtered_nlg_df.title.values[i].split(' ')\n",
    "    tokenized_titles.append(tokens_list)\n",
    "    \n",
    "    # tokenize ingredients\n",
    "    tokens_list = []\n",
    "    for ingredient_item in row.ingredients:\n",
    "        tokens_list.append(ingredient_item.split(' '))\n",
    "    tokenized_ingredients.append(tokens_list)\n",
    "    \n",
    "    # tokenize directions\n",
    "    tokens_list = []\n",
    "    for direction_item in row.directions:\n",
    "        tokens_list.append(direction_item.split(' '))\n",
    "    tokenized_directions.append(tokens_list)\n",
    "    \n",
    "    # tokenize ingredients\n",
    "    tokens_list = []\n",
    "    for NER_item in row.NER:\n",
    "        tokens_list.append( re.sub(r\"[^a-zA-Z ]+\", '', NER_item.lower()).split(' ') )\n",
    "    tokenized_NER.append(tokens_list)\n",
    "\n",
    "print(tokenized_titles[0])\n",
    "print(tokenized_ingredients[0])\n",
    "print(tokenized_directions[0])\n",
    "print(tokenized_NER[0])\n",
    "\"\"\"\n",
    "print(tokenized_directions[0])\n",
    "print(tokenized_ingredients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tokenized_nlg_df = filtered_nlg_df.copy()\n",
    "tokenized_nlg_df['token_title'] = tokenized_titles\n",
    "tokenized_nlg_df['token_ingredients'] = tokenized_ingredients\n",
    "tokenized_nlg_df['token_directions'] = tokenized_directions\n",
    "tokenized_nlg_df['token_NER'] = tokenized_NER\n",
    "\"\"\"\n",
    "tokenized_nlg_df = pd.DataFrame()\n",
    "tokenized_nlg_df['directions'] = tokenized_directions\n",
    "tokenized_nlg_df['ingredients'] = tokenized_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[in, a, heavy, 2, quart, saucepan, mix, brown...</td>\n",
       "      <td>[[brown, sugar], [milk], [vanilla], [nuts], [b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[place, chipped, beef, on, bottom, of, baking...</td>\n",
       "      <td>[[beef], [chicken, breasts], [cream, of, mushr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[in, a, slow, cooker, combine, all, ingredien...</td>\n",
       "      <td>[[frozen, corn], [cream, cheese], [butter], [g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  [[in, a, heavy, 2, quart, saucepan, mix, brown...   \n",
       "1  [[place, chipped, beef, on, bottom, of, baking...   \n",
       "2  [[in, a, slow, cooker, combine, all, ingredien...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [[brown, sugar], [milk], [vanilla], [nuts], [b...  \n",
       "1  [[beef], [chicken, breasts], [cream, of, mushr...  \n",
       "2  [[frozen, corn], [cream, cheese], [butter], [g...  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_nlg_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction Step Combining\n",
    "To ease the complexity of the GAN and RNN, the list of directions for each recipe will be fused into a sinlge list of words, with each step separated by `';'` (note all prior symbols were removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roll', 'steak', 'strips', 'in', 'flour', ';', 'brown', 'in', 'skillet', ';', 'salt', 'and', 'pepper', ';', 'combine', 'tomato', 'liquid', 'water', 'onions', 'and', 'browned', 'steak', 'cover', 'and', 'simmer', 'for', 'one', 'and', 'a', 'quarter', 'hours', ';', 'uncover', 'and', 'stir', 'in', 'worcestershire', 'sauce', ';', 'add', 'tomatoes', 'green', 'peppers', 'and', 'simmer', 'for', '5', 'minutes', ';', 'serve', 'over', 'hot', 'cooked', 'rice', ';']\n"
     ]
    }
   ],
   "source": [
    "list_combined_directions = []\n",
    "for i, row in tokenized_nlg_df.iterrows():\n",
    "    direction = []\n",
    "    for step in row.directions:\n",
    "        for word in step:\n",
    "            if word == '': # skip empty words\n",
    "                continue\n",
    "            direction.append(word)\n",
    "        direction.append(';')\n",
    "    list_combined_directions.append(direction)\n",
    "     \n",
    "tokenized_nlg_df['combined_directions'] = list_combined_directions\n",
    "print(list_combined_directions[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tomatoes', ';', 'water', ';', 'onions', ';', 'worcestershire', 'sauce', ';', 'green', 'peppers', ';', 'oil', ';']\n"
     ]
    }
   ],
   "source": [
    "list_combined_ingredients = []\n",
    "for i, row in tokenized_nlg_df.iterrows():\n",
    "    ingredient_list = []\n",
    "    for ingredients in row.ingredients:\n",
    "        for word in ingredients:\n",
    "            if word == '': # skip empty words\n",
    "                continue\n",
    "            ingredient_list.append(word)\n",
    "        ingredient_list.append(';')\n",
    "    list_combined_ingredients.append(ingredient_list)\n",
    "     \n",
    "tokenized_nlg_df['combined_ingredients'] = list_combined_ingredients\n",
    "print(list_combined_ingredients[8])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction Word Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words before ignoring: 3843\n",
      "Unique words after ignoring: 2637\n",
      "['raisin', 'fitted', 'yams', 'snack', 'wish', 'chutney', 'service', 'hunger', 'pizzelle', 'tubs', 'celery', 'prayer', 'dot', 'headspace', 'chill', 'sprayed', 'faith', 'uv', 'stockpot', 'puddings', 'valley', '16', 'overnight', 'hock', 'rim', 'vegies', 'coals', 'atop', 'pepperidge', 'semisweet', 'sifting', 'prawns', 'results', 'rind', 'teflon', 'joe', 'nicely', 'nice', 'caramel', 'sear', 'gets', 'bake', 'water', 'hours', 'knead', 'sprouts', 'dip', 'crystallized', 'pumpernickel', 'salads', 'bits', 'reynolds', 'soups', 'tart', 'slaw', 'rolled', 'filled', 'splenda', 'putting', 'cilantro', 'free', 'showers', 'treat', 'veggies', 'carnation', 'cokes', 'clear', 'rosemary', 'halibut', 'chafing', 'sundae', 'sterile', 'directions', 'sealed', 'saving', 'minutes', 'wilted', 'consistency', 'currants', 'speed', 'coarse', 'combined', '0', 'liquids', 'fill', 'slice', 'flute', 'tin', 'sure', 'tartar', 'seconds', 'crackers', 'uncle', 'duncan', 'burritos', 'spreading', 'vermouth', 'fist', 'starter', 'half', 'pull', 'sticks', 'pitcher', 'kiwi', 'couple', 'sugars', 'tel', 'bitter', 'life', 'confectioner', 'orange', 'hard', 'liter', 'evaporated', 'stock', 'chilling', 'rinse', 'cleaned', 'butter', 'vodka', 'ro', 'jicama', 'fire', 'crimp', 'adding', 'raise', 'mushy', 'platter', 'powdered', 'oats', 'reserve', 'linguini', 'cocoa', 'tester', 'container', 'bark', 'insides', 'cumin', 'love', 'beat', 'big', 'won', 'seal', 'then', 'crushed', 'addition', 'sheets', 'method', 'to', 'cinnamon', 'dish', 'starch', 'grated', 'place', 'cob', 'fall', 'mine', 'original', 'spoon', 'constantly', 'papers', 'rims', 'made', 'unflavored', 'sweeter', 'smooth', 'peppercorn', 'fillets', 'omit', 'fresh', 'teriyaki', 'dirt', 'kindly', 'ale', 'sausage', 'roux', 'takes', 'sauteed', 'hominy', 'enough', 'dash', 'option', 'inserted', 'roughy', 'pick', 'eggs', 'cool', 'end', 'pile', 'rinsed', 'gallons', 'yolk', 'depending', 'hors', 'fits', 'dice', 'spice', 'sugared', 'marinate', 'remove', 'oiled', 'chestnut', 'sized', 'in', 'actually', 'lawry', 'microwave', 'shoyu', 'ketchup', 'work', 'cheeses', 'dark', 'minute', 'crystals', 'macadamia', 'corned', 'serves', 'frequently', 'raisins', 'serving', 'preferably', 'cook', 'ovenproof', 'fine', 'works', 'long', 'shallow', 'set', 'zucchini', 'thickest', 'control', 'wax', 'pink', 'metal', 'night', 'what', 'sole', 'some', 'kraft', 'ricotta', 'rubber', 'dill', 'fairly', 'dogs', 'apple', 'triple', 'here', 'sprinkles', 'achiote', 'eggbeater', 'seed', 'instant', 'form', 'rise', 'tines', 'fashion', 'tip', 'sprite', 'thoroughly', 'd', 'tots', 'runs', 'beans', 'choice', 'for', '36', 'feet', 'creamy', 'liking', 'emulsify', 'times', 'dust', 'leftover', 'debone', 'doubleacting', 'replace', 'heads', 'delightful', 'rotary', '86', 'beef', 'great', 'low', 'cutter', 'cloth', 'applesauce', 'cooled', 'continue', 'drop', 'sodium', 'loses', 'two', 'been', 'o', 'overbeat', 'whiskey', 'garden', 'slab', 'doing', 'scald', 'sympathy', 'longer', '55', 'peg', 'requires', 'up', 'covers', 'thinner', 'rotini', 'tsp', 'parkay', 'browns', 'distribute', 'partly', '120', 'turmeric', 'min', 'thinly', 'creamer', 'yellow', 'blended', 'strainer', 'kindness', 'sparkling', 'bundt', 'sourdough', 'occasionally', 'mound', 'imitation', 'fettucine', 'chocolate', 'light', 'funnel', 'flour', 'extra', 'dried', 'meringue', 'mashed', 'sorrow', 'glaze', 'stars', 'sandies', 'shaking', 'roll', 'normally', 'forming', 'microcook', 'overcook', 'canned', 'tapped', 'lentils', 'loaves', 'buttered', 'leftovers', 'halfway', 'using', 'rabbit', 'feta', 'saran', 'leave', 'oatmeal', '9x9', 'parchment', 'cheez', 'clump', 'calories', 'ginger', 'section', 'chewy', 'colors', 'points', 'salsa', 'jell', 'enclose', 'step', 'weed', 'runny', 'lid', 'feed', 'dome', 'saved', 'perhaps', '70', 'from', 'purple', 'chili', 'little', 'shell', 'bed', 'core', 'morsels', 'pith', 'secure', 'taste', 'prevent', 'inverted', 'drying', 'squeeze', 'boil', 'frosted', 'slightly', 'melting', 'stew', 'husks', 'pepperoncini', 'slit', 'shortening', 'souffle', 'pickle', 'molds', 'spoonful', 'among', 'sweeten', 'position', 'variety', 'haddock', 'unpeeled', 'tint', 'pocket', 'machine', 'eggnog', 'nonstick', 'chunks', 'preheated', 'hearts', 'shredded', 'catalina', 'legs', 'steadily', 'pulling', 'strawberries', 'according', 'pastry', 'provolone', 'patties', 'coal', 'saltwater', 'saifon', 'scalded', 'drumsticks', 'mash', 'lima', 'crumbles', 'steam', 'except', 'save', 'sirloin', 'duck', 'vanilla', 'different', 'pet', 'last', 'seeds', '8ths', 'procedure', 'damp', 'formed', 'noodle', 'bottles', 'dough', 'buy', 'pouring', 'egg', 'lumps', 'stop', 'rounded', 'peaked', 'shaker', 'pattern', 'help', 'spoonfuls', 'tamales', 'plus', 'unsweetened', 'ice', 'anchovies', 'servings', 'available', 'gel', 'oven', 'virgin', 'oleo', 'stretch', 'take', 'pepper', 'circular', 'franks', 'pat', '100', 'having', 'complete', 'romano', 'cardamom', 'dampen', 'continuing', 'pebbles', 'going', 'changes', 'trays', 'trim', 'about', 'whipping', 'cast', 'quite', 'campbell', '1', 'mexicorn', 'between', 'first', 'sauces', 'overbake', 'ending', 'tough', 'follows', 'smaller', 'chillies', 'salty', 'golf', 'rows', 'toothpick', 'pecan', 'bag', 'unbeaten', 'moisture', 'touched', 'coat', 'simply', 'tablespoonful', 'watermelon', 'sort', 'french', 'pressed', 'american', 'canadian', 'heatproof', 'tightly', 'level', 'cold', 'refrigerate', 'juice', 'tvp', '200', 'good', 'cocacola', 'crispy', 'cooking', 'split', 'pointed', 'average', 'flat', 'possible', 'dinner', 'small', 'spices', 'feeds', 'but', 'dissolves', 'centers', 'next', 'ones', 'gives', '13', 'chow', 'spaghetti', 'children', 'lime', 'cheerios', 'texture', 'done', 'fried', 'three', 'tops', 'well', 'blot', 'rounds', 'knife', 'bamboo', 'broth', 'touch', 'leaf', 'candied', 'them', 'bags', 'chiles', 'crust', 'vinegar', 'wafers', 'penne', 'approx', 'bottoms', 'six', 'crusts', 'quartered', 'tan', 'lite', 'handling', 'against', '75', 'heated', 'boils', 'separates', 'largest', 'apricots', 'russian', 'string', 'round', 'grind', 'criss', 'creamstyle', 'okra', 'leak', 'weather', 'standing', 'campbells', 'tossing', 'recipe', 'eating', 'ring', 'age', 'beet', 'with', 'cutters', 'breast', 'semi', 'skim', 'directs', 'cherries', 'removed', 'crescents', 'satisfy', 'chip', 'shape', 'glasses', 'couscous', 'used', 'prefer', 'yummy', 'please', 'barley', 'season', 'size', 'pressure', 'my', 'begin', '46', 'peppers', 'parties', 'prepared', 'kitchen', 'stewing', 'batch', 'dilute', 'consideration', 'stuffing', 'skillets', 'above', 'separately', 'wheat', 'underside', 'decoration', 'mixer', 'toast', 'lowest', 'peaches', 'pretzel', 'melted', 'radishes', '25', 'slash', 'pretty', 'liters', 'rotel', 'limeade', 'disappear', 'beets', 'cabbage', 'herb', 'doesn', 'muffin', '500', 'slicing', 'flounder', 'tube', 'out', 'swans', 'stops', 'teaspoonful', 'quiche', 'twinkies', 'summer', 'separated', 'stiff', 'creamed', 'qt', 'seedless', 'grinder', 'meats', 'rack', 'leaves', 'hickory', 'c', 'plain', 'same', 'grate', 'pearl', 'coca', 'peeling', 'delicately', 'beer', 'dab', 'return', 'twice', 'thickened', 'almond', 'moderately', 'other', 'toward', 'cores', 'plump', 'divide', 'peaks', 'uncovered', 'garlic', 'sections', 'appetizer', 'flaked', 'floating', 'evaporate', 'envelope', 'becomes', 'arrowroot', 'pyrex', 'begins', 'yeast', 'certo', 'firms', 'skin', 'chachere', 'milligrams', '11', 'scrape', 'along', 'mixture', 'moist', 'fluted', 'farm', 'roast', 'jackets', 'poke', 'snow', 'beaters', 'jalapeno', 'natural', 'only', 'stays', 'package', 'devein', 'close', 'cutlets', 'gather', 'coarsely', 'arugula', 'bath', 'soup', 'grapes', 'usual', 'burner', 'left', 'insert', 'turning', 'extracts', 'star', 'cauliflowerets', 'flatter', 'adjust', 'thighs', 'creme', 'chickens', 'protein', 'basil', 'pounds', 'real', 'wrappers', 'whisk', 'heath', 'measured', 'baked', 'stream', 'peak', 'moisten', 'overlapping', 'throughout', 'squeezing', 'this', 'undercooked', 'carton', 'glass', 'jello', 'artichokes', 'brook', 'rigatoni', 'depression', 'bens', 'colby', 'cheese', 'limburger', 'amber', 'meat', 'pitted', 'bologna', 'sweetened', 'several', 'berries', 'chex', 'casserole', 'pop', 'your', 'salt', '17', 'daily', 'retain', 'refrigerator', 'blackeyed', 'venison', 'cheddar', 'wine', '275', 'cranberries', 'cookies', 'au', 'coloring', 'karo', 'circles', 'gone', 'ravioli', 'bringing', 'important', 'settling', 'soaked', 'roses', 'millet', 'ends', 'pineapple', 'crepes', '64', 'horseradish', 'tomato', 'enchilada', 'towel', 'crockpot', 'advance', 'english', 'marshmallow', 'pudding', 'mg', 'seasonings', 'wire', 'pineapples', 'roasted', 'added', '85', 'main', 'substituted', 'finally', 'rectangular', 'shred', 'allspice', 'grains', 'coke', 'top', 'shot', 'salmon', 'crumbled', 'capful', 'pulp', 'cranberry', 'mix', 'raspberry', 'pressing', 'amount', 'follow', 'finely', 'marjoram', 'state', 'jelled', 'raspberries', 'salted', 'its', 'again', 'partially', 'right', 'any', 'meanwhile', 'gas', 'cereals', 'california', 'blintzes', 'old', 'ball', 'manwich', 'lightly', 'stand', 'kielbasa', 'exchange', 'fettucini', 'letting', 'gr', 'grand', 'even', 'diced', 'dipped', 'really', 'stiffen', 'club', 'rectangles', 'guests', 'pears', 'use', 'ribs', 'whirl', 'stuck', 'tasty', 'another', 'chilled', 'spring', 'disappears', 'we', 'covering', 'portion', 'sprinkled', 'others', 'process', 'dew', 'cognac', 'supper', 'v', 'baking', 'steamed', 'pin', 'velveeta', 'navy', '65', 'shaped', 'spray', 'torn', 'non', 'spread', 'warmer', 'scissors', 'halve', 'pot', 'needed', 'soupy', 'covered', 'savory', 'blade', 'picante', '48', 'desired', 'espresso', 'coating', 'batches', 'stands', 'birthday', 'instructions', 'into', 'butternut', 'glossy', 'angle', 'italian', 'dipping', 'bakon', 'warmed', 'fat', 'coconut', 'braise', 'fingers', 'shells', 'marmalade', 'splashing', 'skillet', 'granulated', 'mini', 'bottom', 'miracle', 'shelf', 'toasted', 'crowd', ';', 'teaspoons', 'cukes', 'grams', '2', 'flame', 'whites', 'saucepot', 'soaking', 'number', '9', 'currant', 'gold', 'kraut', 'green', 'deboned', 'side', 'transparent', 'mush', 'poppy', 'popcorn', 'lids', 'i', 'bouillon', 'remains', '13x9', 'home', 'wash', 'palms', 'lump', 'nutmeg', 'various', 'of', 'ground', 'balls', 'wonton', 'safe', 'completely', 'dots', 'foam', 'bit', 'genesis', 'swiss', 'tail', 'paraffin', 'thawed', '8', 'chips', 'stove', 'oreo', 'store', 'serve', 'punch', 'wrap', 'drops', 'cacao', 'brandy', 'bisquick', 'finish', 'champagne', 'every', 'crystal', 'scrub', 'pints', 'on', 'scraping', 'that', 'hands', 'leaving', 'slices', 'beaten', 'flatten', 'rinsing', 'rises', 'vegetables', 'grease', 'firm', 'active', 'kernel', 'blanch', 'bell', 'cakes', 'during', 'knives', 'brussels', 'aside', 'very', 'poultry', 'watch', 'combination', 'after', 'scoops', 'cluster', 'beverages', 'chopper', 'near', 'self', 'oyster', 'flavoring', 'steak', 'moistened', 'crush', 'indirect', 'italianstyle', 'chopped', 'fitting', 'select', 'cauliflower', 'supreme', 'layers', 'diagonal', 'chocolates', 'crisco', 'go', 'prayers', 'griddle', 'colored', 'fasten', 'almonds', 'table', 'raw', 'chitterlings', 'alternating', 'drained', 'spreadable', 'saut', 'people', 'ungreased', 'allow', 'boiled', 'sweetener', 'degrees', 'oleomargarine', 'safflower', 'grapefruit', 'dropping', 'special', 'cholesterol', 'remaining', 'acting', 'hot', 'future', 'packaged', 'wedge', 'piping', 'enjoy', 'soda', 'sandwich', 'chicken', 'tenderloin', 'oblong', 'thirds', 'tuck', 'edges', 'tiny', 'vermicelli', 'bun', 'patty', 'around', 'brine', 'game', 'cross', 'plate', 'curry', 'beginning', 'n', 'individually', 'orzo', 'boneless', 'are', 'alone', 'bread', 'tabasco', 'you', 'shoots', 'mints', '10x', 'crusty', 'meatballs', 'cornmeal', 'working', 'taking', 'prune', 'lemonlime', 'way', 'pimentos', 'watercress', 'within', 'strip', 'easy', 'freezes', 'discarding', 'dates', 'indefinitely', 'mold', 'alcohol', 'crawfish', 'flours', 'unwrap', 'spins', 'dropped', 'deep', 'escape', 'medium', 'third', 'smearing', 'flake', 'mint', 'duty', 'temperature', 'ranch', 'cantaloupe', 'glazed', '300', 'parmesan', 'exchanges', 'oregano', 'included', 'absorb', 'phyllo', 'crepe', 'pasta', 'part', 'soft', 'deli', 'sausages', 'being', 'cools', 'strain', 'own', 'realemon', 'allbran', 'gently', 'packages', 'saltine', 'northern', 'lower', 'peppermint', 'pint', 'contents', 'test', 'juices', 'herbs', 'mascarpone', 'pepperoni', 'pasteurized', 'flower', 'cup', 'roaster', 'hormel', 'amounts', 'wishbone', 'graham', 'flavors', 'seasoned', 'homemade', 'log', 'reduce', 'across', 'slits', 'eight', 'stage', 'draw', 'pour', 'soon', 'juicy', 'full', 'strips', 'equally', 'lay', 'pig', 'generous', 'curls', 'slush', 'granules', 'glutamate', 'hand', 'finger', 'brush', 'proceed', 'suit', 'cutting', 'floured', 'twist', 'now', 'crumbling', 'fish', 'button', 'as', 'tastes', 'wrapper', 'filling', 'chile', 'heavy', 'gravy', 'bombs', 'check', 'perk', 'foamy', 'bars', 'try', 'should', 'cover', 'smoothness', 'toppings', 'salad', 'scorching', 'marinade', 'mace', 'shavings', 'tray', 'bacon', 'much', 'onions', 'fork', 'pimiento', 'still', 'hardened', 'ladle', 'rolling', 'mixtures', 'continually', 'stuff', 'kettle', 'substitute', 'avocado', 'truss', 'pies', 'rolls', 'wedges', 'blueberry', 'warm', 'spanish', 'whipped', 'fruit', 'tight', 'coated', 'puree', 'roasting', 'under', 'smile', 'both', 'fingertips', 'crunchies', 'butterfingers', 'sliced', 'cube', 'lastly', 'cupcake', 'blend', 'shallots', 'pepsi', 'toy', 'knox', 'reserved', 'maraschino', 'mounds', 'stem', 'sets', 'croquette', 'brownies', 'tips', 'hamburgers', 'bermuda', 'bowls', 'peanut', 'avoid', 'thyme', 'put', 'chilli', 'muffins', 'cherry', 'deviled', 'fruits', 'dog', 'foil', 'fry', 'richer', 'better', 'fully', 'best', 'congealed', 'early', 'kahlua', 'looks', 'dividing', 'smoke', 'limas', 'liqueur', 'croutons', 'grits', 'inch', 'jus', 'choc', 'onion', 'months', 'noodles', 'horizontally', 'want', 'pkg', 'sauce', 'molasses', 'sifted', 'opaque', 'll', 'zest', 'quick', 'hershey', 'flavored', 'reduced', 'thick', 'baby', 'sealing', 'line', 'skewer', 'dijon', 'tater', 'filo', 'camembert', 'mustard', 'was', 'cake', 'till', 'ziploc', 'rock', 'loosely', 'hollow', 'cider', 'caraway', 'condensed', 'inside', 'anise', 'sweat', 'browned', 'stay', 'chowder', 'doubled', '80', 'lobster', 'all', 'freeze', 'steep', 'more', 'would', 'plates', 'airtight', 'lamb', 'lumpy', 'it', 'collards', 'vegall', 'cocktail', 'picks', 'breading', 'bittersweet', 'most', 'strings', 'tie', 'elastic', 'freezing', 'slide', '240', 'fluff', 'precooked', 'less', 'omitted', 'soap', 'ladyfingers', 'halves', 'salami', 'prepare', 'persimmons', 'bird', 'strawberry', 'absorbed', 'dump', 'sterilize', '90', 'so', 'sour', 'handle', 'awhile', 'quarter', 'banana', 'mince', 'wafer', 'bubble', 'liver', 'carefully', 'anchovy', 'diagonally', 'style', 's', '3', 'pods', 'keeping', 'hang', 'family', 'solids', 'quickly', 'butterfly', 'maximum', 'needs', 'or', 'giblets', '6', 'jalapenos', 'per', 'sugar', 'balance', 'melts', 'directed', 'day', 'kettles', 'liquid', 'circle', 'choose', 'opening', 'evenly', 'hens', 'pack', 'sunflower', 'sesame', 'quarts', 'candies', 'wait', 'carrot', 'reaches', 'open', 'p', 'buttermilk', 'tall', 'holes', 'decorating', 'removing', 'garnish', 'crank', 'cucumbers', 'cola', 'yum', 'not', 'butterfinger', 'peas', 'figs', 'racks', 'closely', 'one', 'undrained', 'powder', 'loaf', 'nestle', 'dente', 'stroganoff', 'macaroni', 'crumb', 'motion', 'cornish', 'pimento', 'deer', 'cracked', 'tails', 'segments', 'eagle', 'pickles', 'wanted', 'combine', 'their', 'mouth', 'onto', 'trifle', 'rest', 'decorative', 'extremely', 'once', 'sift', 'simmer', '10', 'easier', 'larger', 'mug', 'outer', 'slivered', 'soak', 'saffron', 'melba', 'seasoning', 'relish', 'cornflakes', 'bubbles', 'sides', 'jar', 'waxed', 'hold', 'dissolved', 'always', 'pats', 'maybe', 'parts', 'run', 'flank', 'sticking', 'monde', 'seams', 'fries', 'group', 'sprinkle', 'chop', 'upon', 'corns', 'tortilla', 'heat', 'lot', 'lots', 'fettuccine', 'winter', 'puff', 'reheated', 'either', 'ripe', 'corn', 'mixed', 'the', 'cracker', 'tuna', 'stems', 'purchased', 'chunk', 'rich', 'additional', 'firmly', 'tins', 'crock', 'clams', 'almost', 'continuously', 'mayonnaise', 'ahead', 'pureed', 'breakfast', '1st', 'drink', 'human', 'served', 'making', 'preference', 'granola', 'canning', 'understanding', 'slowly', 'many', 'lined', '24', 'peanuts', 'lasts', 'unsalted', 'never', 'basting', 'hamburg', 'kool', 'oeuvre', 'careful', 'tarragon', 'they', 'room', 'undiluted', 'loin', 'hair', 'bubbling', 'king', 'cole', 'necessary', 'pans', 'volume', 'anchor', 'miniature', 'sherry', 'membranes', 'thousand', 'rye', 'boned', 'mugs', 'transfer', 'caramels', 'parsley', '4', 'frankfurters', 'scrambled', 'hawaiian', 'chunked', 'dozen', 'squares', 'forms', 'tapioca', 'dollop', 'evaporates', 'caps', 'lean', 'checking', 'tears', 'stocks', 'rabbits', 'repeat', 'lasagna', 'a', 'persimmon', 'cashews', 'turnips', 'packed', 'square', 'seems', 'throw', '35', 'crumbly', 'dandelion', 'gloss', 'allowed', 'dry', 'release', 'back', 'ramen', 'coriander', 'seam', 'tamari', 'florets', 'whatever', 'upside', 'hash', 'mixes', 'unmold', 'trout', 'sterilized', 'halved', 'rectangle', 'food', 'spoke', 'spoons', 'paint', 'worcestershire', 'tea', 'drain', 'luke', 'tap', 'tomatoes', 'batter', 'measure', 'poured', 'packet', 'bay', 'mocha', 'total', 'knorr', '20', 'sun', 'smoked', 'need', 'pickling', 'cheesecloth', 'usually', 'thermometer', 'ham', 'shows', 'pea', 'chickpeas', 'edge', 'spiral', 'soy', 'thickening', 'springs', 'pheasant', 'beater', 'few', 'comes', 'slow', 'oreos', 'discard', 'sink', 'hocks', 'waffles', 'marshmallows', '375', 'skins', 'clam', 'remainder', 'resistant', 'equal', 'flavorings', 'optional', 'ounce', 'barbecue', 'thumb', 'like', 'beating', 'jars', '14', 'toothpicks', 'church', 'building', 'outside', 'pliable', 'junior', 'owens', 'nachos', 'custard', 'chestnuts', 'havarti', 'pork', 'blender', 'lengthwise', 'had', 'overmix', 'bean', 'breadcrumbs', 'running', 'lift', 'tossed', 'blossoms', 'saute', 'single', 'blackberries', 'red', 'creaming', 'drizzle', 'coats', 'cupcakes', 'jelly', 'nutmeats', 'holds', 'scallions', 'bring', '60', 'dutch', 'empty', 'seafood', 'cottage', 'turns', 'manufacturer', 'gentle', 'crunch', 'capers', 'increase', 'accent', 'oval', 'aluminum', 'garnishes', 'joy', 'upright', '50', 'has', 'shin', 'stalk', '350', 'kneading', 'setting', 'before', 'pan', 'flavor', 'rotating', 'drippings', 'block', 'corners', 'followed', 'desire', 'lavender', 'carrots', 'air', 'extract', 'piece', '130', 'mountain', 'sack', 'fluffy', 'field', '30', 'portions', '234', 'preheating', 'yogurt', 'eat', 'refrigerated', 'make', 'ready', 'score', 'comino', 'healthy', 'wraps', 'pale', 'blending', 'child', 'dumplings', 'boxes', 'yields', 'peeled', 'stuffed', 'jellyroll', 'holding', 'meal', 'washed', 'gelatine', 'candy', 'mozzarella', 'could', 'taffy', 'an', 'longhorn', 'alum', 'dressing', 'basket', 'change', 'including', 'chinese', 'point', '250', 'alternate', 'lowfat', 'meaty', 'fryer', 'spicy', 'brown', 'frothy', 'get', 'listed', 'eggplant', 'and', 'wide', 'baker', 'row', 'buns', 'monosodium', 'tofu', 'm', '2nd', 'shellfish', 'sherbet', 'starting', 'sharp', 'curdle', 'pectin', 'containers', 'bubbly', 'marble', 'note', 'krispies', 'cream', 'heating', 'frying', 'burn', 'bakes', 'spareribs', 'those', 'margarine', 'wieners', 'popped', 'let', 'together', 'folding', 'consomme', 'bigger', 'narrow', 'milk', 'alternately', 'biscuit', 'worms', 'apart', 'breasts', 'breads', 'pare', 'lengths', 'kosher', 'teaspoonfuls', 'at', 'thin', 'refried', 'prick', 'oysters', 'kidney', 'wild', 'blueberries', 'entire', 'preheat', 'nacho', 'shoulder', 'honey', 'separate', 'citron', 'spooned', 'is', 'cans', 'apples', 'also', 'saucepan', 'mushroom', 'lemon', 'instead', 'tablespoon', 'yolks', 'turned', 'tests', 'limes', 'soba', 'kids', 'do', 'wrapped', 'double', 'sizzling', 'peek', 'move', 'pops', 'mcbutter', 'days', 'party', 'makes', 'sweet', 'chuck', 'person', 'coffee', 'crack', 'stalks', '450', 'roni', 'solution', 'chunky', 'liberally', 'remember', 'equals', 'proof', 'k', 'flowers', 'eaten', 'remain', 'electric', 'ounces', 'bar', 'logs', 'correct', 'tortellini', 'without', 'placed', 'regularly', 'greased', 'fix', 'shut', 'vessel', 'dashes', 'grahams', 'hotter', 'trimmings', 'there', 'peel', 'gumdrops', 'minced', 'hole', 'pumpkin', 'zinfandel', 'push', 'irish', 'give', 'purpose', 'marnier', 'rotate', 'syrup', 'invert', 'regular', 'milnot', 'de', 'hen', 'kale', 'be', 'shears', 'cloves', 'cayenne', 'diluted', 'gruyere', 'ragu', 'hr', 'shiny', 'golden', 'everything', 'wok', 'bran', 'kiss', 'directly', 'brand', 'indention', 'drinks', 'cooks', 'angel', 'loosen', 'squirt', 'moderate', 'kept', 'brushing', 'containing', 'dishes', 'how', 'storage', 'unroll', 'center', 'assorted', 'blackberry', 'steady', 'rather', 'peppercorns', '425', 'ingredient', 'flakes', 'rotelle', 'samuel', '18', 'monterey', 'base', 'hots', 'cubed', 'particles', 'white', 'bananas', 'draft', 'resembles', 'float', 'clumping', 'fun', 'burgers', 'bourbon', 'lunch', '22', 'rings', 'x', 'breaking', 'nuts', 'jack', 'crumble', 'garbanzos', 'absorbent', 'kernels', 'walnut', 'browning', 'chives', '7', 'keep', 'guacamole', 'apply', 'tbsp', 'spots', 'parboil', 'label', 'philadelphia', 'fats', 'maple', 'smash', 'black', 'have', 'hidden', 'allpurpose', 'just', 'head', 'broiler', 'sit', 'turn', 'pieces', 'sage', 'allowing', 'pronged', 'bite', 'yield', 'soften', 'harden', 'seasonall', 'wipe', 'slotted', 'freshly', 'nonfat', 'cubes', 'immediately', 'asparagus', '33', 'scatter', 'lettuce', 'clusters', 'biscuits', 'stick', 'cornbread', 'see', 'stir', 'elephant', 'taco', 'tablespoonfuls', 'leeks', 'squirrels', 'often', 'gummy', 'vigorously', 'swirl', 'pizza', 'broil', 'dissolve', 'pinto', 'such', 'prior', 'tear', 'cornflake', 'securely', 'etc', 'anything', 'zita', 'topped', 'microwavable', 'pretzels', 'candle', 'bagels', 'deeds', 'rivels', '365', 'delicious', 'tidbits', 'mill', 'sheet', 'colander', 'frosting', 'f', 'crescent', 'greens', 'spiced', 'pizzas', 'blue', 'topping', 'fast', '40', 'concentrate', 'nondairy', 'crunchy', 'grain', 'grocery', 'heaping', 'fillet', 'tupperware', 'lighten', 'mallet', 'generously', 'processor', 'cooked', 'olives', 'marsala', 'time', 'bone', 'bitters', 'bundles', 'surround', 'become', 'everyone', 'preserves', 'pound', 'reused', 'type', 'cuts', 'look', 'resemble', 'sorghum', 'xxxx', 'probably', 'confectioners', 'pit', 'broken', 'whole', 'tablespoons', 'alfalfa', 'shrimp', 'perforations', 'hour', 'veal', 'newspaper', 'skewers', 'gallon', 'potatoes', 'too', 'excess', 'does', 'brisket', 'dredge', 'fluid', 'personal', 'kisses', 'below', 'mushrooms', 'altogether', 'mango', 'enchiladas', 'cracks', 'surface', '45', 'limp', 'find', 'favorite', 'than', 'crispies', 'grill', 'rhubarb', '9x13', 'if', 'layer', '32', 'similar', 'softened', 'individual', 'new', 'island', 'thickens', 'grenadine', 'preparing', 'mexican', 'when', 'rapidly', 'sieve', '112', 'boston', 're', 'uncooked', 'pancake', 'puffs', 'linguine', 'shake', 'lasagne', 'luncheon', 'gelatin', 'whitefish', 'aid', 'tostitos', 'steaks', 'garnished', 'lemons', 'fritos', 'closed', 'skinless', 'exactly', 'arrange', 'fold', 'crosswise', 'until', 'crumbs', 'wet', 'oil', 'measuring', 'cereal', 'break', 'something', 'sooner', 'crisp', 'stewed', 'sec', 'steel', 'goes', '5', 'incorporate', 'handful', 'order', 'second', 'paprika', 'root', 'mayo', 'walnuts', 'canola', 'clean', 'through', 'solid', 'chops', 'uncover', 'bulk', 'called', 'least', 'sauerkraut', 'squeezed', 'helps', 'must', 'towels', 'tied', 'germ', 'mostaccioli', 'pistachio', '150', 'dunk', 'will', 'given', 'sticky', 'wings', 'dessert', 'create', 'thicken', 'briefly', 'spatula', 't', 'apricot', 'cucumber', '325', 'al', 'themselves', 'come', 'diet', 'large', 'pimientos', '23', 'taken', 'down', 'appear', 'artificial', 'puffy', 'bones', 'wesson', 'g', 'saucer', 'groundhog', 'mullet', 'week', 'teaspoon', 'don', 'five', 'seasons', 'placing', 'iron', 'rice', 'nearly', 'starts', 'cracklins', 'touching', 'ziti', 'stirred', 'fashioned', 'triangle', 'vent', 'avocados', 'freezer', 'peck', 'counter', 'romaine', 'oz', 'chipped', 'frost', 'stiffly', 'clove', 'door', 'scallops', 'flowerets', 'country', 'frypan', 'niblets', 'reserving', 'spears', 'icebox', 'cooling', 'degree', 'middle', 'gradually', 'lard', 'carman', 'burning', 'broccoli', 'reheat', 'pear', 'baste', 'off', 'liners', 'mixing', 'scramble', 'syrupy', 'whip', 'pie', 'dippers', 'fridge', 'simmering', 'icing', 'bowl', 'diameter', 'sprinkling', 'slight', 'ensure', 'decorate', 'pam', 'waverly', 'able', 'fondant', 'wooden', '370', 'while', 'itself', 'can', 'countertop', 'morning', 'excellent', 'layering', 'amaretto', 'high', 'these', 'whiz', 'flaky', 'paste', 'quart', 'nectar', 'away', 'thread', 'oat', 'prebaked', 'stack', 'over', 'peach', 'creamette', 'puffed', 'liquor', 'seem', 'finished', 'doneness', 'plastic', 'squirrel', 'artichoke', 'squash', 'garbanzo', '475', 'appearance', 'potato', 'weeks', 'prep', 'blanched', 'masher', 'toss', 'baguette', 'paper', 'cooker', 'add', 'gumbo', 'thaw', 'tinfoil', 'flattened', 'following', 'thickness', 'doritos', 'cookie', 'cut', 'congeal', 'dream', 'intact', 'press', 'start', 'rub', 'nine', 'crabmeat', 'because', 'color', 'butterscotch', 'thicker', 'stirring', 'quarters', 'power', 'may', 'grape', 'scoop', 'cornstarch', 'shapes', 'catsup', 'barely', 'hollowed', 'brownie', 'cups', 'palm', 'strokes', 'frozen', 'jam', 'pecans', 'mein', 'four', 'preparation', 'christmas', 'obrien', 'neck', 'sandwiches', 'cajun', 'contains', 'no', 'loose', 'translucent', 'nut', 'mandarin', 'scramblers', 'gouda', 'stone', 'triangles', 'rum', 'hamburger', 'fit', 'later', 'scant', 'lemonade', 'boiling', '15', 'melt', 'boiler', '12', 'creole', 'quantity', 'inches', 'ritz', 'awful', 'grilled', 'tortillas', 'sprigs', 'depth', 'chilies', 'helpings', 'items', 'hi', 'by', 'lukewarm', 'width', 'birds', 'pancakes', 'preferred', 'tender', 'butterflied', 'packets', 'vegetable', 'unbaked', 'envelopes', 'pinch', 'ingredients', 'prunes', 'board', 'balsamic', 'tongs', 'spinach', 'fudge', 'kind', 'already', 'olive', 'which', 'box', 'basic', 'each', 'says', 'month', 'bottle', 'pulled', 'oranges', 'approximately', 'holidays', 'turkey', 'pulls', 'stored', 'clings', 'keeps', 'easily', 'medal', '400', 'crab', 'elbow']\n"
     ]
    }
   ],
   "source": [
    "# calculate word frequency from directions and ingredients list (NER)\n",
    "if pre_processing == True:\n",
    "    \n",
    "    word_freq = collections.Counter()\n",
    "    for i, row in tokenized_nlg_df.iterrows():\n",
    "        for word in row.combined_directions:\n",
    "            word_freq[word] += 1\n",
    "        \n",
    "        for word in row.combined_ingredients:\n",
    "            word_freq[word] += 1\n",
    "    \n",
    "    minimum_word_freq = 2\n",
    "    vocab, ignored_words = set(), set()\n",
    "    for word, freq in word_freq.items():\n",
    "        if word_freq[word] >= minimum_word_freq:\n",
    "            vocab.add(word) \n",
    "        else:\n",
    "            ignored_words.add(word)\n",
    "            \n",
    "    for word in ignored_words:\n",
    "        del word_freq[word]\n",
    "\n",
    "    print('Unique words before ignoring:', len(vocab) + len(ignored_words))\n",
    "    print('Unique words after ignoring:', len(vocab))\n",
    "\n",
    "    vocab = list(vocab)\n",
    "    json.dump(vocab, open('./data/vocab.json', 'w'))\n",
    "\n",
    "    print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raisin': 0, 'fitted': 1, 'yams': 2, 'snack': 3, 'wish': 4, 'chutney': 5, 'service': 6, 'hunger': 7, 'pizzelle': 8, 'tubs': 9, 'celery': 10, 'prayer': 11, 'dot': 12, 'headspace': 13, 'chill': 14, 'sprayed': 15, 'faith': 16, 'uv': 17, 'stockpot': 18, 'puddings': 19, 'valley': 20, '16': 21, 'overnight': 22, 'hock': 23, 'rim': 24, 'vegies': 25, 'coals': 26, 'atop': 27, 'pepperidge': 28, 'semisweet': 29, 'sifting': 30, 'prawns': 31, 'results': 32, 'rind': 33, 'teflon': 34, 'joe': 35, 'nicely': 36, 'nice': 37, 'caramel': 38, 'sear': 39, 'gets': 40, 'bake': 41, 'water': 42, 'hours': 43, 'knead': 44, 'sprouts': 45, 'dip': 46, 'crystallized': 47, 'pumpernickel': 48, 'salads': 49, 'bits': 50, 'reynolds': 51, 'soups': 52, 'tart': 53, 'slaw': 54, 'rolled': 55, 'filled': 56, 'splenda': 57, 'putting': 58, 'cilantro': 59, 'free': 60, 'showers': 61, 'treat': 62, 'veggies': 63, 'carnation': 64, 'cokes': 65, 'clear': 66, 'rosemary': 67, 'halibut': 68, 'chafing': 69, 'sundae': 70, 'sterile': 71, 'directions': 72, 'sealed': 73, 'saving': 74, 'minutes': 75, 'wilted': 76, 'consistency': 77, 'currants': 78, 'speed': 79, 'coarse': 80, 'combined': 81, '0': 82, 'liquids': 83, 'fill': 84, 'slice': 85, 'flute': 86, 'tin': 87, 'sure': 88, 'tartar': 89, 'seconds': 90, 'crackers': 91, 'uncle': 92, 'duncan': 93, 'burritos': 94, 'spreading': 95, 'vermouth': 96, 'fist': 97, 'starter': 98, 'half': 99, 'pull': 100, 'sticks': 101, 'pitcher': 102, 'kiwi': 103, 'couple': 104, 'sugars': 105, 'tel': 106, 'bitter': 107, 'life': 108, 'confectioner': 109, 'orange': 110, 'hard': 111, 'liter': 112, 'evaporated': 113, 'stock': 114, 'chilling': 115, 'rinse': 116, 'cleaned': 117, 'butter': 118, 'vodka': 119, 'ro': 120, 'jicama': 121, 'fire': 122, 'crimp': 123, 'adding': 124, 'raise': 125, 'mushy': 126, 'platter': 127, 'powdered': 128, 'oats': 129, 'reserve': 130, 'linguini': 131, 'cocoa': 132, 'tester': 133, 'container': 134, 'bark': 135, 'insides': 136, 'cumin': 137, 'love': 138, 'beat': 139, 'big': 140, 'won': 141, 'seal': 142, 'then': 143, 'crushed': 144, 'addition': 145, 'sheets': 146, 'method': 147, 'to': 148, 'cinnamon': 149, 'dish': 150, 'starch': 151, 'grated': 152, 'place': 153, 'cob': 154, 'fall': 155, 'mine': 156, 'original': 157, 'spoon': 158, 'constantly': 159, 'papers': 160, 'rims': 161, 'made': 162, 'unflavored': 163, 'sweeter': 164, 'smooth': 165, 'peppercorn': 166, 'fillets': 167, 'omit': 168, 'fresh': 169, 'teriyaki': 170, 'dirt': 171, 'kindly': 172, 'ale': 173, 'sausage': 174, 'roux': 175, 'takes': 176, 'sauteed': 177, 'hominy': 178, 'enough': 179, 'dash': 180, 'option': 181, 'inserted': 182, 'roughy': 183, 'pick': 184, 'eggs': 185, 'cool': 186, 'end': 187, 'pile': 188, 'rinsed': 189, 'gallons': 190, 'yolk': 191, 'depending': 192, 'hors': 193, 'fits': 194, 'dice': 195, 'spice': 196, 'sugared': 197, 'marinate': 198, 'remove': 199, 'oiled': 200, 'chestnut': 201, 'sized': 202, 'in': 203, 'actually': 204, 'lawry': 205, 'microwave': 206, 'shoyu': 207, 'ketchup': 208, 'work': 209, 'cheeses': 210, 'dark': 211, 'minute': 212, 'crystals': 213, 'macadamia': 214, 'corned': 215, 'serves': 216, 'frequently': 217, 'raisins': 218, 'serving': 219, 'preferably': 220, 'cook': 221, 'ovenproof': 222, 'fine': 223, 'works': 224, 'long': 225, 'shallow': 226, 'set': 227, 'zucchini': 228, 'thickest': 229, 'control': 230, 'wax': 231, 'pink': 232, 'metal': 233, 'night': 234, 'what': 235, 'sole': 236, 'some': 237, 'kraft': 238, 'ricotta': 239, 'rubber': 240, 'dill': 241, 'fairly': 242, 'dogs': 243, 'apple': 244, 'triple': 245, 'here': 246, 'sprinkles': 247, 'achiote': 248, 'eggbeater': 249, 'seed': 250, 'instant': 251, 'form': 252, 'rise': 253, 'tines': 254, 'fashion': 255, 'tip': 256, 'sprite': 257, 'thoroughly': 258, 'd': 259, 'tots': 260, 'runs': 261, 'beans': 262, 'choice': 263, 'for': 264, '36': 265, 'feet': 266, 'creamy': 267, 'liking': 268, 'emulsify': 269, 'times': 270, 'dust': 271, 'leftover': 272, 'debone': 273, 'doubleacting': 274, 'replace': 275, 'heads': 276, 'delightful': 277, 'rotary': 278, '86': 279, 'beef': 280, 'great': 281, 'low': 282, 'cutter': 283, 'cloth': 284, 'applesauce': 285, 'cooled': 286, 'continue': 287, 'drop': 288, 'sodium': 289, 'loses': 290, 'two': 291, 'been': 292, 'o': 293, 'overbeat': 294, 'whiskey': 295, 'garden': 296, 'slab': 297, 'doing': 298, 'scald': 299, 'sympathy': 300, 'longer': 301, '55': 302, 'peg': 303, 'requires': 304, 'up': 305, 'covers': 306, 'thinner': 307, 'rotini': 308, 'tsp': 309, 'parkay': 310, 'browns': 311, 'distribute': 312, 'partly': 313, '120': 314, 'turmeric': 315, 'min': 316, 'thinly': 317, 'creamer': 318, 'yellow': 319, 'blended': 320, 'strainer': 321, 'kindness': 322, 'sparkling': 323, 'bundt': 324, 'sourdough': 325, 'occasionally': 326, 'mound': 327, 'imitation': 328, 'fettucine': 329, 'chocolate': 330, 'light': 331, 'funnel': 332, 'flour': 333, 'extra': 334, 'dried': 335, 'meringue': 336, 'mashed': 337, 'sorrow': 338, 'glaze': 339, 'stars': 340, 'sandies': 341, 'shaking': 342, 'roll': 343, 'normally': 344, 'forming': 345, 'microcook': 346, 'overcook': 347, 'canned': 348, 'tapped': 349, 'lentils': 350, 'loaves': 351, 'buttered': 352, 'leftovers': 353, 'halfway': 354, 'using': 355, 'rabbit': 356, 'feta': 357, 'saran': 358, 'leave': 359, 'oatmeal': 360, '9x9': 361, 'parchment': 362, 'cheez': 363, 'clump': 364, 'calories': 365, 'ginger': 366, 'section': 367, 'chewy': 368, 'colors': 369, 'points': 370, 'salsa': 371, 'jell': 372, 'enclose': 373, 'step': 374, 'weed': 375, 'runny': 376, 'lid': 377, 'feed': 378, 'dome': 379, 'saved': 380, 'perhaps': 381, '70': 382, 'from': 383, 'purple': 384, 'chili': 385, 'little': 386, 'shell': 387, 'bed': 388, 'core': 389, 'morsels': 390, 'pith': 391, 'secure': 392, 'taste': 393, 'prevent': 394, 'inverted': 395, 'drying': 396, 'squeeze': 397, 'boil': 398, 'frosted': 399, 'slightly': 400, 'melting': 401, 'stew': 402, 'husks': 403, 'pepperoncini': 404, 'slit': 405, 'shortening': 406, 'souffle': 407, 'pickle': 408, 'molds': 409, 'spoonful': 410, 'among': 411, 'sweeten': 412, 'position': 413, 'variety': 414, 'haddock': 415, 'unpeeled': 416, 'tint': 417, 'pocket': 418, 'machine': 419, 'eggnog': 420, 'nonstick': 421, 'chunks': 422, 'preheated': 423, 'hearts': 424, 'shredded': 425, 'catalina': 426, 'legs': 427, 'steadily': 428, 'pulling': 429, 'strawberries': 430, 'according': 431, 'pastry': 432, 'provolone': 433, 'patties': 434, 'coal': 435, 'saltwater': 436, 'saifon': 437, 'scalded': 438, 'drumsticks': 439, 'mash': 440, 'lima': 441, 'crumbles': 442, 'steam': 443, 'except': 444, 'save': 445, 'sirloin': 446, 'duck': 447, 'vanilla': 448, 'different': 449, 'pet': 450, 'last': 451, 'seeds': 452, '8ths': 453, 'procedure': 454, 'damp': 455, 'formed': 456, 'noodle': 457, 'bottles': 458, 'dough': 459, 'buy': 460, 'pouring': 461, 'egg': 462, 'lumps': 463, 'stop': 464, 'rounded': 465, 'peaked': 466, 'shaker': 467, 'pattern': 468, 'help': 469, 'spoonfuls': 470, 'tamales': 471, 'plus': 472, 'unsweetened': 473, 'ice': 474, 'anchovies': 475, 'servings': 476, 'available': 477, 'gel': 478, 'oven': 479, 'virgin': 480, 'oleo': 481, 'stretch': 482, 'take': 483, 'pepper': 484, 'circular': 485, 'franks': 486, 'pat': 487, '100': 488, 'having': 489, 'complete': 490, 'romano': 491, 'cardamom': 492, 'dampen': 493, 'continuing': 494, 'pebbles': 495, 'going': 496, 'changes': 497, 'trays': 498, 'trim': 499, 'about': 500, 'whipping': 501, 'cast': 502, 'quite': 503, 'campbell': 504, '1': 505, 'mexicorn': 506, 'between': 507, 'first': 508, 'sauces': 509, 'overbake': 510, 'ending': 511, 'tough': 512, 'follows': 513, 'smaller': 514, 'chillies': 515, 'salty': 516, 'golf': 517, 'rows': 518, 'toothpick': 519, 'pecan': 520, 'bag': 521, 'unbeaten': 522, 'moisture': 523, 'touched': 524, 'coat': 525, 'simply': 526, 'tablespoonful': 527, 'watermelon': 528, 'sort': 529, 'french': 530, 'pressed': 531, 'american': 532, 'canadian': 533, 'heatproof': 534, 'tightly': 535, 'level': 536, 'cold': 537, 'refrigerate': 538, 'juice': 539, 'tvp': 540, '200': 541, 'good': 542, 'cocacola': 543, 'crispy': 544, 'cooking': 545, 'split': 546, 'pointed': 547, 'average': 548, 'flat': 549, 'possible': 550, 'dinner': 551, 'small': 552, 'spices': 553, 'feeds': 554, 'but': 555, 'dissolves': 556, 'centers': 557, 'next': 558, 'ones': 559, 'gives': 560, '13': 561, 'chow': 562, 'spaghetti': 563, 'children': 564, 'lime': 565, 'cheerios': 566, 'texture': 567, 'done': 568, 'fried': 569, 'three': 570, 'tops': 571, 'well': 572, 'blot': 573, 'rounds': 574, 'knife': 575, 'bamboo': 576, 'broth': 577, 'touch': 578, 'leaf': 579, 'candied': 580, 'them': 581, 'bags': 582, 'chiles': 583, 'crust': 584, 'vinegar': 585, 'wafers': 586, 'penne': 587, 'approx': 588, 'bottoms': 589, 'six': 590, 'crusts': 591, 'quartered': 592, 'tan': 593, 'lite': 594, 'handling': 595, 'against': 596, '75': 597, 'heated': 598, 'boils': 599, 'separates': 600, 'largest': 601, 'apricots': 602, 'russian': 603, 'string': 604, 'round': 605, 'grind': 606, 'criss': 607, 'creamstyle': 608, 'okra': 609, 'leak': 610, 'weather': 611, 'standing': 612, 'campbells': 613, 'tossing': 614, 'recipe': 615, 'eating': 616, 'ring': 617, 'age': 618, 'beet': 619, 'with': 620, 'cutters': 621, 'breast': 622, 'semi': 623, 'skim': 624, 'directs': 625, 'cherries': 626, 'removed': 627, 'crescents': 628, 'satisfy': 629, 'chip': 630, 'shape': 631, 'glasses': 632, 'couscous': 633, 'used': 634, 'prefer': 635, 'yummy': 636, 'please': 637, 'barley': 638, 'season': 639, 'size': 640, 'pressure': 641, 'my': 642, 'begin': 643, '46': 644, 'peppers': 645, 'parties': 646, 'prepared': 647, 'kitchen': 648, 'stewing': 649, 'batch': 650, 'dilute': 651, 'consideration': 652, 'stuffing': 653, 'skillets': 654, 'above': 655, 'separately': 656, 'wheat': 657, 'underside': 658, 'decoration': 659, 'mixer': 660, 'toast': 661, 'lowest': 662, 'peaches': 663, 'pretzel': 664, 'melted': 665, 'radishes': 666, '25': 667, 'slash': 668, 'pretty': 669, 'liters': 670, 'rotel': 671, 'limeade': 672, 'disappear': 673, 'beets': 674, 'cabbage': 675, 'herb': 676, 'doesn': 677, 'muffin': 678, '500': 679, 'slicing': 680, 'flounder': 681, 'tube': 682, 'out': 683, 'swans': 684, 'stops': 685, 'teaspoonful': 686, 'quiche': 687, 'twinkies': 688, 'summer': 689, 'separated': 690, 'stiff': 691, 'creamed': 692, 'qt': 693, 'seedless': 694, 'grinder': 695, 'meats': 696, 'rack': 697, 'leaves': 698, 'hickory': 699, 'c': 700, 'plain': 701, 'same': 702, 'grate': 703, 'pearl': 704, 'coca': 705, 'peeling': 706, 'delicately': 707, 'beer': 708, 'dab': 709, 'return': 710, 'twice': 711, 'thickened': 712, 'almond': 713, 'moderately': 714, 'other': 715, 'toward': 716, 'cores': 717, 'plump': 718, 'divide': 719, 'peaks': 720, 'uncovered': 721, 'garlic': 722, 'sections': 723, 'appetizer': 724, 'flaked': 725, 'floating': 726, 'evaporate': 727, 'envelope': 728, 'becomes': 729, 'arrowroot': 730, 'pyrex': 731, 'begins': 732, 'yeast': 733, 'certo': 734, 'firms': 735, 'skin': 736, 'chachere': 737, 'milligrams': 738, '11': 739, 'scrape': 740, 'along': 741, 'mixture': 742, 'moist': 743, 'fluted': 744, 'farm': 745, 'roast': 746, 'jackets': 747, 'poke': 748, 'snow': 749, 'beaters': 750, 'jalapeno': 751, 'natural': 752, 'only': 753, 'stays': 754, 'package': 755, 'devein': 756, 'close': 757, 'cutlets': 758, 'gather': 759, 'coarsely': 760, 'arugula': 761, 'bath': 762, 'soup': 763, 'grapes': 764, 'usual': 765, 'burner': 766, 'left': 767, 'insert': 768, 'turning': 769, 'extracts': 770, 'star': 771, 'cauliflowerets': 772, 'flatter': 773, 'adjust': 774, 'thighs': 775, 'creme': 776, 'chickens': 777, 'protein': 778, 'basil': 779, 'pounds': 780, 'real': 781, 'wrappers': 782, 'whisk': 783, 'heath': 784, 'measured': 785, 'baked': 786, 'stream': 787, 'peak': 788, 'moisten': 789, 'overlapping': 790, 'throughout': 791, 'squeezing': 792, 'this': 793, 'undercooked': 794, 'carton': 795, 'glass': 796, 'jello': 797, 'artichokes': 798, 'brook': 799, 'rigatoni': 800, 'depression': 801, 'bens': 802, 'colby': 803, 'cheese': 804, 'limburger': 805, 'amber': 806, 'meat': 807, 'pitted': 808, 'bologna': 809, 'sweetened': 810, 'several': 811, 'berries': 812, 'chex': 813, 'casserole': 814, 'pop': 815, 'your': 816, 'salt': 817, '17': 818, 'daily': 819, 'retain': 820, 'refrigerator': 821, 'blackeyed': 822, 'venison': 823, 'cheddar': 824, 'wine': 825, '275': 826, 'cranberries': 827, 'cookies': 828, 'au': 829, 'coloring': 830, 'karo': 831, 'circles': 832, 'gone': 833, 'ravioli': 834, 'bringing': 835, 'important': 836, 'settling': 837, 'soaked': 838, 'roses': 839, 'millet': 840, 'ends': 841, 'pineapple': 842, 'crepes': 843, '64': 844, 'horseradish': 845, 'tomato': 846, 'enchilada': 847, 'towel': 848, 'crockpot': 849, 'advance': 850, 'english': 851, 'marshmallow': 852, 'pudding': 853, 'mg': 854, 'seasonings': 855, 'wire': 856, 'pineapples': 857, 'roasted': 858, 'added': 859, '85': 860, 'main': 861, 'substituted': 862, 'finally': 863, 'rectangular': 864, 'shred': 865, 'allspice': 866, 'grains': 867, 'coke': 868, 'top': 869, 'shot': 870, 'salmon': 871, 'crumbled': 872, 'capful': 873, 'pulp': 874, 'cranberry': 875, 'mix': 876, 'raspberry': 877, 'pressing': 878, 'amount': 879, 'follow': 880, 'finely': 881, 'marjoram': 882, 'state': 883, 'jelled': 884, 'raspberries': 885, 'salted': 886, 'its': 887, 'again': 888, 'partially': 889, 'right': 890, 'any': 891, 'meanwhile': 892, 'gas': 893, 'cereals': 894, 'california': 895, 'blintzes': 896, 'old': 897, 'ball': 898, 'manwich': 899, 'lightly': 900, 'stand': 901, 'kielbasa': 902, 'exchange': 903, 'fettucini': 904, 'letting': 905, 'gr': 906, 'grand': 907, 'even': 908, 'diced': 909, 'dipped': 910, 'really': 911, 'stiffen': 912, 'club': 913, 'rectangles': 914, 'guests': 915, 'pears': 916, 'use': 917, 'ribs': 918, 'whirl': 919, 'stuck': 920, 'tasty': 921, 'another': 922, 'chilled': 923, 'spring': 924, 'disappears': 925, 'we': 926, 'covering': 927, 'portion': 928, 'sprinkled': 929, 'others': 930, 'process': 931, 'dew': 932, 'cognac': 933, 'supper': 934, 'v': 935, 'baking': 936, 'steamed': 937, 'pin': 938, 'velveeta': 939, 'navy': 940, '65': 941, 'shaped': 942, 'spray': 943, 'torn': 944, 'non': 945, 'spread': 946, 'warmer': 947, 'scissors': 948, 'halve': 949, 'pot': 950, 'needed': 951, 'soupy': 952, 'covered': 953, 'savory': 954, 'blade': 955, 'picante': 956, '48': 957, 'desired': 958, 'espresso': 959, 'coating': 960, 'batches': 961, 'stands': 962, 'birthday': 963, 'instructions': 964, 'into': 965, 'butternut': 966, 'glossy': 967, 'angle': 968, 'italian': 969, 'dipping': 970, 'bakon': 971, 'warmed': 972, 'fat': 973, 'coconut': 974, 'braise': 975, 'fingers': 976, 'shells': 977, 'marmalade': 978, 'splashing': 979, 'skillet': 980, 'granulated': 981, 'mini': 982, 'bottom': 983, 'miracle': 984, 'shelf': 985, 'toasted': 986, 'crowd': 987, ';': 988, 'teaspoons': 989, 'cukes': 990, 'grams': 991, '2': 992, 'flame': 993, 'whites': 994, 'saucepot': 995, 'soaking': 996, 'number': 997, '9': 998, 'currant': 999, 'gold': 1000, 'kraut': 1001, 'green': 1002, 'deboned': 1003, 'side': 1004, 'transparent': 1005, 'mush': 1006, 'poppy': 1007, 'popcorn': 1008, 'lids': 1009, 'i': 1010, 'bouillon': 1011, 'remains': 1012, '13x9': 1013, 'home': 1014, 'wash': 1015, 'palms': 1016, 'lump': 1017, 'nutmeg': 1018, 'various': 1019, 'of': 1020, 'ground': 1021, 'balls': 1022, 'wonton': 1023, 'safe': 1024, 'completely': 1025, 'dots': 1026, 'foam': 1027, 'bit': 1028, 'genesis': 1029, 'swiss': 1030, 'tail': 1031, 'paraffin': 1032, 'thawed': 1033, '8': 1034, 'chips': 1035, 'stove': 1036, 'oreo': 1037, 'store': 1038, 'serve': 1039, 'punch': 1040, 'wrap': 1041, 'drops': 1042, 'cacao': 1043, 'brandy': 1044, 'bisquick': 1045, 'finish': 1046, 'champagne': 1047, 'every': 1048, 'crystal': 1049, 'scrub': 1050, 'pints': 1051, 'on': 1052, 'scraping': 1053, 'that': 1054, 'hands': 1055, 'leaving': 1056, 'slices': 1057, 'beaten': 1058, 'flatten': 1059, 'rinsing': 1060, 'rises': 1061, 'vegetables': 1062, 'grease': 1063, 'firm': 1064, 'active': 1065, 'kernel': 1066, 'blanch': 1067, 'bell': 1068, 'cakes': 1069, 'during': 1070, 'knives': 1071, 'brussels': 1072, 'aside': 1073, 'very': 1074, 'poultry': 1075, 'watch': 1076, 'combination': 1077, 'after': 1078, 'scoops': 1079, 'cluster': 1080, 'beverages': 1081, 'chopper': 1082, 'near': 1083, 'self': 1084, 'oyster': 1085, 'flavoring': 1086, 'steak': 1087, 'moistened': 1088, 'crush': 1089, 'indirect': 1090, 'italianstyle': 1091, 'chopped': 1092, 'fitting': 1093, 'select': 1094, 'cauliflower': 1095, 'supreme': 1096, 'layers': 1097, 'diagonal': 1098, 'chocolates': 1099, 'crisco': 1100, 'go': 1101, 'prayers': 1102, 'griddle': 1103, 'colored': 1104, 'fasten': 1105, 'almonds': 1106, 'table': 1107, 'raw': 1108, 'chitterlings': 1109, 'alternating': 1110, 'drained': 1111, 'spreadable': 1112, 'saut': 1113, 'people': 1114, 'ungreased': 1115, 'allow': 1116, 'boiled': 1117, 'sweetener': 1118, 'degrees': 1119, 'oleomargarine': 1120, 'safflower': 1121, 'grapefruit': 1122, 'dropping': 1123, 'special': 1124, 'cholesterol': 1125, 'remaining': 1126, 'acting': 1127, 'hot': 1128, 'future': 1129, 'packaged': 1130, 'wedge': 1131, 'piping': 1132, 'enjoy': 1133, 'soda': 1134, 'sandwich': 1135, 'chicken': 1136, 'tenderloin': 1137, 'oblong': 1138, 'thirds': 1139, 'tuck': 1140, 'edges': 1141, 'tiny': 1142, 'vermicelli': 1143, 'bun': 1144, 'patty': 1145, 'around': 1146, 'brine': 1147, 'game': 1148, 'cross': 1149, 'plate': 1150, 'curry': 1151, 'beginning': 1152, 'n': 1153, 'individually': 1154, 'orzo': 1155, 'boneless': 1156, 'are': 1157, 'alone': 1158, 'bread': 1159, 'tabasco': 1160, 'you': 1161, 'shoots': 1162, 'mints': 1163, '10x': 1164, 'crusty': 1165, 'meatballs': 1166, 'cornmeal': 1167, 'working': 1168, 'taking': 1169, 'prune': 1170, 'lemonlime': 1171, 'way': 1172, 'pimentos': 1173, 'watercress': 1174, 'within': 1175, 'strip': 1176, 'easy': 1177, 'freezes': 1178, 'discarding': 1179, 'dates': 1180, 'indefinitely': 1181, 'mold': 1182, 'alcohol': 1183, 'crawfish': 1184, 'flours': 1185, 'unwrap': 1186, 'spins': 1187, 'dropped': 1188, 'deep': 1189, 'escape': 1190, 'medium': 1191, 'third': 1192, 'smearing': 1193, 'flake': 1194, 'mint': 1195, 'duty': 1196, 'temperature': 1197, 'ranch': 1198, 'cantaloupe': 1199, 'glazed': 1200, '300': 1201, 'parmesan': 1202, 'exchanges': 1203, 'oregano': 1204, 'included': 1205, 'absorb': 1206, 'phyllo': 1207, 'crepe': 1208, 'pasta': 1209, 'part': 1210, 'soft': 1211, 'deli': 1212, 'sausages': 1213, 'being': 1214, 'cools': 1215, 'strain': 1216, 'own': 1217, 'realemon': 1218, 'allbran': 1219, 'gently': 1220, 'packages': 1221, 'saltine': 1222, 'northern': 1223, 'lower': 1224, 'peppermint': 1225, 'pint': 1226, 'contents': 1227, 'test': 1228, 'juices': 1229, 'herbs': 1230, 'mascarpone': 1231, 'pepperoni': 1232, 'pasteurized': 1233, 'flower': 1234, 'cup': 1235, 'roaster': 1236, 'hormel': 1237, 'amounts': 1238, 'wishbone': 1239, 'graham': 1240, 'flavors': 1241, 'seasoned': 1242, 'homemade': 1243, 'log': 1244, 'reduce': 1245, 'across': 1246, 'slits': 1247, 'eight': 1248, 'stage': 1249, 'draw': 1250, 'pour': 1251, 'soon': 1252, 'juicy': 1253, 'full': 1254, 'strips': 1255, 'equally': 1256, 'lay': 1257, 'pig': 1258, 'generous': 1259, 'curls': 1260, 'slush': 1261, 'granules': 1262, 'glutamate': 1263, 'hand': 1264, 'finger': 1265, 'brush': 1266, 'proceed': 1267, 'suit': 1268, 'cutting': 1269, 'floured': 1270, 'twist': 1271, 'now': 1272, 'crumbling': 1273, 'fish': 1274, 'button': 1275, 'as': 1276, 'tastes': 1277, 'wrapper': 1278, 'filling': 1279, 'chile': 1280, 'heavy': 1281, 'gravy': 1282, 'bombs': 1283, 'check': 1284, 'perk': 1285, 'foamy': 1286, 'bars': 1287, 'try': 1288, 'should': 1289, 'cover': 1290, 'smoothness': 1291, 'toppings': 1292, 'salad': 1293, 'scorching': 1294, 'marinade': 1295, 'mace': 1296, 'shavings': 1297, 'tray': 1298, 'bacon': 1299, 'much': 1300, 'onions': 1301, 'fork': 1302, 'pimiento': 1303, 'still': 1304, 'hardened': 1305, 'ladle': 1306, 'rolling': 1307, 'mixtures': 1308, 'continually': 1309, 'stuff': 1310, 'kettle': 1311, 'substitute': 1312, 'avocado': 1313, 'truss': 1314, 'pies': 1315, 'rolls': 1316, 'wedges': 1317, 'blueberry': 1318, 'warm': 1319, 'spanish': 1320, 'whipped': 1321, 'fruit': 1322, 'tight': 1323, 'coated': 1324, 'puree': 1325, 'roasting': 1326, 'under': 1327, 'smile': 1328, 'both': 1329, 'fingertips': 1330, 'crunchies': 1331, 'butterfingers': 1332, 'sliced': 1333, 'cube': 1334, 'lastly': 1335, 'cupcake': 1336, 'blend': 1337, 'shallots': 1338, 'pepsi': 1339, 'toy': 1340, 'knox': 1341, 'reserved': 1342, 'maraschino': 1343, 'mounds': 1344, 'stem': 1345, 'sets': 1346, 'croquette': 1347, 'brownies': 1348, 'tips': 1349, 'hamburgers': 1350, 'bermuda': 1351, 'bowls': 1352, 'peanut': 1353, 'avoid': 1354, 'thyme': 1355, 'put': 1356, 'chilli': 1357, 'muffins': 1358, 'cherry': 1359, 'deviled': 1360, 'fruits': 1361, 'dog': 1362, 'foil': 1363, 'fry': 1364, 'richer': 1365, 'better': 1366, 'fully': 1367, 'best': 1368, 'congealed': 1369, 'early': 1370, 'kahlua': 1371, 'looks': 1372, 'dividing': 1373, 'smoke': 1374, 'limas': 1375, 'liqueur': 1376, 'croutons': 1377, 'grits': 1378, 'inch': 1379, 'jus': 1380, 'choc': 1381, 'onion': 1382, 'months': 1383, 'noodles': 1384, 'horizontally': 1385, 'want': 1386, 'pkg': 1387, 'sauce': 1388, 'molasses': 1389, 'sifted': 1390, 'opaque': 1391, 'll': 1392, 'zest': 1393, 'quick': 1394, 'hershey': 1395, 'flavored': 1396, 'reduced': 1397, 'thick': 1398, 'baby': 1399, 'sealing': 1400, 'line': 1401, 'skewer': 1402, 'dijon': 1403, 'tater': 1404, 'filo': 1405, 'camembert': 1406, 'mustard': 1407, 'was': 1408, 'cake': 1409, 'till': 1410, 'ziploc': 1411, 'rock': 1412, 'loosely': 1413, 'hollow': 1414, 'cider': 1415, 'caraway': 1416, 'condensed': 1417, 'inside': 1418, 'anise': 1419, 'sweat': 1420, 'browned': 1421, 'stay': 1422, 'chowder': 1423, 'doubled': 1424, '80': 1425, 'lobster': 1426, 'all': 1427, 'freeze': 1428, 'steep': 1429, 'more': 1430, 'would': 1431, 'plates': 1432, 'airtight': 1433, 'lamb': 1434, 'lumpy': 1435, 'it': 1436, 'collards': 1437, 'vegall': 1438, 'cocktail': 1439, 'picks': 1440, 'breading': 1441, 'bittersweet': 1442, 'most': 1443, 'strings': 1444, 'tie': 1445, 'elastic': 1446, 'freezing': 1447, 'slide': 1448, '240': 1449, 'fluff': 1450, 'precooked': 1451, 'less': 1452, 'omitted': 1453, 'soap': 1454, 'ladyfingers': 1455, 'halves': 1456, 'salami': 1457, 'prepare': 1458, 'persimmons': 1459, 'bird': 1460, 'strawberry': 1461, 'absorbed': 1462, 'dump': 1463, 'sterilize': 1464, '90': 1465, 'so': 1466, 'sour': 1467, 'handle': 1468, 'awhile': 1469, 'quarter': 1470, 'banana': 1471, 'mince': 1472, 'wafer': 1473, 'bubble': 1474, 'liver': 1475, 'carefully': 1476, 'anchovy': 1477, 'diagonally': 1478, 'style': 1479, 's': 1480, '3': 1481, 'pods': 1482, 'keeping': 1483, 'hang': 1484, 'family': 1485, 'solids': 1486, 'quickly': 1487, 'butterfly': 1488, 'maximum': 1489, 'needs': 1490, 'or': 1491, 'giblets': 1492, '6': 1493, 'jalapenos': 1494, 'per': 1495, 'sugar': 1496, 'balance': 1497, 'melts': 1498, 'directed': 1499, 'day': 1500, 'kettles': 1501, 'liquid': 1502, 'circle': 1503, 'choose': 1504, 'opening': 1505, 'evenly': 1506, 'hens': 1507, 'pack': 1508, 'sunflower': 1509, 'sesame': 1510, 'quarts': 1511, 'candies': 1512, 'wait': 1513, 'carrot': 1514, 'reaches': 1515, 'open': 1516, 'p': 1517, 'buttermilk': 1518, 'tall': 1519, 'holes': 1520, 'decorating': 1521, 'removing': 1522, 'garnish': 1523, 'crank': 1524, 'cucumbers': 1525, 'cola': 1526, 'yum': 1527, 'not': 1528, 'butterfinger': 1529, 'peas': 1530, 'figs': 1531, 'racks': 1532, 'closely': 1533, 'one': 1534, 'undrained': 1535, 'powder': 1536, 'loaf': 1537, 'nestle': 1538, 'dente': 1539, 'stroganoff': 1540, 'macaroni': 1541, 'crumb': 1542, 'motion': 1543, 'cornish': 1544, 'pimento': 1545, 'deer': 1546, 'cracked': 1547, 'tails': 1548, 'segments': 1549, 'eagle': 1550, 'pickles': 1551, 'wanted': 1552, 'combine': 1553, 'their': 1554, 'mouth': 1555, 'onto': 1556, 'trifle': 1557, 'rest': 1558, 'decorative': 1559, 'extremely': 1560, 'once': 1561, 'sift': 1562, 'simmer': 1563, '10': 1564, 'easier': 1565, 'larger': 1566, 'mug': 1567, 'outer': 1568, 'slivered': 1569, 'soak': 1570, 'saffron': 1571, 'melba': 1572, 'seasoning': 1573, 'relish': 1574, 'cornflakes': 1575, 'bubbles': 1576, 'sides': 1577, 'jar': 1578, 'waxed': 1579, 'hold': 1580, 'dissolved': 1581, 'always': 1582, 'pats': 1583, 'maybe': 1584, 'parts': 1585, 'run': 1586, 'flank': 1587, 'sticking': 1588, 'monde': 1589, 'seams': 1590, 'fries': 1591, 'group': 1592, 'sprinkle': 1593, 'chop': 1594, 'upon': 1595, 'corns': 1596, 'tortilla': 1597, 'heat': 1598, 'lot': 1599, 'lots': 1600, 'fettuccine': 1601, 'winter': 1602, 'puff': 1603, 'reheated': 1604, 'either': 1605, 'ripe': 1606, 'corn': 1607, 'mixed': 1608, 'the': 1609, 'cracker': 1610, 'tuna': 1611, 'stems': 1612, 'purchased': 1613, 'chunk': 1614, 'rich': 1615, 'additional': 1616, 'firmly': 1617, 'tins': 1618, 'crock': 1619, 'clams': 1620, 'almost': 1621, 'continuously': 1622, 'mayonnaise': 1623, 'ahead': 1624, 'pureed': 1625, 'breakfast': 1626, '1st': 1627, 'drink': 1628, 'human': 1629, 'served': 1630, 'making': 1631, 'preference': 1632, 'granola': 1633, 'canning': 1634, 'understanding': 1635, 'slowly': 1636, 'many': 1637, 'lined': 1638, '24': 1639, 'peanuts': 1640, 'lasts': 1641, 'unsalted': 1642, 'never': 1643, 'basting': 1644, 'hamburg': 1645, 'kool': 1646, 'oeuvre': 1647, 'careful': 1648, 'tarragon': 1649, 'they': 1650, 'room': 1651, 'undiluted': 1652, 'loin': 1653, 'hair': 1654, 'bubbling': 1655, 'king': 1656, 'cole': 1657, 'necessary': 1658, 'pans': 1659, 'volume': 1660, 'anchor': 1661, 'miniature': 1662, 'sherry': 1663, 'membranes': 1664, 'thousand': 1665, 'rye': 1666, 'boned': 1667, 'mugs': 1668, 'transfer': 1669, 'caramels': 1670, 'parsley': 1671, '4': 1672, 'frankfurters': 1673, 'scrambled': 1674, 'hawaiian': 1675, 'chunked': 1676, 'dozen': 1677, 'squares': 1678, 'forms': 1679, 'tapioca': 1680, 'dollop': 1681, 'evaporates': 1682, 'caps': 1683, 'lean': 1684, 'checking': 1685, 'tears': 1686, 'stocks': 1687, 'rabbits': 1688, 'repeat': 1689, 'lasagna': 1690, 'a': 1691, 'persimmon': 1692, 'cashews': 1693, 'turnips': 1694, 'packed': 1695, 'square': 1696, 'seems': 1697, 'throw': 1698, '35': 1699, 'crumbly': 1700, 'dandelion': 1701, 'gloss': 1702, 'allowed': 1703, 'dry': 1704, 'release': 1705, 'back': 1706, 'ramen': 1707, 'coriander': 1708, 'seam': 1709, 'tamari': 1710, 'florets': 1711, 'whatever': 1712, 'upside': 1713, 'hash': 1714, 'mixes': 1715, 'unmold': 1716, 'trout': 1717, 'sterilized': 1718, 'halved': 1719, 'rectangle': 1720, 'food': 1721, 'spoke': 1722, 'spoons': 1723, 'paint': 1724, 'worcestershire': 1725, 'tea': 1726, 'drain': 1727, 'luke': 1728, 'tap': 1729, 'tomatoes': 1730, 'batter': 1731, 'measure': 1732, 'poured': 1733, 'packet': 1734, 'bay': 1735, 'mocha': 1736, 'total': 1737, 'knorr': 1738, '20': 1739, 'sun': 1740, 'smoked': 1741, 'need': 1742, 'pickling': 1743, 'cheesecloth': 1744, 'usually': 1745, 'thermometer': 1746, 'ham': 1747, 'shows': 1748, 'pea': 1749, 'chickpeas': 1750, 'edge': 1751, 'spiral': 1752, 'soy': 1753, 'thickening': 1754, 'springs': 1755, 'pheasant': 1756, 'beater': 1757, 'few': 1758, 'comes': 1759, 'slow': 1760, 'oreos': 1761, 'discard': 1762, 'sink': 1763, 'hocks': 1764, 'waffles': 1765, 'marshmallows': 1766, '375': 1767, 'skins': 1768, 'clam': 1769, 'remainder': 1770, 'resistant': 1771, 'equal': 1772, 'flavorings': 1773, 'optional': 1774, 'ounce': 1775, 'barbecue': 1776, 'thumb': 1777, 'like': 1778, 'beating': 1779, 'jars': 1780, '14': 1781, 'toothpicks': 1782, 'church': 1783, 'building': 1784, 'outside': 1785, 'pliable': 1786, 'junior': 1787, 'owens': 1788, 'nachos': 1789, 'custard': 1790, 'chestnuts': 1791, 'havarti': 1792, 'pork': 1793, 'blender': 1794, 'lengthwise': 1795, 'had': 1796, 'overmix': 1797, 'bean': 1798, 'breadcrumbs': 1799, 'running': 1800, 'lift': 1801, 'tossed': 1802, 'blossoms': 1803, 'saute': 1804, 'single': 1805, 'blackberries': 1806, 'red': 1807, 'creaming': 1808, 'drizzle': 1809, 'coats': 1810, 'cupcakes': 1811, 'jelly': 1812, 'nutmeats': 1813, 'holds': 1814, 'scallions': 1815, 'bring': 1816, '60': 1817, 'dutch': 1818, 'empty': 1819, 'seafood': 1820, 'cottage': 1821, 'turns': 1822, 'manufacturer': 1823, 'gentle': 1824, 'crunch': 1825, 'capers': 1826, 'increase': 1827, 'accent': 1828, 'oval': 1829, 'aluminum': 1830, 'garnishes': 1831, 'joy': 1832, 'upright': 1833, '50': 1834, 'has': 1835, 'shin': 1836, 'stalk': 1837, '350': 1838, 'kneading': 1839, 'setting': 1840, 'before': 1841, 'pan': 1842, 'flavor': 1843, 'rotating': 1844, 'drippings': 1845, 'block': 1846, 'corners': 1847, 'followed': 1848, 'desire': 1849, 'lavender': 1850, 'carrots': 1851, 'air': 1852, 'extract': 1853, 'piece': 1854, '130': 1855, 'mountain': 1856, 'sack': 1857, 'fluffy': 1858, 'field': 1859, '30': 1860, 'portions': 1861, '234': 1862, 'preheating': 1863, 'yogurt': 1864, 'eat': 1865, 'refrigerated': 1866, 'make': 1867, 'ready': 1868, 'score': 1869, 'comino': 1870, 'healthy': 1871, 'wraps': 1872, 'pale': 1873, 'blending': 1874, 'child': 1875, 'dumplings': 1876, 'boxes': 1877, 'yields': 1878, 'peeled': 1879, 'stuffed': 1880, 'jellyroll': 1881, 'holding': 1882, 'meal': 1883, 'washed': 1884, 'gelatine': 1885, 'candy': 1886, 'mozzarella': 1887, 'could': 1888, 'taffy': 1889, 'an': 1890, 'longhorn': 1891, 'alum': 1892, 'dressing': 1893, 'basket': 1894, 'change': 1895, 'including': 1896, 'chinese': 1897, 'point': 1898, '250': 1899, 'alternate': 1900, 'lowfat': 1901, 'meaty': 1902, 'fryer': 1903, 'spicy': 1904, 'brown': 1905, 'frothy': 1906, 'get': 1907, 'listed': 1908, 'eggplant': 1909, 'and': 1910, 'wide': 1911, 'baker': 1912, 'row': 1913, 'buns': 1914, 'monosodium': 1915, 'tofu': 1916, 'm': 1917, '2nd': 1918, 'shellfish': 1919, 'sherbet': 1920, 'starting': 1921, 'sharp': 1922, 'curdle': 1923, 'pectin': 1924, 'containers': 1925, 'bubbly': 1926, 'marble': 1927, 'note': 1928, 'krispies': 1929, 'cream': 1930, 'heating': 1931, 'frying': 1932, 'burn': 1933, 'bakes': 1934, 'spareribs': 1935, 'those': 1936, 'margarine': 1937, 'wieners': 1938, 'popped': 1939, 'let': 1940, 'together': 1941, 'folding': 1942, 'consomme': 1943, 'bigger': 1944, 'narrow': 1945, 'milk': 1946, 'alternately': 1947, 'biscuit': 1948, 'worms': 1949, 'apart': 1950, 'breasts': 1951, 'breads': 1952, 'pare': 1953, 'lengths': 1954, 'kosher': 1955, 'teaspoonfuls': 1956, 'at': 1957, 'thin': 1958, 'refried': 1959, 'prick': 1960, 'oysters': 1961, 'kidney': 1962, 'wild': 1963, 'blueberries': 1964, 'entire': 1965, 'preheat': 1966, 'nacho': 1967, 'shoulder': 1968, 'honey': 1969, 'separate': 1970, 'citron': 1971, 'spooned': 1972, 'is': 1973, 'cans': 1974, 'apples': 1975, 'also': 1976, 'saucepan': 1977, 'mushroom': 1978, 'lemon': 1979, 'instead': 1980, 'tablespoon': 1981, 'yolks': 1982, 'turned': 1983, 'tests': 1984, 'limes': 1985, 'soba': 1986, 'kids': 1987, 'do': 1988, 'wrapped': 1989, 'double': 1990, 'sizzling': 1991, 'peek': 1992, 'move': 1993, 'pops': 1994, 'mcbutter': 1995, 'days': 1996, 'party': 1997, 'makes': 1998, 'sweet': 1999, 'chuck': 2000, 'person': 2001, 'coffee': 2002, 'crack': 2003, 'stalks': 2004, '450': 2005, 'roni': 2006, 'solution': 2007, 'chunky': 2008, 'liberally': 2009, 'remember': 2010, 'equals': 2011, 'proof': 2012, 'k': 2013, 'flowers': 2014, 'eaten': 2015, 'remain': 2016, 'electric': 2017, 'ounces': 2018, 'bar': 2019, 'logs': 2020, 'correct': 2021, 'tortellini': 2022, 'without': 2023, 'placed': 2024, 'regularly': 2025, 'greased': 2026, 'fix': 2027, 'shut': 2028, 'vessel': 2029, 'dashes': 2030, 'grahams': 2031, 'hotter': 2032, 'trimmings': 2033, 'there': 2034, 'peel': 2035, 'gumdrops': 2036, 'minced': 2037, 'hole': 2038, 'pumpkin': 2039, 'zinfandel': 2040, 'push': 2041, 'irish': 2042, 'give': 2043, 'purpose': 2044, 'marnier': 2045, 'rotate': 2046, 'syrup': 2047, 'invert': 2048, 'regular': 2049, 'milnot': 2050, 'de': 2051, 'hen': 2052, 'kale': 2053, 'be': 2054, 'shears': 2055, 'cloves': 2056, 'cayenne': 2057, 'diluted': 2058, 'gruyere': 2059, 'ragu': 2060, 'hr': 2061, 'shiny': 2062, 'golden': 2063, 'everything': 2064, 'wok': 2065, 'bran': 2066, 'kiss': 2067, 'directly': 2068, 'brand': 2069, 'indention': 2070, 'drinks': 2071, 'cooks': 2072, 'angel': 2073, 'loosen': 2074, 'squirt': 2075, 'moderate': 2076, 'kept': 2077, 'brushing': 2078, 'containing': 2079, 'dishes': 2080, 'how': 2081, 'storage': 2082, 'unroll': 2083, 'center': 2084, 'assorted': 2085, 'blackberry': 2086, 'steady': 2087, 'rather': 2088, 'peppercorns': 2089, '425': 2090, 'ingredient': 2091, 'flakes': 2092, 'rotelle': 2093, 'samuel': 2094, '18': 2095, 'monterey': 2096, 'base': 2097, 'hots': 2098, 'cubed': 2099, 'particles': 2100, 'white': 2101, 'bananas': 2102, 'draft': 2103, 'resembles': 2104, 'float': 2105, 'clumping': 2106, 'fun': 2107, 'burgers': 2108, 'bourbon': 2109, 'lunch': 2110, '22': 2111, 'rings': 2112, 'x': 2113, 'breaking': 2114, 'nuts': 2115, 'jack': 2116, 'crumble': 2117, 'garbanzos': 2118, 'absorbent': 2119, 'kernels': 2120, 'walnut': 2121, 'browning': 2122, 'chives': 2123, '7': 2124, 'keep': 2125, 'guacamole': 2126, 'apply': 2127, 'tbsp': 2128, 'spots': 2129, 'parboil': 2130, 'label': 2131, 'philadelphia': 2132, 'fats': 2133, 'maple': 2134, 'smash': 2135, 'black': 2136, 'have': 2137, 'hidden': 2138, 'allpurpose': 2139, 'just': 2140, 'head': 2141, 'broiler': 2142, 'sit': 2143, 'turn': 2144, 'pieces': 2145, 'sage': 2146, 'allowing': 2147, 'pronged': 2148, 'bite': 2149, 'yield': 2150, 'soften': 2151, 'harden': 2152, 'seasonall': 2153, 'wipe': 2154, 'slotted': 2155, 'freshly': 2156, 'nonfat': 2157, 'cubes': 2158, 'immediately': 2159, 'asparagus': 2160, '33': 2161, 'scatter': 2162, 'lettuce': 2163, 'clusters': 2164, 'biscuits': 2165, 'stick': 2166, 'cornbread': 2167, 'see': 2168, 'stir': 2169, 'elephant': 2170, 'taco': 2171, 'tablespoonfuls': 2172, 'leeks': 2173, 'squirrels': 2174, 'often': 2175, 'gummy': 2176, 'vigorously': 2177, 'swirl': 2178, 'pizza': 2179, 'broil': 2180, 'dissolve': 2181, 'pinto': 2182, 'such': 2183, 'prior': 2184, 'tear': 2185, 'cornflake': 2186, 'securely': 2187, 'etc': 2188, 'anything': 2189, 'zita': 2190, 'topped': 2191, 'microwavable': 2192, 'pretzels': 2193, 'candle': 2194, 'bagels': 2195, 'deeds': 2196, 'rivels': 2197, '365': 2198, 'delicious': 2199, 'tidbits': 2200, 'mill': 2201, 'sheet': 2202, 'colander': 2203, 'frosting': 2204, 'f': 2205, 'crescent': 2206, 'greens': 2207, 'spiced': 2208, 'pizzas': 2209, 'blue': 2210, 'topping': 2211, 'fast': 2212, '40': 2213, 'concentrate': 2214, 'nondairy': 2215, 'crunchy': 2216, 'grain': 2217, 'grocery': 2218, 'heaping': 2219, 'fillet': 2220, 'tupperware': 2221, 'lighten': 2222, 'mallet': 2223, 'generously': 2224, 'processor': 2225, 'cooked': 2226, 'olives': 2227, 'marsala': 2228, 'time': 2229, 'bone': 2230, 'bitters': 2231, 'bundles': 2232, 'surround': 2233, 'become': 2234, 'everyone': 2235, 'preserves': 2236, 'pound': 2237, 'reused': 2238, 'type': 2239, 'cuts': 2240, 'look': 2241, 'resemble': 2242, 'sorghum': 2243, 'xxxx': 2244, 'probably': 2245, 'confectioners': 2246, 'pit': 2247, 'broken': 2248, 'whole': 2249, 'tablespoons': 2250, 'alfalfa': 2251, 'shrimp': 2252, 'perforations': 2253, 'hour': 2254, 'veal': 2255, 'newspaper': 2256, 'skewers': 2257, 'gallon': 2258, 'potatoes': 2259, 'too': 2260, 'excess': 2261, 'does': 2262, 'brisket': 2263, 'dredge': 2264, 'fluid': 2265, 'personal': 2266, 'kisses': 2267, 'below': 2268, 'mushrooms': 2269, 'altogether': 2270, 'mango': 2271, 'enchiladas': 2272, 'cracks': 2273, 'surface': 2274, '45': 2275, 'limp': 2276, 'find': 2277, 'favorite': 2278, 'than': 2279, 'crispies': 2280, 'grill': 2281, 'rhubarb': 2282, '9x13': 2283, 'if': 2284, 'layer': 2285, '32': 2286, 'similar': 2287, 'softened': 2288, 'individual': 2289, 'new': 2290, 'island': 2291, 'thickens': 2292, 'grenadine': 2293, 'preparing': 2294, 'mexican': 2295, 'when': 2296, 'rapidly': 2297, 'sieve': 2298, '112': 2299, 'boston': 2300, 're': 2301, 'uncooked': 2302, 'pancake': 2303, 'puffs': 2304, 'linguine': 2305, 'shake': 2306, 'lasagne': 2307, 'luncheon': 2308, 'gelatin': 2309, 'whitefish': 2310, 'aid': 2311, 'tostitos': 2312, 'steaks': 2313, 'garnished': 2314, 'lemons': 2315, 'fritos': 2316, 'closed': 2317, 'skinless': 2318, 'exactly': 2319, 'arrange': 2320, 'fold': 2321, 'crosswise': 2322, 'until': 2323, 'crumbs': 2324, 'wet': 2325, 'oil': 2326, 'measuring': 2327, 'cereal': 2328, 'break': 2329, 'something': 2330, 'sooner': 2331, 'crisp': 2332, 'stewed': 2333, 'sec': 2334, 'steel': 2335, 'goes': 2336, '5': 2337, 'incorporate': 2338, 'handful': 2339, 'order': 2340, 'second': 2341, 'paprika': 2342, 'root': 2343, 'mayo': 2344, 'walnuts': 2345, 'canola': 2346, 'clean': 2347, 'through': 2348, 'solid': 2349, 'chops': 2350, 'uncover': 2351, 'bulk': 2352, 'called': 2353, 'least': 2354, 'sauerkraut': 2355, 'squeezed': 2356, 'helps': 2357, 'must': 2358, 'towels': 2359, 'tied': 2360, 'germ': 2361, 'mostaccioli': 2362, 'pistachio': 2363, '150': 2364, 'dunk': 2365, 'will': 2366, 'given': 2367, 'sticky': 2368, 'wings': 2369, 'dessert': 2370, 'create': 2371, 'thicken': 2372, 'briefly': 2373, 'spatula': 2374, 't': 2375, 'apricot': 2376, 'cucumber': 2377, '325': 2378, 'al': 2379, 'themselves': 2380, 'come': 2381, 'diet': 2382, 'large': 2383, 'pimientos': 2384, '23': 2385, 'taken': 2386, 'down': 2387, 'appear': 2388, 'artificial': 2389, 'puffy': 2390, 'bones': 2391, 'wesson': 2392, 'g': 2393, 'saucer': 2394, 'groundhog': 2395, 'mullet': 2396, 'week': 2397, 'teaspoon': 2398, 'don': 2399, 'five': 2400, 'seasons': 2401, 'placing': 2402, 'iron': 2403, 'rice': 2404, 'nearly': 2405, 'starts': 2406, 'cracklins': 2407, 'touching': 2408, 'ziti': 2409, 'stirred': 2410, 'fashioned': 2411, 'triangle': 2412, 'vent': 2413, 'avocados': 2414, 'freezer': 2415, 'peck': 2416, 'counter': 2417, 'romaine': 2418, 'oz': 2419, 'chipped': 2420, 'frost': 2421, 'stiffly': 2422, 'clove': 2423, 'door': 2424, 'scallops': 2425, 'flowerets': 2426, 'country': 2427, 'frypan': 2428, 'niblets': 2429, 'reserving': 2430, 'spears': 2431, 'icebox': 2432, 'cooling': 2433, 'degree': 2434, 'middle': 2435, 'gradually': 2436, 'lard': 2437, 'carman': 2438, 'burning': 2439, 'broccoli': 2440, 'reheat': 2441, 'pear': 2442, 'baste': 2443, 'off': 2444, 'liners': 2445, 'mixing': 2446, 'scramble': 2447, 'syrupy': 2448, 'whip': 2449, 'pie': 2450, 'dippers': 2451, 'fridge': 2452, 'simmering': 2453, 'icing': 2454, 'bowl': 2455, 'diameter': 2456, 'sprinkling': 2457, 'slight': 2458, 'ensure': 2459, 'decorate': 2460, 'pam': 2461, 'waverly': 2462, 'able': 2463, 'fondant': 2464, 'wooden': 2465, '370': 2466, 'while': 2467, 'itself': 2468, 'can': 2469, 'countertop': 2470, 'morning': 2471, 'excellent': 2472, 'layering': 2473, 'amaretto': 2474, 'high': 2475, 'these': 2476, 'whiz': 2477, 'flaky': 2478, 'paste': 2479, 'quart': 2480, 'nectar': 2481, 'away': 2482, 'thread': 2483, 'oat': 2484, 'prebaked': 2485, 'stack': 2486, 'over': 2487, 'peach': 2488, 'creamette': 2489, 'puffed': 2490, 'liquor': 2491, 'seem': 2492, 'finished': 2493, 'doneness': 2494, 'plastic': 2495, 'squirrel': 2496, 'artichoke': 2497, 'squash': 2498, 'garbanzo': 2499, '475': 2500, 'appearance': 2501, 'potato': 2502, 'weeks': 2503, 'prep': 2504, 'blanched': 2505, 'masher': 2506, 'toss': 2507, 'baguette': 2508, 'paper': 2509, 'cooker': 2510, 'add': 2511, 'gumbo': 2512, 'thaw': 2513, 'tinfoil': 2514, 'flattened': 2515, 'following': 2516, 'thickness': 2517, 'doritos': 2518, 'cookie': 2519, 'cut': 2520, 'congeal': 2521, 'dream': 2522, 'intact': 2523, 'press': 2524, 'start': 2525, 'rub': 2526, 'nine': 2527, 'crabmeat': 2528, 'because': 2529, 'color': 2530, 'butterscotch': 2531, 'thicker': 2532, 'stirring': 2533, 'quarters': 2534, 'power': 2535, 'may': 2536, 'grape': 2537, 'scoop': 2538, 'cornstarch': 2539, 'shapes': 2540, 'catsup': 2541, 'barely': 2542, 'hollowed': 2543, 'brownie': 2544, 'cups': 2545, 'palm': 2546, 'strokes': 2547, 'frozen': 2548, 'jam': 2549, 'pecans': 2550, 'mein': 2551, 'four': 2552, 'preparation': 2553, 'christmas': 2554, 'obrien': 2555, 'neck': 2556, 'sandwiches': 2557, 'cajun': 2558, 'contains': 2559, 'no': 2560, 'loose': 2561, 'translucent': 2562, 'nut': 2563, 'mandarin': 2564, 'scramblers': 2565, 'gouda': 2566, 'stone': 2567, 'triangles': 2568, 'rum': 2569, 'hamburger': 2570, 'fit': 2571, 'later': 2572, 'scant': 2573, 'lemonade': 2574, 'boiling': 2575, '15': 2576, 'melt': 2577, 'boiler': 2578, '12': 2579, 'creole': 2580, 'quantity': 2581, 'inches': 2582, 'ritz': 2583, 'awful': 2584, 'grilled': 2585, 'tortillas': 2586, 'sprigs': 2587, 'depth': 2588, 'chilies': 2589, 'helpings': 2590, 'items': 2591, 'hi': 2592, 'by': 2593, 'lukewarm': 2594, 'width': 2595, 'birds': 2596, 'pancakes': 2597, 'preferred': 2598, 'tender': 2599, 'butterflied': 2600, 'packets': 2601, 'vegetable': 2602, 'unbaked': 2603, 'envelopes': 2604, 'pinch': 2605, 'ingredients': 2606, 'prunes': 2607, 'board': 2608, 'balsamic': 2609, 'tongs': 2610, 'spinach': 2611, 'fudge': 2612, 'kind': 2613, 'already': 2614, 'olive': 2615, 'which': 2616, 'box': 2617, 'basic': 2618, 'each': 2619, 'says': 2620, 'month': 2621, 'bottle': 2622, 'pulled': 2623, 'oranges': 2624, 'approximately': 2625, 'holidays': 2626, 'turkey': 2627, 'pulls': 2628, 'stored': 2629, 'clings': 2630, 'keeps': 2631, 'easily': 2632, 'medal': 2633, '400': 2634, 'crab': 2635, 'elbow': 2636}\n"
     ]
    }
   ],
   "source": [
    "# store vocab into a .json file\n",
    "vocab = json.load(open('./data/vocab.json', 'r'))\n",
    "vocab_stoi = {s: i for i, s in enumerate(vocab)}\n",
    "vocab_itos = {i: s for i, s in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab_stoi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[343, 1087, 1255, 203, 333, 988, 1905, 203, 980, 988, 817, 1910, 484, 988, 1553, 846, 1502, 42, 1301, 1910, 1421, 1087, 1290, 1910, 1563, 264, 1534, 1910, 1691, 1470, 43, 988, 2351, 1910, 2169, 203, 1725, 1388, 988, 2511, 1730, 1002, 645, 1910, 1563, 264, 2337, 75, 988, 1039, 2487, 1128, 2226, 2404, 988]\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    indexed_directions = []\n",
    "    for i, row in tokenized_nlg_df.iterrows():\n",
    "        direction = []\n",
    "        for word in row.combined_directions:\n",
    "            if word in vocab:\n",
    "                direction.append(vocab_stoi[word])\n",
    "        indexed_directions.append(direction)\n",
    "        \n",
    "    print(indexed_directions[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1730, 988, 42, 988, 1301, 988, 1725, 1388, 988, 1002, 645, 988, 2326, 988]\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    indexed_ingredients = []\n",
    "    for i, row in tokenized_nlg_df.iterrows():\n",
    "        ingredients = []\n",
    "        for word in row.combined_ingredients:\n",
    "            if word in vocab:\n",
    "                ingredients.append(vocab_stoi[word])\n",
    "        indexed_ingredients.append(ingredients)\n",
    "        \n",
    "    print(indexed_ingredients[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    indexed_nlg_df = pd.DataFrame({'directions': indexed_directions, 'ingredients': indexed_ingredients})\n",
    "    #indexed_nlg_df.to_csv('data/indexed_nlg.csv', header=False, index=False)\n",
    "    \n",
    "#indexed_nlg_df = pd.read_csv('data/indexed_nlg.csv', header=None, names=[\"directions\", \"ingredients\"],\n",
    "#                            converters={'directions':pd.eval, 'ingredients':pd.eval})\n",
    "\n",
    "    indexed_nlg_df.to_json('./data/indexed_nlg.json')\n",
    "    \n",
    "indexed_nlg_df = pd.read_json('./data/indexed_nlg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[203, 1691, 1281, 992, 2480, 1977, 876, 1905, ...</td>\n",
       "      <td>[1905, 1496, 988, 1946, 988, 448, 988, 2115, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[153, 2420, 280, 1052, 983, 1020, 936, 150, 98...</td>\n",
       "      <td>[280, 988, 1136, 1951, 988, 1930, 1020, 1978, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[203, 1691, 1760, 2510, 1553, 1427, 2606, 1290...</td>\n",
       "      <td>[2548, 1607, 988, 1930, 804, 988, 118, 988, 72...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  [203, 1691, 1281, 992, 2480, 1977, 876, 1905, ...   \n",
       "1  [153, 2420, 280, 1052, 983, 1020, 936, 150, 98...   \n",
       "2  [203, 1691, 1760, 2510, 1553, 1427, 2606, 1290...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  [1905, 1496, 988, 1946, 988, 448, 988, 2115, 9...  \n",
       "1  [280, 988, 1136, 1951, 988, 1930, 1020, 1978, ...  \n",
       "2  [2548, 1607, 988, 1930, 804, 988, 118, 988, 72...  "
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_nlg_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction Character Vocabulary\n",
    "For the baseline model, a character based vocabulary will be used instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ', ';']\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '0': 26, '1': 27, '2': 28, '3': 29, '4': 30, '5': 31, '6': 32, '7': 33, '8': 34, '9': 35, ' ': 36, ';': 37}\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    char_vocab = list(string.ascii_lowercase) + list(string.digits) + [' ', ';']\n",
    "    json.dump(char_vocab, open('./data/char_vocab.json', 'w'))\n",
    "char_vocab = json.load(open('./data/char_vocab.json', 'r'))\n",
    "char_vocab_stoi = {s: i for i, s in enumerate(char_vocab)}\n",
    "char_vocab_itos = {i: s for i, s in enumerate(char_vocab)}\n",
    "char_vocab_size = len(vocab)\n",
    "print(char_vocab)\n",
    "print(char_vocab_stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove characters not in the character vocabulary\n",
    "chared_directions_list = []\n",
    "chared_ingredients_list = []\n",
    "for i, row in combined_nlg_df.iterrows(): \n",
    "    chared_direction = ''\n",
    "    for char in row.directions:\n",
    "        if char in char_vocab:\n",
    "            chared_direction += char\n",
    "    chared_directions_list.append(chared_direction)\n",
    "    \n",
    "    chared_ingredients = ''\n",
    "    for char in row.ingredients:\n",
    "        if char in char_vocab:\n",
    "            chared_ingredients += char\n",
    "    chared_ingredients_list.append(chared_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_nlg_df = pd.DataFrame()\n",
    "char_nlg_df['directions'] = chared_directions_list\n",
    "char_nlg_df['ingredients'] = chared_ingredients_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    char_nlg_df.to_csv('data/char_nlg_df.csv', header=False, index=False)\n",
    "    \n",
    "char_nlg_df = pd.read_csv('data/char_nlg_df.csv', header=None, names=[\"directions\", \"ingredients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in a heavy 2 quart saucepan mix brown sugar nu...</td>\n",
       "      <td>brown sugar ; milk ; vanilla ; nuts ; butter ;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place chipped beef on bottom of baking dish  ;...</td>\n",
       "      <td>beef ; chicken breasts ; cream of mushroom sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in a slow cooker combine all ingredients cover...</td>\n",
       "      <td>frozen corn ; cream cheese ; butter ; garlic p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          directions  \\\n",
       "0  in a heavy 2 quart saucepan mix brown sugar nu...   \n",
       "1  place chipped beef on bottom of baking dish  ;...   \n",
       "2  in a slow cooker combine all ingredients cover...   \n",
       "\n",
       "                                         ingredients  \n",
       "0  brown sugar ; milk ; vanilla ; nuts ; butter ;...  \n",
       "1  beef ; chicken breasts ; cream of mushroom sou...  \n",
       "2  frozen corn ; cream cheese ; butter ; garlic p...  "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_nlg_df[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closest Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param: ingredient - list of strings of an ingredient (tokenized)\n",
    "#        ingredient_df - dataframe containing ingredient vocabulary and\n",
    "#                        their corresponding GloVe embedding\n",
    "# return: string of closest ingredient in vocabulary\n",
    "#         if none (e.g. ingredient has is OOV in GloVe), returns empty string\n",
    "def get_closest_ingredient (ingredient, ingredients_df):\n",
    "    # check if ingredient is in ingredients_df\n",
    "    if len(ingredient) == 1 and ingredient[0] in ingredients_df['ingredient'].values:\n",
    "        return ingredient[0]\n",
    "    \n",
    "    closest_ingredient = ''\n",
    "    smallest_distance = float('inf')\n",
    "    \n",
    "    if (len(ingredient) == 0):\n",
    "        return closest_ingredient\n",
    "    \n",
    "    # compute the GloVe embedding of the ingredient\n",
    "    ingredient_embedding = glove_average(ingredient)\n",
    "    \n",
    "    if torch.count_nonzero(ingredient_embedding) == 0:\n",
    "        return ''\n",
    "    \n",
    "    # compute distances between embeddings, choose the smallest distance\n",
    "    for _, row in ingredients_df.iterrows():\n",
    "        difference = ingredient_embedding - torch.FloatTensor(row['embedding'])\n",
    "        distance = torch.sum(torch.square(difference))\n",
    "        if distance < smallest_distance:\n",
    "            smallest_distance = distance\n",
    "            closest_ingredient = row['ingredient']\n",
    "    \n",
    "    return closest_ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown sugar', 'milk', 'vanilla', 'soy nut', 'butter', 'rice paper']\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    # changes the ingredients list into their corresponding closest ingredients\n",
    "    # in the vocabulary using the GloVe embeddings\n",
    "    NER_closest_ingredients = []\n",
    "\n",
    "    for i, row in tokenized_nlg_df.iterrows():\n",
    "        NER_closest_list = []\n",
    "        for ingredient_tokens in row.ingredients:\n",
    "            NER_closest_list.append( get_closest_ingredient(ingredient_tokens, ingredients_df) )\n",
    "        NER_closest_ingredients.append(NER_closest_list)\n",
    "\n",
    "    print(NER_closest_ingredients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    nlg_ingredients_df = pd.DataFrame()\n",
    "    nlg_ingredients_df['token_NER'] = list(tokenized_nlg_df['ingredients'])\n",
    "    nlg_ingredients_df['closest_ingredients'] = NER_closest_ingredients\n",
    "    nlg_ingredients_df.to_csv('data/recipe_nlg/closest_ingredients.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_NER</th>\n",
       "      <th>closest_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[brown, sugar], [milk], [vanilla], [nuts], [b...</td>\n",
       "      <td>[brown sugar, milk, vanilla, soy nut, butter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[beef], [chicken, breasts], [cream, of, mushr...</td>\n",
       "      <td>[beef, chicken, passion fruit, sour cream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[frozen, corn], [cream, cheese], [butter], [g...</td>\n",
       "      <td>[corn, cheese, butter, garlic, salt, pepper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[chicken], [chicken, gravy], [cream, of, mush...</td>\n",
       "      <td>[chicken, chicken, passion fruit, cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[peanut, butter], [graham, cracker, crumbs], ...</td>\n",
       "      <td>[peanut butter, graham cracker, butter, sugar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[baking, potatoes], [extra, lean, ground, bee...</td>\n",
       "      <td>[baking mix, crescent roll, butter, milk, salt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[sugar], [butter], [egg], [buttermilk], [flou...</td>\n",
       "      <td>[sugar, butter, egg, buttermilk, flour, salt, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           token_NER  \\\n",
       "0  [[brown, sugar], [milk], [vanilla], [nuts], [b...   \n",
       "1  [[beef], [chicken, breasts], [cream, of, mushr...   \n",
       "2  [[frozen, corn], [cream, cheese], [butter], [g...   \n",
       "3  [[chicken], [chicken, gravy], [cream, of, mush...   \n",
       "4  [[peanut, butter], [graham, cracker, crumbs], ...   \n",
       "5  [[baking, potatoes], [extra, lean, ground, bee...   \n",
       "6  [[sugar], [butter], [egg], [buttermilk], [flou...   \n",
       "\n",
       "                                 closest_ingredients  \n",
       "0  [brown sugar, milk, vanilla, soy nut, butter, ...  \n",
       "1         [beef, chicken, passion fruit, sour cream]  \n",
       "2       [corn, cheese, butter, garlic, salt, pepper]  \n",
       "3          [chicken, chicken, passion fruit, cheese]  \n",
       "4  [peanut butter, graham cracker, butter, sugar,...  \n",
       "5  [baking mix, crescent roll, butter, milk, salt...  \n",
       "6  [sugar, butter, egg, buttermilk, flour, salt, ...  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlg_ingredients_df[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lettuce', 'black pepper', 'grape', 'garlic', 'pepper', 'onion', 'seasoning', 'lentils', 'gorgonzola']\n"
     ]
    }
   ],
   "source": [
    "# outputs the ingredient to closest ingredient pairings for What's Cooking data\n",
    "if pre_processing == True:\n",
    "    wc_ingredients, wc_closest_ingredients = [], []\n",
    "    \n",
    "    limit = 7500\n",
    "    for i in range(len(wc_train_data)):\n",
    "        wc_ingredients.append(wc_train_data[i]['ingredients'])\n",
    "        \n",
    "        item_closest_ingredients = []\n",
    "        for ingredient in wc_train_data[i]['ingredients']:\n",
    "            token_list = re.sub(r\"[^a-zA-Z ]+\", '', ingredient.lower()).split(' ')\n",
    "            closest_ingredient = get_closest_ingredient(token_list, ingredients_df)\n",
    "            item_closest_ingredients.append(closest_ingredient)\n",
    "        wc_closest_ingredients.append(item_closest_ingredients)\n",
    "        \n",
    "        if i >= limit:\n",
    "            break\n",
    "\n",
    "    print(wc_closest_ingredients[0])\n",
    "    \n",
    "    wc_ingredients_df = pd.DataFrame({'ingredients': wc_ingredients, 'closest_ingredients': wc_closest_ingredients})\n",
    "    wc_ingredients_df.to_csv('data/whats_cooking/closest_ingredients.csv', header=True, index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredient Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # get frequency based on appearences in Recipenlg recipes\n",
    "    nlg_ingredients_df = pd.read_csv('data/recipe_nlg/closest_ingredients.csv', index_col=0,\n",
    "                               converters={'token_NER':pd.eval, 'closest_ingredients':pd.eval})\n",
    "    \n",
    "    ingredient_frequency = torch.zeros(len(ingredients_df)).tolist()\n",
    "    \n",
    "    for i in range(nlg_ingredients_df.shape[0]):\n",
    "        for closest_ingredient in nlg_ingredients_df[\"closest_ingredients\"][i]:\n",
    "            index = ingredient_vocab_stoi.get(closest_ingredient)\n",
    "            if (index != None):\n",
    "                ingredient_frequency[index] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    # get frequency based on appearences in What's Cooking recipes\n",
    "    wc_ingredients_df = pd.read_csv('data/whats_cooking/closest_ingredients.csv', index_col=0,\n",
    "                                    converters={'ingredients':pd.eval, 'closest_ingredients':pd.eval})\n",
    "    \n",
    "    for i in range(wc_ingredients_df.shape[0]):\n",
    "        for closest_ingredient in wc_ingredients_df[\"closest_ingredients\"][i]:\n",
    "            index = ingredient_vocab_stoi.get(closest_ingredient)\n",
    "            if (index != None):\n",
    "                ingredient_frequency[index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    ingredient_frequency = ( torch.FloatTensor(ingredient_frequency) / max(ingredient_frequency) ).tolist()\n",
    "    ingredients_frequency_df = (ingredients_df.copy()).drop('embedding', axis=1)\n",
    "    ingredients_frequency_df['frequency'] = ingredient_frequency\n",
    "    ingredients_frequency_df.to_csv('data/ingredients_frequency.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_frequency_df = pd.read_csv('data/ingredients_frequency.csv', header=None, names=[\"ingredient\", \"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aioli</td>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ale</td>\n",
       "      <td>0.007678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almond</td>\n",
       "      <td>0.014886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anise</td>\n",
       "      <td>0.002977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>0.008461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>applesauce</td>\n",
       "      <td>0.013475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apricot</td>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>artichoke</td>\n",
       "      <td>0.009715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arugula</td>\n",
       "      <td>0.007521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asafoetida</td>\n",
       "      <td>0.005171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ingredient  frequency\n",
       "0       aioli   0.004231\n",
       "1         ale   0.007678\n",
       "2      almond   0.014886\n",
       "3       anise   0.002977\n",
       "4       apple   0.008461\n",
       "5  applesauce   0.013475\n",
       "6     apricot   0.005641\n",
       "7   artichoke   0.009715\n",
       "8     arugula   0.007521\n",
       "9  asafoetida   0.005171"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_frequency_df[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first iteration, we further filter the ingredients with less than 0.1% frequency. This yielded 381 ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n"
     ]
    }
   ],
   "source": [
    "if pre_processing == True:\n",
    "    filtered_ingredients_frequency_df = ingredients_frequency_df[ingredients_frequency_df['frequency'] > 0.001]\n",
    "    print(filtered_ingredients_frequency_df.shape[0])\n",
    "    filtered_ingredients_frequency_df.drop('frequency', axis=1).to_csv('data/intermediary/frequency_filtered_ingredients.csv', header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredient Graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the graph, each time an ingredient appears in a recipe with another ingredient, their compatibility is increased. This is implemented with an adjacency matrix. The compatibilities will be normalized by each row of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processing == True:\n",
    "    ingredient_graph = torch.zeros(len(ingredients_df), len(ingredients_df))\n",
    "\n",
    "    for i in range(nlg_ingredients_df.shape[0]):\n",
    "        for ingredient_1 in nlg_ingredients_df[\"closest_ingredients\"][i]:\n",
    "            if ingredient_1 != '':\n",
    "                index_1 = ingredient_vocab_stoi[ingredient_1]\n",
    "                for ingredient_2 in nlg_ingredients_df[\"closest_ingredients\"][i]:\n",
    "                    if ingredient_2 != '' and ingredient_2 != ingredient_1:\n",
    "                        index_2 = ingredient_vocab_stoi[ingredient_2]\n",
    "                        \n",
    "                        ingredient_graph[index_1][index_2] += 1\n",
    "    \n",
    "    for i in range(ingredient_graph.shape[0]):\n",
    "        ingredient_max = torch.max(ingredient_graph[i])\n",
    "        if (ingredient_max > 0):\n",
    "            ingredient_graph[i] = ingredient_graph[i] / ingredient_max\n",
    "        \n",
    "    json.dump(ingredient_graph.tolist(), open('./data/ingredient_graph.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1091, 0.0000, 0.0000, 0.0000, 0.5818, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.0000, 0.1167, 0.0000, 0.0000, 0.4667, 0.0000, 0.0000, 0.0333],\n",
      "        [0.0000, 0.0199, 0.0000, 0.0000, 0.0000, 0.6534, 0.0511, 0.0142, 0.0142],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0527, 0.0461, 0.3789, 0.0016, 0.0000, 0.0000, 0.0675, 0.0099, 0.0148],\n",
      "        [0.0000, 0.0000, 0.1552, 0.0000, 0.0000, 0.3534, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3571, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0476, 0.1190, 0.0000, 0.0000, 0.2143, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "ingredient_graph = json.load(open('./data/ingredient_graph.json', 'r'))\n",
    "ingredient_graph = torch.FloatTensor(ingredient_graph)\n",
    "print(ingredient_graph[40:49,40:49])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingredient Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beef', 'cheese', 'cherry']"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param: ingredient_list  - list of ingredient strings (e.g. [\"food\", \"two foods\"])\n",
    "#        compatibility    - controls how compatible the output ingredients are, from 0 to 1\n",
    "#        ingredient_graph - the big ingredient graph\n",
    "#        ingredient_df    - Pandas DataFrame containing the GloVe embeddings of ingredients in vocabulary\n",
    "# return: a list of ingredient strings that are a subset of ingredient_list\n",
    "def select_ingredients(ingredient_list, compatibility, ingredient_graph, ingredients_df):\n",
    "    compatibility = max( 0, min(1, compatibility) ) # clamp to [0,1]\n",
    "    \n",
    "    original_ingredients = ingredient_list.copy()\n",
    "    \n",
    "    # get closest ingredients of the ingredient_list\n",
    "    closest_ingredient_list = []\n",
    "    for ingredient in original_ingredients:\n",
    "        ingredient = ingredient.split(' ')\n",
    "        closest_ingredient_list.append(get_closest_ingredient(ingredient, ingredients_df))\n",
    "        \n",
    "    # remove unknown ingredients\n",
    "    original_ingredients_temp, closest_ingredient_list_temp = [], []\n",
    "    for i, ingredient in enumerate(closest_ingredient_list):\n",
    "        if ingredient == '':\n",
    "            continue\n",
    "        original_ingredients_temp.append(original_ingredients[i])\n",
    "        closest_ingredient_list_temp.append(closest_ingredient_list[i])\n",
    "    original_ingredients = original_ingredients_temp\n",
    "    closest_ingredient_list = closest_ingredient_list_temp\n",
    "    \n",
    "    # get graph indices of closest ingredients\n",
    "    closest_ingredient_indices = [ingredient_vocab_stoi[x] for x in closest_ingredient_list]\n",
    "    \n",
    "    # create mini matrix\n",
    "    mini_ingredient_graph = torch.zeros(len(original_ingredients), len(original_ingredients)).tolist()\n",
    "    for i, index_1 in enumerate(closest_ingredient_indices):\n",
    "        for j, index_2 in enumerate(closest_ingredient_indices):\n",
    "            mini_ingredient_graph[i][j] = ingredient_graph[index_1][index_2].item()\n",
    "            \n",
    "    sorted_matches_ingredients = []\n",
    "    # sort ingredients based on compatibility for each row\n",
    "    for i in range(len(original_ingredients)):\n",
    "        graph_row = mini_ingredient_graph[i]\n",
    "        sorted_matches_ingredients.append([x for _,x in sorted(zip(graph_row,original_ingredients),reverse=True)])\n",
    "    \n",
    "    new_ingredient_list = []\n",
    "    for i in range(len(original_ingredients)):\n",
    "        index = original_ingredients.index(sorted_matches_ingredients[i][0]) # get most compatible ingredient for this ingredient\n",
    "        if ( mini_ingredient_graph[i][index] > compatibility):\n",
    "            new_ingredient_list.append(sorted_matches_ingredients[i][0])\n",
    "            new_ingredient_list.append(original_ingredients[i])\n",
    "    \n",
    "    return list(set(new_ingredient_list))\n",
    "\n",
    "select_ingredients(['cheese', 'salad', 'beef', 'banana', 'ice cream', 'cherry'], 0.3, ingredient_graph, ingredients_df)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Primary Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredient Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Baseline Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code requires torchtext 0.9\n",
    "It is recommended to run the baseline model seperately. The following code block should be run first before the import code block at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install torchtext==0.9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions_field = torchtext.legacy.data.Field(sequential=True,\n",
    "                                  tokenize=lambda x: x,\n",
    "                                  include_lengths=True,\n",
    "                                  batch_first=True,\n",
    "                                  use_vocab=True,\n",
    "                                  init_token=\"<BOS>\",\n",
    "                                  eos_token=\"<EOS>\")\n",
    "\n",
    "fields = [('directions', directions_field), ('ingredients', None)]\n",
    "baseline_data = torchtext.legacy.data.TabularDataset(\"./data/char_nlg_df.csv\", \"csv\", fields)\n",
    "\n",
    "directions_field.build_vocab(baseline_data)\n",
    "baseline_vocab_stoi = directions_field.vocab.stoi\n",
    "baseline_vocab_itos = directions_field.vocab.itos\n",
    "baseline_vocab_size = len(directions_field.vocab.itos)\n",
    "print(baseline_vocab_size)\n",
    "print(directions_field.vocab.itos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: A generative RNN trained using character-tokenized recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRecipeGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers =1 ):\n",
    "          super(RNNRecipeGenerator, self).__init__()\n",
    "          self.ident = torch.eye(vocab_size)\n",
    "          self.rnn = nn.GRU(vocab_size, hidden_size, n_layers, batch_first = True)\n",
    "          self.decoder = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inp, hidden = None):\n",
    "          inp = self.ident[inp]\n",
    "          output, hidden = self.rnn(inp, hidden)\n",
    "          output = self.decoder(output)\n",
    "          return output, hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recipe Generation: Using probability distribution to predict next character. Formatting is done manually corresponding to output from neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(model, max_len=1000, temperature=0.8):\n",
    "    generated_sequence = \"\"\n",
    "    \n",
    "    inp = torch.Tensor([baseline_vocab_stoi[\"<BOS>\"]]).long()\n",
    "    hidden = None\n",
    "    step = 1\n",
    "\n",
    "    for c in range(max_len):\n",
    "          output, hidden = model(inp.unsqueeze(0), hidden)\n",
    "          output_dist = output.data.view(-1).div(temperature).exp()\n",
    "          top = int(torch.multinomial(output_dist, 1)[0])\n",
    "\n",
    "          predicted_char = baseline_vocab_itos[top]\n",
    "\n",
    "          if predicted_char == \"<pad>\":\n",
    "              continue\n",
    "\n",
    "          if predicted_char == \"<BOS>\":\n",
    "              continue\n",
    "          \n",
    "          if predicted_char == \"<unk>\":\n",
    "              continue\n",
    "\n",
    "          if predicted_char == \";\":\n",
    "              step += 1\n",
    "              predicted_char = str(\"\\n \" + str(step) + \".\")\n",
    "\n",
    "          if predicted_char == \"<EOS>\":\n",
    "              break\n",
    "\n",
    "          generated_sequence += predicted_char\n",
    "          inp = torch.Tensor([top]).long()\n",
    "\n",
    "    return generated_sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training: A sample is printed every print_freq iterations to see the model's progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(model, data, batch_size=1, num_epochs=1, lr=1e-3, print_freq=200):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    iter = 0\n",
    "    data_iter = torchtext.legacy.data.BucketIterator(data, batch_size=batch_size, sort_key=lambda x: len(x.directions), sort_within_batch=True)\n",
    "    losses, iterations = [],[]\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        min_loss = float('inf')\n",
    "        for (directions, lengths), ingredients in data_iter:\n",
    "            target = directions[:, 1:]\n",
    "            inp = directions[:, :-1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output, _ = model(inp)\n",
    "            loss = criterion(output.reshape(-1, baseline_vocab_size), target.reshape(-1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss\n",
    "            iter += 1\n",
    "            losses.append(float(loss))\n",
    "            iterations.append(iter)\n",
    "\n",
    "            if iter % print_freq == 0:\n",
    "                  print(\"Iteration # %d: Loss %f\" % (iter+1, float(avg_loss/print_freq)))\n",
    "                  print(\"Generated Recipe: \\n 1.\" + sample_sequence(model, 1000, 1.5))\n",
    "                  avg_loss = 0\n",
    "\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iterations, losses, label = \"Training\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "baseline_model = RNNRecipeGenerator(baseline_vocab_size, 64, n_layers=1)\n",
    "train_baseline(baseline_model, baseline_data, batch_size=16, num_epochs=3, lr=1e-3, print_freq=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Results and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f6b67828bcf6e6b24b24226b27e29c318445726d2dd849532926bd41a61ff72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
